{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw1XwPRD9OLu"
   },
   "source": [
    "# IERG 5350 Assignment 4: Advanced Algorithms for Continuous Control in RL\n",
    "\n",
    "### Welcome to assignment 4 of our RL course!\n",
    "*2020-2021 Term 1, IERG 5350: Reinforcement Learning. Department of Information Engineering, The Chinese University of Hong Kong. Course Instructor: Professor ZHOU Bolei. Assignment author: PENG Zhenghao, SUN Hao, ZHAN Xiaohang.*\n",
    "\n",
    "\n",
    "| Student Name | Student ID |\n",
    "| :----: | :----: |\n",
    "| HUANG Zhaoyang | 1155152331 |\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "In this assignment, we will implement a system of RL that allows us to train and evaluate RL agents formally and efficiently.\n",
    "\n",
    "In this notebook, you will go through the following components of the whole system:\n",
    "- Preparation: Colab, and Environment\n",
    "- Section 1: Training with algorithm PPO\n",
    "- Section 2: Training with algorithm DDPG\n",
    "- Section 3: Training with algorithm TD3\n",
    "- Section 4: Transfer your PPO/ DDPG/ TD3 to another task: Four-Solution-Maze\n",
    "\n",
    "The author of this assignment is SUN, Hao (sh018 AT ie.cuhk.edu.hk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyLEr-yOpxvD"
   },
   "source": [
    "# Colab\n",
    "\n",
    "### Introduction to Google Colab: \n",
    "From now on, our assignment as well as the final project will be based on the Google Colab, where you can apply for free GPU resources to accelerate the learning of your RL models. \n",
    "\n",
    "Here are some resources as intro to the Colab.\n",
    "\n",
    "- YouTube Video: https://www.youtube.com/watch?v=inN8seMm7UI\n",
    "- Colab Intro: https://colab.research.google.com/notebooks/intro.ipynb\n",
    "(you may need to login with your google account)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Gym Continuous Control Tasks\n",
    "\n",
    "### Introduction to the Gym Continuous Control Envirionments\n",
    "\n",
    "In the last assignment, you have already used the gym[atari] benchmarks, where the action space is discrete so that normal approach is value-based methods e.g., DQN.\n",
    "\n",
    "In this assignment, we will try to implement three prevailing RL algorithms for continuous control tasks, namely the PPO(https://arxiv.org/abs/1707.06347), DDPG(https://arxiv.org/abs/1509.02971) and TD3(https://arxiv.org/abs/1802.09477).\n",
    "\n",
    "We will now begin with a gym environment for continuous control,\n",
    "\n",
    "The Pendulum-v0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "2CjdPG_oqT1l",
    "outputId": "541724ca-af57-4bed-817f-728b21e8fb49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state space is like [0.99344123 0.11434389 0.64249418]\n",
      "the max and min action is:  [2.] [-2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'so that you may need to use action value re-size if you want to use the tanh activation functions'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "ENV_NAME = \"Pendulum-v0\"\n",
    "env = gym.make(ENV_NAME)\n",
    "state = env.reset()\n",
    "print('the state space is like', state)\n",
    "print('the max and min action is: ',env.action_space.high,env.action_space.low)\n",
    "\n",
    "'''so that you may need to use action value re-size if you want to use the tanh activation functions'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7IHoYJWur1S"
   },
   "source": [
    "# PPO \n",
    "\n",
    "The Proximal Policy Optimization Algorithms is the most prevailing on-policy learning method. Although its sample efficiency is not as high as the off-policy methods, the PPO is relatively easy to implement and the learning is much more stable than off-policy methods. Whenever you have a task you want to try whether RL works, you may try to run a PPO agent at first. It is worth mentioning even the most challenging game, the StarCraftII agent AlphaStar is trained based on PPO (with lots of improvements, ofcourse).\n",
    "\n",
    "\n",
    "## TODOs for You\n",
    "The ppo has the benfitsof trust region policy optimization (TRPO) but is much simpler to implement, and with some implementation engeneering, the sample complexity of TRPO is further improved.\n",
    "\n",
    "The key idea of PPO optimization is *Not Optimize the Policy Too Much in a Certain Step*, which follows the key insight of the method of TRPO.\n",
    "\n",
    "In TRPO, the optimization objective of policy is to learn a policy such that \n",
    "\n",
    "$$\\max_\\theta \\hat{\\mathbb{E}}_t [\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)}\\hat{A}_t]$$\n",
    "\n",
    "subject to \n",
    "\n",
    "$$\\hat{\\mathbb{E}}_t[KL[\\pi_{\\theta_{old}}(\\cdot|s_t),\\pi_\\theta(\\cdot|s_t)]] \\le \\delta$$\n",
    "\n",
    "where $\\hat{A}$ denotes the advantage function, rather than optimize the objective function of \n",
    "\n",
    "$$L^{PG}(\\theta) = \\hat{\\mathbb{E}}_t[\\log \\pi_\\theta(a_t|s_t)\\hat{A}_t]$$\n",
    "\n",
    "in the normal policy gradint methods.\n",
    "\n",
    "The PPO proposed two alternative approaches to solve the constrained optimization above, namely the Clipped Surrogated Objective and the Adaptive KL penalty Coefficient. The former one is more generally used in practice as it's more convenient to implement, more efficient and owns stable performance.\n",
    "\n",
    "The Clipped Surrogated Objective approach replace the surrogate objective\n",
    "\n",
    "$$L^{CPI}(\\theta) = \\hat{\\mathbb{E}}_t[\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)}\\hat{A}_t] = \\hat{\\mathbb{E}}_t[r_t(\\theta)\\hat{A}_t]$$\n",
    "\n",
    "of TRPO (CPI: Conservative Policy Iteration) by \n",
    "\n",
    "$$L^{CLIP}(\\theta) = \\hat{\\mathbb{E}}_t[\\min(r_t(\\theta)\\hat{A}_t,clip(r_t(\\theta),1-\\epsilon, 1+\\epsilon)\\hat{A}_t)]$$\n",
    "\n",
    "You can check that $L^{CLIP}(\\theta) = L^{CPI}(\\theta)$ around the old policy parameter $\\theta_{old}$, i.e., when r = 1.\n",
    "\n",
    "## TODOs here:\n",
    "\n",
    "In this section, your task is to finish the code of a PPO algorithm and evaluate its performance in the Pendulum-v0 environment.\n",
    "\n",
    "Specifically, you need to\n",
    "- Q1. finish building up the ActorCritic ''\\__init__'' function, i.e., build up the neural network.\n",
    "- Q2. finish the foward function, in this part, there are two functions need to finish: the \\_forward_actor function and the \\_forward_critic function\n",
    "- Q3. finish the select_action function, which is called during interacting with the environment, so that you may need to return an action as well as the (log-)probability of getting that action for future optimization\n",
    "- Q4. finish the optimization steps for your PPO agent, that means you need to build up the surrogate loss through your saved tuples in previous episodes and optimize it with current network parameters.\n",
    "- Q5. finally, you may need to optimize some of the hyper-parameters to have a better task performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hCkX9dWFvXxa"
   },
   "outputs": [],
   "source": [
    "# You need not to rivese this unless you want to try other hyper-parameter settings\n",
    "# in which case you may revise the default values of class args()\n",
    "from IPython import display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as joindir\n",
    "from os import makedirs as mkdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'value', 'action', 'logproba', 'mask', 'next_state', 'reward'))\n",
    "env = gym.make(ENV_NAME)\n",
    "env.reset()\n",
    "\n",
    "EPS = 1e-10 # you may need this tiny value somewhere, and think about why?\n",
    "RESULT_DIR = 'Result_PPO'\n",
    "mkdir(RESULT_DIR, exist_ok=True)\n",
    "mkdir(ENV_NAME.split('-')[0]+'/CheckPoints', exist_ok=True)\n",
    "mkdir(ENV_NAME.split('-')[0]+'/Rwds', exist_ok=True)\n",
    "rwds = []\n",
    "rwds_history = []\n",
    "\n",
    "class args(object):\n",
    "    hid_num = 256\n",
    "    drop_prob = 0.1\n",
    "    env_name = ENV_NAME\n",
    "    seed = 1234\n",
    "    num_episode = 1000\n",
    "    batch_size = 5120\n",
    "#     batch_size = 10240\n",
    "    max_step_per_round = 2000\n",
    "    gamma = 0.995\n",
    "    lamda = 0.9\n",
    "    log_num_episode = 1\n",
    "    num_epoch = 10\n",
    "    minibatch_size = 256\n",
    "#     minibatch_size = 512\n",
    "    clip = 0.2\n",
    "    loss_coeff_value = 0.5\n",
    "    loss_coeff_entropy = 0.01\n",
    "    lr = 3e-4\n",
    "    num_parallel_run = 1\n",
    "    # tricks\n",
    "    schedule_adam = 'linear'\n",
    "    schedule_clip = 'linear'\n",
    "    layer_norm = True\n",
    "    state_norm = True\n",
    "    advantage_norm = True\n",
    "    lossvalue_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "H0zwluYyx-y_"
   },
   "outputs": [],
   "source": [
    "# You need not to rivese this, these classes are used for normalization\n",
    "class RunningStat(object):\n",
    "    def __init__(self, shape):\n",
    "        self._n = 0\n",
    "        self._M = np.zeros(shape)\n",
    "        self._S = np.zeros(shape)\n",
    "\n",
    "    def push(self, x):\n",
    "        x = np.asarray(x)\n",
    "        assert x.shape == self._M.shape\n",
    "        self._n += 1\n",
    "        if self._n == 1:\n",
    "            self._M[...] = x\n",
    "        else:\n",
    "            oldM = self._M.copy()\n",
    "            self._M[...] = oldM + (x - oldM) / self._n\n",
    "            self._S[...] = self._S + (x - oldM) * (x - self._M)\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        return self._n\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self._M\n",
    "\n",
    "    @property\n",
    "    def var(self):\n",
    "        return self._S / (self._n - 1) if self._n > 1 else np.square(self._M)\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(self.var)\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self._M.shape\n",
    "\n",
    "\n",
    "class ZFilter:\n",
    "    \"\"\"\n",
    "    y = (x-mean)/std\n",
    "    using running estimates of mean,std\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shape, demean=True, destd=True, clip=10.0):\n",
    "        self.demean = demean\n",
    "        self.destd = destd\n",
    "        self.clip = clip\n",
    "\n",
    "        self.rs = RunningStat(shape)\n",
    "\n",
    "    def __call__(self, x, update=True):\n",
    "        if update: self.rs.push(x)\n",
    "        if self.demean:\n",
    "            x = x - self.rs.mean\n",
    "        if self.destd:\n",
    "            x = x / (self.rs.std + 1e-8)\n",
    "        if self.clip:\n",
    "            x = np.clip(x, -self.clip, self.clip)\n",
    "        return x\n",
    "\n",
    "    def output_shape(self, input_space):\n",
    "        return input_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "JDqYISHHyQve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 0 Reward: -1300.5992 total_loss = 75.6463 = 0.1669 + 0.5 * 150.9638 + 0.01 * -0.2432\n",
      "-----------------\n",
      "Finished episode: 1 Reward: -1306.5176 total_loss = 25.5704 = 0.1746 + 0.5 * 50.7983 + 0.01 * -0.3382\n",
      "-----------------\n",
      "Finished episode: 2 Reward: -1275.1845 total_loss = 20.5015 = -0.0560 + 0.5 * 41.1202 + 0.01 * -0.2625\n",
      "-----------------\n",
      "Finished episode: 3 Reward: -1330.6315 total_loss = 20.8473 = 0.1944 + 0.5 * 41.3108 + 0.01 * -0.2562\n",
      "-----------------\n",
      "Finished episode: 4 Reward: -1354.6451 total_loss = 20.9559 = 0.1728 + 0.5 * 41.5720 + 0.01 * -0.2902\n",
      "-----------------\n",
      "Finished episode: 5 Reward: -1256.0644 total_loss = 19.0352 = 0.0765 + 0.5 * 37.9240 + 0.01 * -0.3252\n",
      "-----------------\n",
      "Finished episode: 6 Reward: -1294.9929 total_loss = 19.4824 = 0.2743 + 0.5 * 38.4218 + 0.01 * -0.2796\n",
      "-----------------\n",
      "Finished episode: 7 Reward: -1192.6062 total_loss = 16.2362 = 0.0438 + 0.5 * 32.3911 + 0.01 * -0.3187\n",
      "-----------------\n",
      "Finished episode: 8 Reward: -1192.4326 total_loss = 17.7648 = 0.0428 + 0.5 * 35.4493 + 0.01 * -0.2674\n",
      "-----------------\n",
      "Finished episode: 9 Reward: -1319.6265 total_loss = 20.1768 = 0.1403 + 0.5 * 40.0791 + 0.01 * -0.3123\n",
      "-----------------\n",
      "Finished episode: 10 Reward: -1225.5195 total_loss = 17.5742 = 0.0994 + 0.5 * 34.9558 + 0.01 * -0.3138\n",
      "-----------------\n",
      "Finished episode: 11 Reward: -1193.5584 total_loss = 16.2314 = 0.0694 + 0.5 * 32.3293 + 0.01 * -0.2710\n",
      "-----------------\n",
      "Finished episode: 12 Reward: -1442.4786 total_loss = 21.9320 = 0.0708 + 0.5 * 43.7283 + 0.01 * -0.2992\n",
      "-----------------\n",
      "Finished episode: 13 Reward: -1279.9060 total_loss = 19.5450 = 0.0275 + 0.5 * 39.0410 + 0.01 * -0.2926\n",
      "-----------------\n",
      "Finished episode: 14 Reward: -1355.6629 total_loss = 20.4281 = 0.0218 + 0.5 * 40.8185 + 0.01 * -0.2966\n",
      "-----------------\n",
      "Finished episode: 15 Reward: -1369.5939 total_loss = 20.6235 = 0.0399 + 0.5 * 41.1729 + 0.01 * -0.2882\n",
      "-----------------\n",
      "Finished episode: 16 Reward: -1264.1923 total_loss = 18.7667 = -0.0163 + 0.5 * 37.5718 + 0.01 * -0.2901\n",
      "-----------------\n",
      "Finished episode: 17 Reward: -1365.9351 total_loss = 21.0378 = -0.0342 + 0.5 * 42.1497 + 0.01 * -0.2849\n",
      "-----------------\n",
      "Finished episode: 18 Reward: -1235.0282 total_loss = 18.9512 = -0.0514 + 0.5 * 38.0108 + 0.01 * -0.2807\n",
      "-----------------\n",
      "Finished episode: 19 Reward: -1189.4045 total_loss = 17.0803 = -0.0837 + 0.5 * 34.3336 + 0.01 * -0.2737\n",
      "-----------------\n",
      "Finished episode: 20 Reward: -1092.5205 total_loss = 14.7350 = -0.0196 + 0.5 * 29.5145 + 0.01 * -0.2672\n",
      "-----------------\n",
      "Finished episode: 21 Reward: -1094.4614 total_loss = 14.4692 = 0.0677 + 0.5 * 28.8084 + 0.01 * -0.2632\n",
      "-----------------\n",
      "Finished episode: 22 Reward: -1171.0492 total_loss = 15.0717 = 0.0665 + 0.5 * 30.0159 + 0.01 * -0.2659\n",
      "-----------------\n",
      "Finished episode: 23 Reward: -1196.1815 total_loss = 12.7098 = 0.0180 + 0.5 * 25.3887 + 0.01 * -0.2610\n",
      "-----------------\n",
      "Finished episode: 24 Reward: -1048.1633 total_loss = 12.8841 = -0.0273 + 0.5 * 25.8281 + 0.01 * -0.2614\n",
      "-----------------\n",
      "Finished episode: 25 Reward: -1033.3203 total_loss = 11.2278 = -0.0608 + 0.5 * 22.5823 + 0.01 * -0.2560\n",
      "-----------------\n",
      "Finished episode: 26 Reward: -1083.9182 total_loss = 11.4853 = 0.1137 + 0.5 * 22.7482 + 0.01 * -0.2559\n",
      "-----------------\n",
      "Finished episode: 27 Reward: -1048.6678 total_loss = 9.0567 = -0.0059 + 0.5 * 18.1304 + 0.01 * -0.2540\n",
      "-----------------\n",
      "Finished episode: 28 Reward: -1008.0915 total_loss = 11.5522 = -0.1032 + 0.5 * 23.3158 + 0.01 * -0.2511\n",
      "-----------------\n",
      "Finished episode: 29 Reward: -1017.4503 total_loss = 10.5190 = 0.0051 + 0.5 * 21.0329 + 0.01 * -0.2499\n",
      "-----------------\n",
      "Finished episode: 30 Reward: -1028.5254 total_loss = 10.7496 = -0.0630 + 0.5 * 21.6303 + 0.01 * -0.2468\n",
      "-----------------\n",
      "Finished episode: 31 Reward: -1073.5016 total_loss = 11.3602 = 0.0535 + 0.5 * 22.6182 + 0.01 * -0.2443\n",
      "-----------------\n",
      "Finished episode: 32 Reward: -1010.8863 total_loss = 11.5860 = -0.0541 + 0.5 * 23.2850 + 0.01 * -0.2418\n",
      "-----------------\n",
      "Finished episode: 33 Reward: -992.0305 total_loss = 9.2434 = 0.0277 + 0.5 * 18.4362 + 0.01 * -0.2388\n",
      "-----------------\n",
      "Finished episode: 34 Reward: -1040.2006 total_loss = 12.9048 = -0.1152 + 0.5 * 26.0447 + 0.01 * -0.2374\n",
      "-----------------\n",
      "Finished episode: 35 Reward: -943.5026 total_loss = 10.5558 = -0.0371 + 0.5 * 21.1905 + 0.01 * -0.2366\n",
      "-----------------\n",
      "Finished episode: 36 Reward: -1061.1211 total_loss = 11.8950 = -0.0340 + 0.5 * 23.8626 + 0.01 * -0.2323\n",
      "-----------------\n",
      "Finished episode: 37 Reward: -1031.8047 total_loss = 8.9873 = 0.1262 + 0.5 * 17.7268 + 0.01 * -0.2319\n",
      "-----------------\n",
      "Finished episode: 38 Reward: -1002.7559 total_loss = 11.4869 = 0.0566 + 0.5 * 22.8652 + 0.01 * -0.2330\n",
      "-----------------\n",
      "Finished episode: 39 Reward: -1005.4990 total_loss = 10.2783 = 0.0410 + 0.5 * 20.4791 + 0.01 * -0.2296\n",
      "-----------------\n",
      "Finished episode: 40 Reward: -982.8307 total_loss = 10.2824 = -0.0373 + 0.5 * 20.6439 + 0.01 * -0.2284\n",
      "-----------------\n",
      "Finished episode: 41 Reward: -933.9072 total_loss = 10.7852 = -0.0331 + 0.5 * 21.6412 + 0.01 * -0.2285\n",
      "-----------------\n",
      "Finished episode: 42 Reward: -978.4919 total_loss = 10.2867 = -0.0009 + 0.5 * 20.5799 + 0.01 * -0.2283\n",
      "-----------------\n",
      "Finished episode: 43 Reward: -962.7063 total_loss = 12.6629 = -0.0100 + 0.5 * 25.3502 + 0.01 * -0.2264\n",
      "-----------------\n",
      "Finished episode: 44 Reward: -967.8699 total_loss = 10.7818 = -0.0304 + 0.5 * 21.6288 + 0.01 * -0.2231\n",
      "-----------------\n",
      "Finished episode: 45 Reward: -1048.0090 total_loss = 10.3390 = -0.1275 + 0.5 * 20.9373 + 0.01 * -0.2243\n",
      "-----------------\n",
      "Finished episode: 46 Reward: -982.8864 total_loss = 11.1738 = -0.1349 + 0.5 * 22.6218 + 0.01 * -0.2216\n",
      "-----------------\n",
      "Finished episode: 47 Reward: -1029.3059 total_loss = 10.8622 = 0.0249 + 0.5 * 21.6791 + 0.01 * -0.2209\n",
      "-----------------\n",
      "Finished episode: 48 Reward: -1009.7563 total_loss = 9.7188 = -0.0199 + 0.5 * 19.4817 + 0.01 * -0.2187\n",
      "-----------------\n",
      "Finished episode: 49 Reward: -1084.5654 total_loss = 11.5863 = 0.0037 + 0.5 * 23.1696 + 0.01 * -0.2179\n",
      "-----------------\n",
      "Finished episode: 50 Reward: -1029.7156 total_loss = 11.0278 = -0.0303 + 0.5 * 22.1205 + 0.01 * -0.2142\n",
      "-----------------\n",
      "Finished episode: 51 Reward: -976.0222 total_loss = 9.5496 = -0.0401 + 0.5 * 19.1836 + 0.01 * -0.2131\n",
      "-----------------\n",
      "Finished episode: 52 Reward: -1009.7482 total_loss = 10.8825 = -0.0424 + 0.5 * 21.8540 + 0.01 * -0.2128\n",
      "-----------------\n",
      "Finished episode: 53 Reward: -958.3221 total_loss = 8.3130 = 0.0282 + 0.5 * 16.5738 + 0.01 * -0.2133\n",
      "-----------------\n",
      "Finished episode: 54 Reward: -970.8566 total_loss = 11.3512 = -0.0397 + 0.5 * 22.7860 + 0.01 * -0.2127\n",
      "-----------------\n",
      "Finished episode: 55 Reward: -1070.1599 total_loss = 12.4241 = 0.0100 + 0.5 * 24.8325 + 0.01 * -0.2128\n",
      "-----------------\n",
      "Finished episode: 56 Reward: -1060.7537 total_loss = 12.4920 = 0.0857 + 0.5 * 24.8168 + 0.01 * -0.2110\n",
      "-----------------\n",
      "Finished episode: 57 Reward: -1067.8083 total_loss = 10.6903 = -0.0265 + 0.5 * 21.4377 + 0.01 * -0.2090\n",
      "-----------------\n",
      "Finished episode: 58 Reward: -1042.5199 total_loss = 13.0786 = 0.0547 + 0.5 * 26.0519 + 0.01 * -0.2074\n",
      "-----------------\n",
      "Finished episode: 59 Reward: -890.3887 total_loss = 10.6729 = 0.0395 + 0.5 * 21.2710 + 0.01 * -0.2068\n",
      "-----------------\n",
      "Finished episode: 60 Reward: -1097.0821 total_loss = 12.7891 = 0.0920 + 0.5 * 25.3984 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 61 Reward: -979.7002 total_loss = 9.8284 = 0.0311 + 0.5 * 19.5987 + 0.01 * -0.2057\n",
      "-----------------\n",
      "Finished episode: 62 Reward: -1103.4018 total_loss = 13.8255 = 0.0440 + 0.5 * 27.5671 + 0.01 * -0.2039\n",
      "-----------------\n",
      "Finished episode: 63 Reward: -1023.1149 total_loss = 11.1658 = 0.0680 + 0.5 * 22.1997 + 0.01 * -0.2054\n",
      "-----------------\n",
      "Finished episode: 64 Reward: -939.9862 total_loss = 8.4931 = 0.0107 + 0.5 * 16.9688 + 0.01 * -0.2037\n",
      "-----------------\n",
      "Finished episode: 65 Reward: -1005.0943 total_loss = 11.6759 = -0.0748 + 0.5 * 23.5055 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 66 Reward: -1011.5346 total_loss = 8.2296 = 0.0557 + 0.5 * 16.3519 + 0.01 * -0.2034\n",
      "-----------------\n",
      "Finished episode: 67 Reward: -974.0445 total_loss = 10.7521 = 0.0007 + 0.5 * 21.5069 + 0.01 * -0.2020\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 68 Reward: -1068.1527 total_loss = 10.3271 = -0.0284 + 0.5 * 20.7150 + 0.01 * -0.2043\n",
      "-----------------\n",
      "Finished episode: 69 Reward: -1043.3821 total_loss = 11.3795 = 0.0275 + 0.5 * 22.7081 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 70 Reward: -1093.9854 total_loss = 13.0613 = -0.0480 + 0.5 * 26.2225 + 0.01 * -0.1989\n",
      "-----------------\n",
      "Finished episode: 71 Reward: -1025.2817 total_loss = 9.3093 = 0.0032 + 0.5 * 18.6163 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 72 Reward: -1058.6795 total_loss = 12.5588 = 0.0403 + 0.5 * 25.0409 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 73 Reward: -1020.8842 total_loss = 11.2235 = -0.0518 + 0.5 * 22.5547 + 0.01 * -0.2000\n",
      "-----------------\n",
      "Finished episode: 74 Reward: -935.6032 total_loss = 9.6573 = 0.0333 + 0.5 * 19.2520 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 75 Reward: -984.7596 total_loss = 11.0845 = 0.0251 + 0.5 * 22.1227 + 0.01 * -0.1981\n",
      "-----------------\n",
      "Finished episode: 76 Reward: -1050.9059 total_loss = 9.6437 = -0.0100 + 0.5 * 19.3115 + 0.01 * -0.1995\n",
      "-----------------\n",
      "Finished episode: 77 Reward: -967.0716 total_loss = 8.9253 = -0.0394 + 0.5 * 17.9335 + 0.01 * -0.1995\n",
      "-----------------\n",
      "Finished episode: 78 Reward: -990.1663 total_loss = 8.5593 = 0.0501 + 0.5 * 17.0223 + 0.01 * -0.1984\n",
      "-----------------\n",
      "Finished episode: 79 Reward: -1142.2989 total_loss = 11.8615 = -0.0852 + 0.5 * 23.8972 + 0.01 * -0.1960\n",
      "-----------------\n",
      "Finished episode: 80 Reward: -998.1996 total_loss = 8.6204 = 0.0221 + 0.5 * 17.2005 + 0.01 * -0.1977\n",
      "-----------------\n",
      "Finished episode: 81 Reward: -1045.1394 total_loss = 12.5697 = -0.0098 + 0.5 * 25.1630 + 0.01 * -0.1961\n",
      "-----------------\n",
      "Finished episode: 82 Reward: -1014.0253 total_loss = 9.8962 = 0.0274 + 0.5 * 19.7416 + 0.01 * -0.2005\n",
      "-----------------\n",
      "Finished episode: 83 Reward: -982.3824 total_loss = 9.9919 = -0.1403 + 0.5 * 20.2683 + 0.01 * -0.1979\n",
      "-----------------\n",
      "Finished episode: 84 Reward: -1125.0867 total_loss = 13.4532 = 0.0128 + 0.5 * 26.8848 + 0.01 * -0.1965\n",
      "-----------------\n",
      "Finished episode: 85 Reward: -985.0502 total_loss = 10.3870 = -0.0170 + 0.5 * 20.8120 + 0.01 * -0.1986\n",
      "-----------------\n",
      "Finished episode: 86 Reward: -1024.5938 total_loss = 8.0601 = 0.0360 + 0.5 * 16.0520 + 0.01 * -0.1966\n",
      "-----------------\n",
      "Finished episode: 87 Reward: -947.5765 total_loss = 7.4493 = -0.0606 + 0.5 * 15.0236 + 0.01 * -0.1979\n",
      "-----------------\n",
      "Finished episode: 88 Reward: -967.2838 total_loss = 10.8656 = -0.0193 + 0.5 * 21.7738 + 0.01 * -0.1989\n",
      "-----------------\n",
      "Finished episode: 89 Reward: -962.4397 total_loss = 10.8779 = 0.0364 + 0.5 * 21.6869 + 0.01 * -0.1976\n",
      "-----------------\n",
      "Finished episode: 90 Reward: -925.8708 total_loss = 8.7175 = 0.1007 + 0.5 * 17.2376 + 0.01 * -0.1971\n",
      "-----------------\n",
      "Finished episode: 91 Reward: -935.6970 total_loss = 8.7298 = -0.0228 + 0.5 * 17.5091 + 0.01 * -0.1964\n",
      "-----------------\n",
      "Finished episode: 92 Reward: -1077.0668 total_loss = 12.7788 = -0.1107 + 0.5 * 25.7830 + 0.01 * -0.1947\n",
      "-----------------\n",
      "Finished episode: 93 Reward: -942.2360 total_loss = 8.7784 = -0.0488 + 0.5 * 17.6583 + 0.01 * -0.1994\n",
      "-----------------\n",
      "Finished episode: 94 Reward: -1016.8709 total_loss = 11.5237 = 0.0251 + 0.5 * 23.0011 + 0.01 * -0.1956\n",
      "-----------------\n",
      "Finished episode: 95 Reward: -1051.5299 total_loss = 12.1271 = -0.0155 + 0.5 * 24.2892 + 0.01 * -0.1985\n",
      "-----------------\n",
      "Finished episode: 96 Reward: -966.7426 total_loss = 9.0762 = -0.0869 + 0.5 * 18.3303 + 0.01 * -0.1972\n",
      "-----------------\n",
      "Finished episode: 97 Reward: -897.1216 total_loss = 8.6054 = -0.0212 + 0.5 * 17.2570 + 0.01 * -0.1957\n",
      "-----------------\n",
      "Finished episode: 98 Reward: -1103.0222 total_loss = 13.5770 = -0.0242 + 0.5 * 27.2064 + 0.01 * -0.1971\n",
      "-----------------\n",
      "Finished episode: 99 Reward: -1048.6315 total_loss = 11.2428 = 0.0414 + 0.5 * 22.4068 + 0.01 * -0.1950\n",
      "-----------------\n",
      "Finished episode: 100 Reward: -1053.1118 total_loss = 10.8571 = -0.0249 + 0.5 * 21.7677 + 0.01 * -0.1947\n",
      "-----------------\n",
      "Finished episode: 101 Reward: -954.6866 total_loss = 7.7337 = -0.0171 + 0.5 * 15.5055 + 0.01 * -0.1948\n",
      "-----------------\n",
      "Finished episode: 102 Reward: -972.4046 total_loss = 8.8954 = -0.0021 + 0.5 * 17.7988 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 103 Reward: -943.7533 total_loss = 7.9621 = 0.0731 + 0.5 * 15.7819 + 0.01 * -0.1928\n",
      "-----------------\n",
      "Finished episode: 104 Reward: -1042.9962 total_loss = 9.0363 = -0.0893 + 0.5 * 18.2552 + 0.01 * -0.1946\n",
      "-----------------\n",
      "Finished episode: 105 Reward: -1003.0422 total_loss = 11.2073 = -0.0978 + 0.5 * 22.6141 + 0.01 * -0.1950\n",
      "-----------------\n",
      "Finished episode: 106 Reward: -960.6836 total_loss = 10.5558 = 0.0243 + 0.5 * 21.0668 + 0.01 * -0.1951\n",
      "-----------------\n",
      "Finished episode: 107 Reward: -980.2383 total_loss = 10.7258 = 0.0172 + 0.5 * 21.4211 + 0.01 * -0.1949\n",
      "-----------------\n",
      "Finished episode: 108 Reward: -960.0016 total_loss = 10.5998 = -0.2172 + 0.5 * 21.6379 + 0.01 * -0.1962\n",
      "-----------------\n",
      "Finished episode: 109 Reward: -943.2537 total_loss = 9.5171 = -0.0673 + 0.5 * 19.1726 + 0.01 * -0.1955\n",
      "-----------------\n",
      "Finished episode: 110 Reward: -1109.9129 total_loss = 10.5526 = -0.1643 + 0.5 * 21.4376 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 111 Reward: -1045.4487 total_loss = 11.3192 = 0.1019 + 0.5 * 22.4384 + 0.01 * -0.1917\n",
      "-----------------\n",
      "Finished episode: 112 Reward: -1012.2058 total_loss = 13.6492 = 0.0553 + 0.5 * 27.1916 + 0.01 * -0.1893\n",
      "-----------------\n",
      "Finished episode: 113 Reward: -950.5749 total_loss = 10.2384 = -0.0203 + 0.5 * 20.5212 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 114 Reward: -1138.2992 total_loss = 12.3204 = 0.0318 + 0.5 * 24.5809 + 0.01 * -0.1891\n",
      "-----------------\n",
      "Finished episode: 115 Reward: -894.0458 total_loss = 8.0950 = -0.0487 + 0.5 * 16.2912 + 0.01 * -0.1909\n",
      "-----------------\n",
      "Finished episode: 116 Reward: -1035.6031 total_loss = 11.8360 = -0.0805 + 0.5 * 23.8368 + 0.01 * -0.1915\n",
      "-----------------\n",
      "Finished episode: 117 Reward: -938.7734 total_loss = 9.2200 = -0.0404 + 0.5 * 18.5247 + 0.01 * -0.1923\n",
      "-----------------\n",
      "Finished episode: 118 Reward: -926.9092 total_loss = 9.4785 = 0.0641 + 0.5 * 18.8328 + 0.01 * -0.1907\n",
      "-----------------\n",
      "Finished episode: 119 Reward: -1074.5638 total_loss = 11.9199 = -0.0580 + 0.5 * 23.9595 + 0.01 * -0.1904\n",
      "-----------------\n",
      "Finished episode: 120 Reward: -940.1921 total_loss = 11.5757 = -0.0059 + 0.5 * 23.1669 + 0.01 * -0.1925\n",
      "-----------------\n",
      "Finished episode: 121 Reward: -1005.7931 total_loss = 12.7848 = -0.0207 + 0.5 * 25.6148 + 0.01 * -0.1916\n",
      "-----------------\n",
      "Finished episode: 122 Reward: -897.6859 total_loss = 9.4979 = -0.0876 + 0.5 * 19.1747 + 0.01 * -0.1932\n",
      "-----------------\n",
      "Finished episode: 123 Reward: -937.3554 total_loss = 8.4928 = 0.0120 + 0.5 * 16.9654 + 0.01 * -0.1922\n",
      "-----------------\n",
      "Finished episode: 124 Reward: -931.0802 total_loss = 7.6399 = -0.0313 + 0.5 * 15.3462 + 0.01 * -0.1934\n",
      "-----------------\n",
      "Finished episode: 125 Reward: -1031.6784 total_loss = 10.6022 = 0.0297 + 0.5 * 21.1490 + 0.01 * -0.1911\n",
      "-----------------\n",
      "Finished episode: 126 Reward: -1000.0554 total_loss = 9.8195 = 0.0061 + 0.5 * 19.6308 + 0.01 * -0.1907\n",
      "-----------------\n",
      "Finished episode: 127 Reward: -902.6857 total_loss = 8.6628 = -0.0873 + 0.5 * 17.5041 + 0.01 * -0.1929\n",
      "-----------------\n",
      "Finished episode: 128 Reward: -912.5438 total_loss = 9.1112 = -0.0132 + 0.5 * 18.2528 + 0.01 * -0.1925\n",
      "-----------------\n",
      "Finished episode: 129 Reward: -867.8332 total_loss = 7.8471 = 0.0381 + 0.5 * 15.6218 + 0.01 * -0.1911\n",
      "-----------------\n",
      "Finished episode: 130 Reward: -955.3233 total_loss = 7.7678 = -0.0962 + 0.5 * 15.7318 + 0.01 * -0.1926\n",
      "-----------------\n",
      "Finished episode: 131 Reward: -866.0712 total_loss = 9.4685 = -0.0509 + 0.5 * 19.0428 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 132 Reward: -924.9254 total_loss = 9.6088 = -0.0757 + 0.5 * 19.3730 + 0.01 * -0.1935\n",
      "-----------------\n",
      "Finished episode: 133 Reward: -998.9192 total_loss = 9.3626 = -0.0271 + 0.5 * 18.7832 + 0.01 * -0.1910\n",
      "-----------------\n",
      "Finished episode: 134 Reward: -860.8165 total_loss = 8.6193 = -0.0321 + 0.5 * 17.3065 + 0.01 * -0.1919\n",
      "-----------------\n",
      "Finished episode: 135 Reward: -858.2197 total_loss = 8.7375 = 0.0115 + 0.5 * 17.4558 + 0.01 * -0.1910\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 136 Reward: -1015.6561 total_loss = 8.5211 = -0.0558 + 0.5 * 17.1577 + 0.01 * -0.1924\n",
      "-----------------\n",
      "Finished episode: 137 Reward: -992.2951 total_loss = 8.5050 = 0.0019 + 0.5 * 17.0101 + 0.01 * -0.1891\n",
      "-----------------\n",
      "Finished episode: 138 Reward: -935.4265 total_loss = 10.8186 = 0.0065 + 0.5 * 21.6280 + 0.01 * -0.1875\n",
      "-----------------\n",
      "Finished episode: 139 Reward: -975.9290 total_loss = 9.6722 = 0.0183 + 0.5 * 19.3116 + 0.01 * -0.1892\n",
      "-----------------\n",
      "Finished episode: 140 Reward: -884.8585 total_loss = 8.9540 = -0.0845 + 0.5 * 18.0809 + 0.01 * -0.1894\n",
      "-----------------\n",
      "Finished episode: 141 Reward: -943.9329 total_loss = 8.4614 = 0.0277 + 0.5 * 16.8711 + 0.01 * -0.1911\n",
      "-----------------\n",
      "Finished episode: 142 Reward: -893.9038 total_loss = 8.5635 = 0.0385 + 0.5 * 17.0538 + 0.01 * -0.1897\n",
      "-----------------\n",
      "Finished episode: 143 Reward: -982.4217 total_loss = 8.8867 = -0.0705 + 0.5 * 17.9181 + 0.01 * -0.1874\n",
      "-----------------\n",
      "Finished episode: 144 Reward: -974.5897 total_loss = 8.1657 = -0.0376 + 0.5 * 16.4104 + 0.01 * -0.1888\n",
      "-----------------\n",
      "Finished episode: 145 Reward: -924.7423 total_loss = 10.0908 = 0.0407 + 0.5 * 20.1038 + 0.01 * -0.1883\n",
      "-----------------\n",
      "Finished episode: 146 Reward: -976.7374 total_loss = 7.8428 = 0.0336 + 0.5 * 15.6221 + 0.01 * -0.1883\n",
      "-----------------\n",
      "Finished episode: 147 Reward: -917.2016 total_loss = 10.9015 = -0.0287 + 0.5 * 21.8641 + 0.01 * -0.1871\n",
      "-----------------\n",
      "Finished episode: 148 Reward: -887.1651 total_loss = 7.9272 = 0.0016 + 0.5 * 15.8548 + 0.01 * -0.1865\n",
      "-----------------\n",
      "Finished episode: 149 Reward: -929.6325 total_loss = 8.8911 = 0.0635 + 0.5 * 17.6589 + 0.01 * -0.1883\n",
      "-----------------\n",
      "Finished episode: 150 Reward: -896.4894 total_loss = 9.7648 = 0.0630 + 0.5 * 19.4073 + 0.01 * -0.1859\n",
      "-----------------\n",
      "Finished episode: 151 Reward: -911.9719 total_loss = 8.2437 = -0.0472 + 0.5 * 16.5856 + 0.01 * -0.1860\n",
      "-----------------\n",
      "Finished episode: 152 Reward: -850.8953 total_loss = 9.1693 = 0.0093 + 0.5 * 18.3238 + 0.01 * -0.1873\n",
      "-----------------\n",
      "Finished episode: 153 Reward: -944.2455 total_loss = 9.9804 = -0.0861 + 0.5 * 20.1367 + 0.01 * -0.1865\n",
      "-----------------\n",
      "Finished episode: 154 Reward: -957.9517 total_loss = 9.2200 = 0.0344 + 0.5 * 18.3750 + 0.01 * -0.1850\n",
      "-----------------\n",
      "Finished episode: 155 Reward: -943.5956 total_loss = 8.7426 = 0.0234 + 0.5 * 17.4422 + 0.01 * -0.1851\n",
      "-----------------\n",
      "Finished episode: 156 Reward: -878.0980 total_loss = 8.3890 = -0.0050 + 0.5 * 16.7916 + 0.01 * -0.1854\n",
      "-----------------\n",
      "Finished episode: 157 Reward: -921.4074 total_loss = 8.9500 = -0.0252 + 0.5 * 17.9540 + 0.01 * -0.1869\n",
      "-----------------\n",
      "Finished episode: 158 Reward: -1007.6638 total_loss = 8.5997 = 0.0059 + 0.5 * 17.1913 + 0.01 * -0.1859\n",
      "-----------------\n",
      "Finished episode: 159 Reward: -944.2755 total_loss = 9.6086 = 0.0766 + 0.5 * 19.0677 + 0.01 * -0.1855\n",
      "-----------------\n",
      "Finished episode: 160 Reward: -1000.2907 total_loss = 11.8188 = 0.0007 + 0.5 * 23.6398 + 0.01 * -0.1841\n",
      "-----------------\n",
      "Finished episode: 161 Reward: -1016.5108 total_loss = 10.8205 = 0.0473 + 0.5 * 21.5502 + 0.01 * -0.1841\n",
      "-----------------\n",
      "Finished episode: 162 Reward: -1003.7405 total_loss = 7.9970 = 0.0368 + 0.5 * 15.9242 + 0.01 * -0.1847\n",
      "-----------------\n",
      "Finished episode: 163 Reward: -1003.6439 total_loss = 9.0922 = -0.0532 + 0.5 * 18.2946 + 0.01 * -0.1874\n",
      "-----------------\n",
      "Finished episode: 164 Reward: -1088.9244 total_loss = 6.8356 = 0.0060 + 0.5 * 13.6629 + 0.01 * -0.1883\n",
      "-----------------\n",
      "Finished episode: 165 Reward: -981.4026 total_loss = 9.6276 = 0.0228 + 0.5 * 19.2134 + 0.01 * -0.1868\n",
      "-----------------\n",
      "Finished episode: 166 Reward: -943.4746 total_loss = 9.9457 = 0.0496 + 0.5 * 19.7959 + 0.01 * -0.1861\n",
      "-----------------\n",
      "Finished episode: 167 Reward: -958.3337 total_loss = 8.6998 = -0.0047 + 0.5 * 17.4128 + 0.01 * -0.1856\n",
      "-----------------\n",
      "Finished episode: 168 Reward: -933.8582 total_loss = 7.5520 = -0.0659 + 0.5 * 15.2395 + 0.01 * -0.1868\n",
      "-----------------\n",
      "Finished episode: 169 Reward: -876.5003 total_loss = 8.4661 = -0.0520 + 0.5 * 17.0398 + 0.01 * -0.1867\n",
      "-----------------\n",
      "Finished episode: 170 Reward: -896.7588 total_loss = 9.4898 = -0.0552 + 0.5 * 19.0937 + 0.01 * -0.1869\n",
      "-----------------\n",
      "Finished episode: 171 Reward: -935.8401 total_loss = 11.5087 = 0.0443 + 0.5 * 22.9325 + 0.01 * -0.1856\n",
      "-----------------\n",
      "Finished episode: 172 Reward: -1009.2668 total_loss = 9.4464 = -0.0282 + 0.5 * 18.9528 + 0.01 * -0.1844\n",
      "-----------------\n",
      "Finished episode: 173 Reward: -922.9010 total_loss = 7.1508 = -0.0744 + 0.5 * 14.4540 + 0.01 * -0.1852\n",
      "-----------------\n",
      "Finished episode: 174 Reward: -946.9164 total_loss = 10.1843 = -0.0908 + 0.5 * 20.5539 + 0.01 * -0.1857\n",
      "-----------------\n",
      "Finished episode: 175 Reward: -907.4085 total_loss = 8.5721 = -0.0829 + 0.5 * 17.3138 + 0.01 * -0.1847\n",
      "-----------------\n",
      "Finished episode: 176 Reward: -899.5845 total_loss = 6.9193 = -0.0562 + 0.5 * 13.9547 + 0.01 * -0.1861\n",
      "-----------------\n",
      "Finished episode: 177 Reward: -863.9664 total_loss = 8.3822 = -0.0652 + 0.5 * 16.8986 + 0.01 * -0.1863\n",
      "-----------------\n",
      "Finished episode: 178 Reward: -976.4851 total_loss = 11.4983 = 0.0120 + 0.5 * 22.9762 + 0.01 * -0.1861\n",
      "-----------------\n",
      "Finished episode: 179 Reward: -854.2327 total_loss = 8.8761 = 0.0192 + 0.5 * 17.7176 + 0.01 * -0.1867\n",
      "-----------------\n",
      "Finished episode: 180 Reward: -916.6840 total_loss = 8.7505 = 0.0358 + 0.5 * 17.4331 + 0.01 * -0.1864\n",
      "-----------------\n",
      "Finished episode: 181 Reward: -972.0790 total_loss = 8.3186 = -0.1414 + 0.5 * 16.9238 + 0.01 * -0.1865\n",
      "-----------------\n",
      "Finished episode: 182 Reward: -899.8264 total_loss = 7.9757 = -0.0787 + 0.5 * 16.1125 + 0.01 * -0.1868\n",
      "-----------------\n",
      "Finished episode: 183 Reward: -967.4416 total_loss = 7.5636 = -0.0681 + 0.5 * 15.2672 + 0.01 * -0.1872\n",
      "-----------------\n",
      "Finished episode: 184 Reward: -987.1452 total_loss = 11.6259 = 0.0350 + 0.5 * 23.1855 + 0.01 * -0.1859\n",
      "-----------------\n",
      "Finished episode: 185 Reward: -903.6382 total_loss = 9.6796 = 0.0888 + 0.5 * 19.1853 + 0.01 * -0.1851\n",
      "-----------------\n",
      "Finished episode: 186 Reward: -872.2712 total_loss = 9.1180 = -0.0623 + 0.5 * 18.3643 + 0.01 * -0.1867\n",
      "-----------------\n",
      "Finished episode: 187 Reward: -1025.0992 total_loss = 10.4044 = -0.1009 + 0.5 * 21.0144 + 0.01 * -0.1856\n",
      "-----------------\n",
      "Finished episode: 188 Reward: -972.9195 total_loss = 8.4377 = 0.0265 + 0.5 * 16.8262 + 0.01 * -0.1878\n",
      "-----------------\n",
      "Finished episode: 189 Reward: -903.7142 total_loss = 9.0977 = -0.0667 + 0.5 * 18.3326 + 0.01 * -0.1868\n",
      "-----------------\n",
      "Finished episode: 190 Reward: -1016.3056 total_loss = 9.0561 = -0.0191 + 0.5 * 18.1541 + 0.01 * -0.1888\n",
      "-----------------\n",
      "Finished episode: 191 Reward: -928.9998 total_loss = 9.2859 = 0.0445 + 0.5 * 18.4866 + 0.01 * -0.1882\n",
      "-----------------\n",
      "Finished episode: 192 Reward: -927.9323 total_loss = 10.3636 = -0.0302 + 0.5 * 20.7913 + 0.01 * -0.1884\n",
      "-----------------\n",
      "Finished episode: 193 Reward: -1034.8489 total_loss = 11.8370 = -0.0800 + 0.5 * 23.8376 + 0.01 * -0.1881\n",
      "-----------------\n",
      "Finished episode: 194 Reward: -1027.9762 total_loss = 13.3588 = 0.1024 + 0.5 * 26.5166 + 0.01 * -0.1878\n",
      "-----------------\n",
      "Finished episode: 195 Reward: -940.6987 total_loss = 9.2872 = 0.0379 + 0.5 * 18.5023 + 0.01 * -0.1875\n",
      "-----------------\n",
      "Finished episode: 196 Reward: -941.7198 total_loss = 8.4477 = -0.1062 + 0.5 * 17.1117 + 0.01 * -0.1894\n",
      "-----------------\n",
      "Finished episode: 197 Reward: -921.9817 total_loss = 8.5850 = -0.0378 + 0.5 * 17.2494 + 0.01 * -0.1882\n",
      "-----------------\n",
      "Finished episode: 198 Reward: -931.2893 total_loss = 8.7389 = -0.0808 + 0.5 * 17.6431 + 0.01 * -0.1885\n",
      "-----------------\n",
      "Finished episode: 199 Reward: -915.1351 total_loss = 10.7582 = -0.0320 + 0.5 * 21.5842 + 0.01 * -0.1873\n",
      "-----------------\n",
      "Finished episode: 200 Reward: -913.5160 total_loss = 7.8102 = -0.0256 + 0.5 * 15.6754 + 0.01 * -0.1870\n",
      "-----------------\n",
      "Finished episode: 201 Reward: -987.9794 total_loss = 9.1682 = -0.0675 + 0.5 * 18.4751 + 0.01 * -0.1901\n",
      "-----------------\n",
      "Finished episode: 202 Reward: -916.4582 total_loss = 7.6922 = -0.0159 + 0.5 * 15.4200 + 0.01 * -0.1901\n",
      "-----------------\n",
      "Finished episode: 203 Reward: -1035.5959 total_loss = 9.2503 = 0.0159 + 0.5 * 18.4726 + 0.01 * -0.1888\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 204 Reward: -896.4065 total_loss = 8.1309 = -0.0135 + 0.5 * 16.2928 + 0.01 * -0.1915\n",
      "-----------------\n",
      "Finished episode: 205 Reward: -954.1396 total_loss = 7.7445 = -0.1366 + 0.5 * 15.7661 + 0.01 * -0.1911\n",
      "-----------------\n",
      "Finished episode: 206 Reward: -861.1821 total_loss = 7.1186 = -0.0797 + 0.5 * 14.4003 + 0.01 * -0.1908\n",
      "-----------------\n",
      "Finished episode: 207 Reward: -971.0786 total_loss = 10.1148 = -0.0259 + 0.5 * 20.2852 + 0.01 * -0.1908\n",
      "-----------------\n",
      "Finished episode: 208 Reward: -946.7436 total_loss = 10.0227 = 0.0618 + 0.5 * 19.9256 + 0.01 * -0.1875\n",
      "-----------------\n",
      "Finished episode: 209 Reward: -922.4291 total_loss = 9.4122 = 0.0554 + 0.5 * 18.7173 + 0.01 * -0.1881\n",
      "-----------------\n",
      "Finished episode: 210 Reward: -1016.3100 total_loss = 11.2599 = -0.0344 + 0.5 * 22.5923 + 0.01 * -0.1886\n",
      "-----------------\n",
      "Finished episode: 211 Reward: -867.2027 total_loss = 6.9718 = 0.0042 + 0.5 * 13.9391 + 0.01 * -0.1886\n",
      "-----------------\n",
      "Finished episode: 212 Reward: -885.0831 total_loss = 7.4380 = 0.0777 + 0.5 * 14.7243 + 0.01 * -0.1890\n",
      "-----------------\n",
      "Finished episode: 213 Reward: -887.7450 total_loss = 8.8044 = 0.0875 + 0.5 * 17.4377 + 0.01 * -0.1889\n",
      "-----------------\n",
      "Finished episode: 214 Reward: -921.0459 total_loss = 8.6813 = 0.0216 + 0.5 * 17.3232 + 0.01 * -0.1892\n",
      "-----------------\n",
      "Finished episode: 215 Reward: -993.5092 total_loss = 8.1890 = 0.1545 + 0.5 * 16.0728 + 0.01 * -0.1902\n",
      "-----------------\n",
      "Finished episode: 216 Reward: -919.1053 total_loss = 9.1012 = -0.0956 + 0.5 * 18.3973 + 0.01 * -0.1897\n",
      "-----------------\n",
      "Finished episode: 217 Reward: -869.2894 total_loss = 9.9771 = -0.0137 + 0.5 * 19.9854 + 0.01 * -0.1905\n",
      "-----------------\n",
      "Finished episode: 218 Reward: -876.9234 total_loss = 9.3800 = 0.0460 + 0.5 * 18.6718 + 0.01 * -0.1902\n",
      "-----------------\n",
      "Finished episode: 219 Reward: -843.8672 total_loss = 9.0658 = 0.0783 + 0.5 * 17.9787 + 0.01 * -0.1930\n",
      "-----------------\n",
      "Finished episode: 220 Reward: -910.3444 total_loss = 7.4356 = 0.0962 + 0.5 * 14.6828 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 221 Reward: -864.2923 total_loss = 8.5411 = 0.0101 + 0.5 * 17.0660 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 222 Reward: -867.8076 total_loss = 9.0951 = -0.0045 + 0.5 * 18.2030 + 0.01 * -0.1934\n",
      "-----------------\n",
      "Finished episode: 223 Reward: -849.2635 total_loss = 6.6113 = -0.0146 + 0.5 * 13.2556 + 0.01 * -0.1949\n",
      "-----------------\n",
      "Finished episode: 224 Reward: -971.3509 total_loss = 9.4591 = 0.0614 + 0.5 * 18.7993 + 0.01 * -0.1951\n",
      "-----------------\n",
      "Finished episode: 225 Reward: -946.6000 total_loss = 9.5737 = 0.0334 + 0.5 * 19.0844 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 226 Reward: -868.4810 total_loss = 6.9380 = -0.0199 + 0.5 * 13.9196 + 0.01 * -0.1952\n",
      "-----------------\n",
      "Finished episode: 227 Reward: -969.3714 total_loss = 11.1132 = 0.0254 + 0.5 * 22.1793 + 0.01 * -0.1901\n",
      "-----------------\n",
      "Finished episode: 228 Reward: -929.7930 total_loss = 8.2953 = 0.0736 + 0.5 * 16.4471 + 0.01 * -0.1917\n",
      "-----------------\n",
      "Finished episode: 229 Reward: -1001.9676 total_loss = 8.6497 = -0.0342 + 0.5 * 17.3716 + 0.01 * -0.1926\n",
      "-----------------\n",
      "Finished episode: 230 Reward: -929.2440 total_loss = 9.3760 = -0.0224 + 0.5 * 18.8006 + 0.01 * -0.1909\n",
      "-----------------\n",
      "Finished episode: 231 Reward: -875.8708 total_loss = 9.2362 = 0.0973 + 0.5 * 18.2816 + 0.01 * -0.1915\n",
      "-----------------\n",
      "Finished episode: 232 Reward: -967.1610 total_loss = 12.5079 = 0.0606 + 0.5 * 24.8984 + 0.01 * -0.1906\n",
      "-----------------\n",
      "Finished episode: 233 Reward: -941.4108 total_loss = 7.4837 = 0.0171 + 0.5 * 14.9372 + 0.01 * -0.1953\n",
      "-----------------\n",
      "Finished episode: 234 Reward: -881.7494 total_loss = 9.0437 = -0.0386 + 0.5 * 18.1685 + 0.01 * -0.1932\n",
      "-----------------\n",
      "Finished episode: 235 Reward: -889.4162 total_loss = 8.0220 = -0.0692 + 0.5 * 16.1864 + 0.01 * -0.1941\n",
      "-----------------\n",
      "Finished episode: 236 Reward: -888.3196 total_loss = 7.4377 = 0.0253 + 0.5 * 14.8288 + 0.01 * -0.1963\n",
      "-----------------\n",
      "Finished episode: 237 Reward: -916.2299 total_loss = 7.3769 = -0.0440 + 0.5 * 14.8458 + 0.01 * -0.1948\n",
      "-----------------\n",
      "Finished episode: 238 Reward: -843.9910 total_loss = 7.9139 = -0.0959 + 0.5 * 16.0235 + 0.01 * -0.1933\n",
      "-----------------\n",
      "Finished episode: 239 Reward: -889.4367 total_loss = 8.2833 = 0.0637 + 0.5 * 16.4431 + 0.01 * -0.1960\n",
      "-----------------\n",
      "Finished episode: 240 Reward: -847.2156 total_loss = 8.1164 = -0.0729 + 0.5 * 16.3826 + 0.01 * -0.1975\n",
      "-----------------\n",
      "Finished episode: 241 Reward: -813.1555 total_loss = 8.4627 = 0.0499 + 0.5 * 16.8296 + 0.01 * -0.1969\n",
      "-----------------\n",
      "Finished episode: 242 Reward: -906.4411 total_loss = 9.0659 = -0.0474 + 0.5 * 18.2306 + 0.01 * -0.1973\n",
      "-----------------\n",
      "Finished episode: 243 Reward: -833.3654 total_loss = 8.4865 = 0.0541 + 0.5 * 16.8686 + 0.01 * -0.1949\n",
      "-----------------\n",
      "Finished episode: 244 Reward: -879.8044 total_loss = 10.8824 = -0.0714 + 0.5 * 21.9116 + 0.01 * -0.1948\n",
      "-----------------\n",
      "Finished episode: 245 Reward: -938.8606 total_loss = 8.2004 = 0.0093 + 0.5 * 16.3862 + 0.01 * -0.1967\n",
      "-----------------\n",
      "Finished episode: 246 Reward: -892.3755 total_loss = 7.2204 = -0.0071 + 0.5 * 14.4590 + 0.01 * -0.1964\n",
      "-----------------\n",
      "Finished episode: 247 Reward: -821.4248 total_loss = 8.6737 = 0.0453 + 0.5 * 17.2607 + 0.01 * -0.1981\n",
      "-----------------\n",
      "Finished episode: 248 Reward: -885.2108 total_loss = 7.4383 = -0.0796 + 0.5 * 15.0398 + 0.01 * -0.1983\n",
      "-----------------\n",
      "Finished episode: 249 Reward: -903.3489 total_loss = 9.2351 = -0.0297 + 0.5 * 18.5334 + 0.01 * -0.1971\n",
      "-----------------\n",
      "Finished episode: 250 Reward: -936.8616 total_loss = 6.8924 = 0.1126 + 0.5 * 13.5637 + 0.01 * -0.1974\n",
      "-----------------\n",
      "Finished episode: 251 Reward: -868.3387 total_loss = 9.0952 = 0.0367 + 0.5 * 18.1210 + 0.01 * -0.1993\n",
      "-----------------\n",
      "Finished episode: 252 Reward: -865.2160 total_loss = 9.4441 = 0.0418 + 0.5 * 18.8086 + 0.01 * -0.1977\n",
      "-----------------\n",
      "Finished episode: 253 Reward: -844.2786 total_loss = 7.9990 = 0.0089 + 0.5 * 15.9843 + 0.01 * -0.1978\n",
      "-----------------\n",
      "Finished episode: 254 Reward: -870.9960 total_loss = 8.3206 = 0.0588 + 0.5 * 16.5275 + 0.01 * -0.1974\n",
      "-----------------\n",
      "Finished episode: 255 Reward: -917.6899 total_loss = 9.3136 = -0.0249 + 0.5 * 18.6810 + 0.01 * -0.1988\n",
      "-----------------\n",
      "Finished episode: 256 Reward: -794.7970 total_loss = 8.6942 = -0.0460 + 0.5 * 17.4844 + 0.01 * -0.1983\n",
      "-----------------\n",
      "Finished episode: 257 Reward: -1030.7156 total_loss = 10.2829 = 0.1021 + 0.5 * 20.3656 + 0.01 * -0.1974\n",
      "-----------------\n",
      "Finished episode: 258 Reward: -985.0555 total_loss = 11.7960 = -0.0161 + 0.5 * 23.6281 + 0.01 * -0.1951\n",
      "-----------------\n",
      "Finished episode: 259 Reward: -1041.7308 total_loss = 12.9179 = 0.0469 + 0.5 * 25.7459 + 0.01 * -0.1915\n",
      "-----------------\n",
      "Finished episode: 260 Reward: -1055.8853 total_loss = 10.8305 = 0.0290 + 0.5 * 21.6067 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 261 Reward: -1031.6530 total_loss = 12.0768 = 0.0362 + 0.5 * 24.0850 + 0.01 * -0.1896\n",
      "-----------------\n",
      "Finished episode: 262 Reward: -968.5377 total_loss = 13.1754 = -0.0251 + 0.5 * 26.4050 + 0.01 * -0.1899\n",
      "-----------------\n",
      "Finished episode: 263 Reward: -1051.5053 total_loss = 9.9300 = -0.1118 + 0.5 * 20.0875 + 0.01 * -0.1890\n",
      "-----------------\n",
      "Finished episode: 264 Reward: -1013.3111 total_loss = 11.5274 = -0.0411 + 0.5 * 23.1406 + 0.01 * -0.1878\n",
      "-----------------\n",
      "Finished episode: 265 Reward: -1021.4917 total_loss = 11.2969 = 0.0995 + 0.5 * 22.3985 + 0.01 * -0.1849\n",
      "-----------------\n",
      "Finished episode: 266 Reward: -1005.8415 total_loss = 12.1265 = -0.0629 + 0.5 * 24.3826 + 0.01 * -0.1840\n",
      "-----------------\n",
      "Finished episode: 267 Reward: -1023.8760 total_loss = 13.1956 = -0.0819 + 0.5 * 26.5588 + 0.01 * -0.1830\n",
      "-----------------\n",
      "Finished episode: 268 Reward: -964.0080 total_loss = 10.1465 = -0.0593 + 0.5 * 20.4151 + 0.01 * -0.1835\n",
      "-----------------\n",
      "Finished episode: 269 Reward: -942.9918 total_loss = 10.0602 = -0.0197 + 0.5 * 20.1635 + 0.01 * -0.1847\n",
      "-----------------\n",
      "Finished episode: 270 Reward: -989.7352 total_loss = 9.3949 = 0.0144 + 0.5 * 18.7646 + 0.01 * -0.1835\n",
      "-----------------\n",
      "Finished episode: 271 Reward: -1028.4028 total_loss = 12.7584 = -0.1055 + 0.5 * 25.7315 + 0.01 * -0.1839\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 272 Reward: -1015.7239 total_loss = 8.4888 = -0.0082 + 0.5 * 16.9976 + 0.01 * -0.1844\n",
      "-----------------\n",
      "Finished episode: 273 Reward: -956.1271 total_loss = 9.1517 = -0.0448 + 0.5 * 18.3965 + 0.01 * -0.1845\n",
      "-----------------\n",
      "Finished episode: 274 Reward: -1015.6025 total_loss = 7.4000 = 0.0530 + 0.5 * 14.6977 + 0.01 * -0.1862\n",
      "-----------------\n",
      "Finished episode: 275 Reward: -897.0848 total_loss = 10.8582 = -0.0636 + 0.5 * 21.8474 + 0.01 * -0.1851\n",
      "-----------------\n",
      "Finished episode: 276 Reward: -903.1894 total_loss = 7.4659 = -0.2128 + 0.5 * 15.3611 + 0.01 * -0.1855\n",
      "-----------------\n",
      "Finished episode: 277 Reward: -1006.9353 total_loss = 10.3226 = -0.0109 + 0.5 * 20.6707 + 0.01 * -0.1862\n",
      "-----------------\n",
      "Finished episode: 278 Reward: -953.6732 total_loss = 10.8808 = -0.1012 + 0.5 * 21.9677 + 0.01 * -0.1870\n",
      "-----------------\n",
      "Finished episode: 279 Reward: -1026.0048 total_loss = 10.0250 = -0.1375 + 0.5 * 20.3288 + 0.01 * -0.1869\n",
      "-----------------\n",
      "Finished episode: 280 Reward: -936.0183 total_loss = 11.0532 = -0.1411 + 0.5 * 22.3925 + 0.01 * -0.1885\n",
      "-----------------\n",
      "Finished episode: 281 Reward: -931.1476 total_loss = 9.4962 = -0.1086 + 0.5 * 19.2133 + 0.01 * -0.1898\n",
      "-----------------\n",
      "Finished episode: 282 Reward: -864.1557 total_loss = 8.2416 = 0.0069 + 0.5 * 16.4731 + 0.01 * -0.1895\n",
      "-----------------\n",
      "Finished episode: 283 Reward: -895.1989 total_loss = 7.6283 = 0.0066 + 0.5 * 15.2471 + 0.01 * -0.1915\n",
      "-----------------\n",
      "Finished episode: 284 Reward: -993.1527 total_loss = 12.6047 = -0.0365 + 0.5 * 25.2863 + 0.01 * -0.1898\n",
      "-----------------\n",
      "Finished episode: 285 Reward: -847.4948 total_loss = 8.2682 = 0.0167 + 0.5 * 16.5068 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 286 Reward: -1012.5513 total_loss = 9.0719 = -0.0900 + 0.5 * 18.3276 + 0.01 * -0.1905\n",
      "-----------------\n",
      "Finished episode: 287 Reward: -933.0755 total_loss = 7.2924 = -0.0107 + 0.5 * 14.6101 + 0.01 * -0.1911\n",
      "-----------------\n",
      "Finished episode: 288 Reward: -934.0071 total_loss = 10.9972 = -0.0018 + 0.5 * 22.0019 + 0.01 * -0.1916\n",
      "-----------------\n",
      "Finished episode: 289 Reward: -922.2105 total_loss = 9.1028 = -0.0903 + 0.5 * 18.3901 + 0.01 * -0.1911\n",
      "-----------------\n",
      "Finished episode: 290 Reward: -892.3228 total_loss = 9.1287 = 0.0353 + 0.5 * 18.1905 + 0.01 * -0.1914\n",
      "-----------------\n",
      "Finished episode: 291 Reward: -927.7073 total_loss = 6.7155 = -0.0726 + 0.5 * 13.5799 + 0.01 * -0.1928\n",
      "-----------------\n",
      "Finished episode: 292 Reward: -903.6408 total_loss = 10.2251 = 0.0213 + 0.5 * 20.4115 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 293 Reward: -874.5761 total_loss = 8.7506 = 0.0370 + 0.5 * 17.4310 + 0.01 * -0.1905\n",
      "-----------------\n",
      "Finished episode: 294 Reward: -888.2081 total_loss = 8.0231 = -0.1230 + 0.5 * 16.2961 + 0.01 * -0.1921\n",
      "-----------------\n",
      "Finished episode: 295 Reward: -885.4908 total_loss = 7.0486 = 0.0575 + 0.5 * 13.9860 + 0.01 * -0.1917\n",
      "-----------------\n",
      "Finished episode: 296 Reward: -827.1577 total_loss = 9.4201 = 0.0342 + 0.5 * 18.7756 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 297 Reward: -889.9213 total_loss = 8.8573 = 0.0849 + 0.5 * 17.5487 + 0.01 * -0.1927\n",
      "-----------------\n",
      "Finished episode: 298 Reward: -880.1020 total_loss = 6.8574 = 0.0959 + 0.5 * 13.5269 + 0.01 * -0.1917\n",
      "-----------------\n",
      "Finished episode: 299 Reward: -938.4770 total_loss = 8.0330 = 0.0072 + 0.5 * 16.0554 + 0.01 * -0.1908\n",
      "-----------------\n",
      "Finished episode: 300 Reward: -966.0621 total_loss = 9.5050 = 0.0612 + 0.5 * 18.8914 + 0.01 * -0.1897\n",
      "-----------------\n",
      "Finished episode: 301 Reward: -869.6042 total_loss = 8.5659 = 0.0190 + 0.5 * 17.0975 + 0.01 * -0.1914\n",
      "-----------------\n",
      "Finished episode: 302 Reward: -862.0972 total_loss = 8.2996 = 0.0314 + 0.5 * 16.5402 + 0.01 * -0.1925\n",
      "-----------------\n",
      "Finished episode: 303 Reward: -947.3302 total_loss = 7.1498 = 0.0670 + 0.5 * 14.1694 + 0.01 * -0.1902\n",
      "-----------------\n",
      "Finished episode: 304 Reward: -792.7757 total_loss = 8.6012 = -0.0671 + 0.5 * 17.3406 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 305 Reward: -844.3228 total_loss = 6.3175 = 0.0172 + 0.5 * 12.6044 + 0.01 * -0.1932\n",
      "-----------------\n",
      "Finished episode: 306 Reward: -855.7669 total_loss = 8.2849 = 0.0871 + 0.5 * 16.3994 + 0.01 * -0.1931\n",
      "-----------------\n",
      "Finished episode: 307 Reward: -952.7367 total_loss = 8.6662 = 0.0551 + 0.5 * 17.2260 + 0.01 * -0.1927\n",
      "-----------------\n",
      "Finished episode: 308 Reward: -923.1853 total_loss = 9.1526 = 0.0519 + 0.5 * 18.2052 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 309 Reward: -918.1457 total_loss = 7.7653 = -0.0041 + 0.5 * 15.5427 + 0.01 * -0.1913\n",
      "-----------------\n",
      "Finished episode: 310 Reward: -941.7627 total_loss = 10.4284 = 0.0204 + 0.5 * 20.8199 + 0.01 * -0.1927\n",
      "-----------------\n",
      "Finished episode: 311 Reward: -919.4703 total_loss = 8.0156 = 0.0464 + 0.5 * 15.9423 + 0.01 * -0.1936\n",
      "-----------------\n",
      "Finished episode: 312 Reward: -911.5717 total_loss = 6.5755 = -0.2547 + 0.5 * 13.6642 + 0.01 * -0.1954\n",
      "-----------------\n",
      "Finished episode: 313 Reward: -900.4946 total_loss = 9.1643 = -0.0764 + 0.5 * 18.4853 + 0.01 * -0.1930\n",
      "-----------------\n",
      "Finished episode: 314 Reward: -954.5302 total_loss = 6.8025 = 0.0093 + 0.5 * 13.5903 + 0.01 * -0.1956\n",
      "-----------------\n",
      "Finished episode: 315 Reward: -968.1116 total_loss = 9.6888 = 0.0546 + 0.5 * 19.2722 + 0.01 * -0.1926\n",
      "-----------------\n",
      "Finished episode: 316 Reward: -870.5115 total_loss = 8.3355 = -0.0382 + 0.5 * 16.7513 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 317 Reward: -986.3354 total_loss = 10.8048 = 0.0314 + 0.5 * 21.5505 + 0.01 * -0.1945\n",
      "-----------------\n",
      "Finished episode: 318 Reward: -1024.5744 total_loss = 11.6011 = -0.0026 + 0.5 * 23.2112 + 0.01 * -0.1919\n",
      "-----------------\n",
      "Finished episode: 319 Reward: -934.3334 total_loss = 8.1585 = -0.0674 + 0.5 * 16.4557 + 0.01 * -0.1942\n",
      "-----------------\n",
      "Finished episode: 320 Reward: -978.7155 total_loss = 8.4797 = 0.0390 + 0.5 * 16.8854 + 0.01 * -0.1945\n",
      "-----------------\n",
      "Finished episode: 321 Reward: -934.5991 total_loss = 8.8848 = 0.1875 + 0.5 * 17.3985 + 0.01 * -0.1941\n",
      "-----------------\n",
      "Finished episode: 322 Reward: -853.8252 total_loss = 9.3402 = 0.0214 + 0.5 * 18.6415 + 0.01 * -0.1963\n",
      "-----------------\n",
      "Finished episode: 323 Reward: -881.6472 total_loss = 8.6764 = 0.0468 + 0.5 * 17.2631 + 0.01 * -0.1956\n",
      "-----------------\n",
      "Finished episode: 324 Reward: -1005.3894 total_loss = 10.9411 = 0.0290 + 0.5 * 21.8281 + 0.01 * -0.1938\n",
      "-----------------\n",
      "Finished episode: 325 Reward: -857.0467 total_loss = 8.5279 = -0.0101 + 0.5 * 17.0800 + 0.01 * -0.1956\n",
      "-----------------\n",
      "Finished episode: 326 Reward: -863.0223 total_loss = 9.0633 = -0.0380 + 0.5 * 18.2066 + 0.01 * -0.1981\n",
      "-----------------\n",
      "Finished episode: 327 Reward: -849.3877 total_loss = 7.2878 = -0.0339 + 0.5 * 14.6474 + 0.01 * -0.1970\n",
      "-----------------\n",
      "Finished episode: 328 Reward: -901.6770 total_loss = 9.8207 = -0.0656 + 0.5 * 19.7765 + 0.01 * -0.1951\n",
      "-----------------\n",
      "Finished episode: 329 Reward: -856.5629 total_loss = 10.0164 = 0.0468 + 0.5 * 19.9431 + 0.01 * -0.1961\n",
      "-----------------\n",
      "Finished episode: 330 Reward: -889.0535 total_loss = 8.2131 = -0.0626 + 0.5 * 16.5553 + 0.01 * -0.1957\n",
      "-----------------\n",
      "Finished episode: 331 Reward: -835.4564 total_loss = 10.1180 = -0.0305 + 0.5 * 20.3009 + 0.01 * -0.1965\n",
      "-----------------\n",
      "Finished episode: 332 Reward: -846.0950 total_loss = 8.3098 = -0.0768 + 0.5 * 16.7772 + 0.01 * -0.1976\n",
      "-----------------\n",
      "Finished episode: 333 Reward: -915.9513 total_loss = 7.9282 = -0.0452 + 0.5 * 15.9507 + 0.01 * -0.1966\n",
      "-----------------\n",
      "Finished episode: 334 Reward: -848.8965 total_loss = 8.4080 = -0.0825 + 0.5 * 16.9849 + 0.01 * -0.1964\n",
      "-----------------\n",
      "Finished episode: 335 Reward: -884.1554 total_loss = 9.0639 = -0.0365 + 0.5 * 18.2047 + 0.01 * -0.1988\n",
      "-----------------\n",
      "Finished episode: 336 Reward: -904.2955 total_loss = 7.4121 = -0.1628 + 0.5 * 15.1538 + 0.01 * -0.1990\n",
      "-----------------\n",
      "Finished episode: 337 Reward: -838.6278 total_loss = 9.2015 = -0.0063 + 0.5 * 18.4197 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 338 Reward: -905.3980 total_loss = 9.1429 = -0.0309 + 0.5 * 18.3517 + 0.01 * -0.1990\n",
      "-----------------\n",
      "Finished episode: 339 Reward: -894.1009 total_loss = 8.6967 = 0.1043 + 0.5 * 17.1889 + 0.01 * -0.2011\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 340 Reward: -783.7957 total_loss = 9.4085 = 0.0301 + 0.5 * 18.7607 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 341 Reward: -832.1103 total_loss = 7.9940 = 0.0150 + 0.5 * 15.9621 + 0.01 * -0.2024\n",
      "-----------------\n",
      "Finished episode: 342 Reward: -864.1712 total_loss = 9.1385 = -0.0234 + 0.5 * 18.3279 + 0.01 * -0.2027\n",
      "-----------------\n",
      "Finished episode: 343 Reward: -1008.2935 total_loss = 8.3201 = -0.0133 + 0.5 * 16.6709 + 0.01 * -0.2002\n",
      "-----------------\n",
      "Finished episode: 344 Reward: -835.3605 total_loss = 9.2674 = 0.0519 + 0.5 * 18.4351 + 0.01 * -0.2023\n",
      "-----------------\n",
      "Finished episode: 345 Reward: -930.5178 total_loss = 8.0626 = -0.0161 + 0.5 * 16.1615 + 0.01 * -0.2035\n",
      "-----------------\n",
      "Finished episode: 346 Reward: -877.6673 total_loss = 8.9137 = 0.0421 + 0.5 * 17.7473 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 347 Reward: -892.3168 total_loss = 8.4255 = -0.0019 + 0.5 * 16.8590 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 348 Reward: -886.5162 total_loss = 8.9432 = 0.0329 + 0.5 * 17.8247 + 0.01 * -0.2013\n",
      "-----------------\n",
      "Finished episode: 349 Reward: -835.5087 total_loss = 7.5937 = -0.0114 + 0.5 * 15.2143 + 0.01 * -0.2022\n",
      "-----------------\n",
      "Finished episode: 350 Reward: -865.5143 total_loss = 7.0255 = -0.0330 + 0.5 * 14.1211 + 0.01 * -0.2031\n",
      "-----------------\n",
      "Finished episode: 351 Reward: -923.0789 total_loss = 10.1317 = 0.0145 + 0.5 * 20.2385 + 0.01 * -0.2025\n",
      "-----------------\n",
      "Finished episode: 352 Reward: -895.7972 total_loss = 7.9984 = 0.0709 + 0.5 * 15.8589 + 0.01 * -0.2022\n",
      "-----------------\n",
      "Finished episode: 353 Reward: -887.0717 total_loss = 8.9060 = -0.0072 + 0.5 * 17.8305 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 354 Reward: -847.7697 total_loss = 9.5353 = -0.0042 + 0.5 * 19.0832 + 0.01 * -0.2016\n",
      "-----------------\n",
      "Finished episode: 355 Reward: -850.9028 total_loss = 7.9096 = -0.0391 + 0.5 * 15.9014 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 356 Reward: -896.6505 total_loss = 6.6429 = 0.0241 + 0.5 * 13.2418 + 0.01 * -0.2012\n",
      "-----------------\n",
      "Finished episode: 357 Reward: -892.7709 total_loss = 8.0654 = 0.0272 + 0.5 * 16.0804 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 358 Reward: -957.9408 total_loss = 7.6307 = -0.0487 + 0.5 * 15.3628 + 0.01 * -0.1997\n",
      "-----------------\n",
      "Finished episode: 359 Reward: -981.1097 total_loss = 9.7284 = 0.0071 + 0.5 * 19.4467 + 0.01 * -0.2002\n",
      "-----------------\n",
      "Finished episode: 360 Reward: -849.9760 total_loss = 10.0337 = 0.0433 + 0.5 * 19.9849 + 0.01 * -0.2018\n",
      "-----------------\n",
      "Finished episode: 361 Reward: -917.3276 total_loss = 8.7009 = -0.0135 + 0.5 * 17.4328 + 0.01 * -0.2020\n",
      "-----------------\n",
      "Finished episode: 362 Reward: -1028.9579 total_loss = 9.6149 = -0.0255 + 0.5 * 19.2848 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 363 Reward: -963.6617 total_loss = 12.7857 = -0.0199 + 0.5 * 25.6150 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 364 Reward: -888.6807 total_loss = 7.8338 = 0.0012 + 0.5 * 15.6692 + 0.01 * -0.2032\n",
      "-----------------\n",
      "Finished episode: 365 Reward: -932.2756 total_loss = 8.8662 = 0.0578 + 0.5 * 17.6209 + 0.01 * -0.2019\n",
      "-----------------\n",
      "Finished episode: 366 Reward: -853.5782 total_loss = 8.9094 = -0.0438 + 0.5 * 17.9103 + 0.01 * -0.2022\n",
      "-----------------\n",
      "Finished episode: 367 Reward: -972.6823 total_loss = 8.5742 = 0.0064 + 0.5 * 17.1397 + 0.01 * -0.2020\n",
      "-----------------\n",
      "Finished episode: 368 Reward: -889.5607 total_loss = 8.1387 = -0.0421 + 0.5 * 16.3655 + 0.01 * -0.1996\n",
      "-----------------\n",
      "Finished episode: 369 Reward: -835.0084 total_loss = 7.4972 = -0.0441 + 0.5 * 15.0867 + 0.01 * -0.2022\n",
      "-----------------\n",
      "Finished episode: 370 Reward: -897.2354 total_loss = 7.8223 = -0.0826 + 0.5 * 15.8139 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 371 Reward: -880.5671 total_loss = 8.8469 = 0.0227 + 0.5 * 17.6526 + 0.01 * -0.2025\n",
      "-----------------\n",
      "Finished episode: 372 Reward: -926.4389 total_loss = 9.0493 = -0.0868 + 0.5 * 18.2762 + 0.01 * -0.2011\n",
      "-----------------\n",
      "Finished episode: 373 Reward: -872.3282 total_loss = 7.1726 = -0.0069 + 0.5 * 14.3630 + 0.01 * -0.2024\n",
      "-----------------\n",
      "Finished episode: 374 Reward: -861.2429 total_loss = 9.0707 = -0.0183 + 0.5 * 18.1820 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 375 Reward: -841.5395 total_loss = 7.0689 = -0.0561 + 0.5 * 14.2542 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 376 Reward: -861.9172 total_loss = 8.2971 = 0.0636 + 0.5 * 16.4709 + 0.01 * -0.2020\n",
      "-----------------\n",
      "Finished episode: 377 Reward: -799.5395 total_loss = 7.8349 = -0.0232 + 0.5 * 15.7202 + 0.01 * -0.2024\n",
      "-----------------\n",
      "Finished episode: 378 Reward: -906.3836 total_loss = 6.8411 = -0.0024 + 0.5 * 13.6910 + 0.01 * -0.2026\n",
      "-----------------\n",
      "Finished episode: 379 Reward: -887.0380 total_loss = 9.2790 = 0.0606 + 0.5 * 18.4408 + 0.01 * -0.2024\n",
      "-----------------\n",
      "Finished episode: 380 Reward: -906.4117 total_loss = 9.9063 = 0.0469 + 0.5 * 19.7229 + 0.01 * -0.2019\n",
      "-----------------\n",
      "Finished episode: 381 Reward: -859.0489 total_loss = 9.2138 = -0.0544 + 0.5 * 18.5403 + 0.01 * -0.2033\n",
      "-----------------\n",
      "Finished episode: 382 Reward: -908.8822 total_loss = 8.7494 = -0.0302 + 0.5 * 17.5631 + 0.01 * -0.2020\n",
      "-----------------\n",
      "Finished episode: 383 Reward: -862.3355 total_loss = 7.5572 = -0.0379 + 0.5 * 15.1944 + 0.01 * -0.2035\n",
      "-----------------\n",
      "Finished episode: 384 Reward: -861.4780 total_loss = 9.2790 = -0.0431 + 0.5 * 18.6481 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 385 Reward: -945.6011 total_loss = 10.3727 = 0.0254 + 0.5 * 20.6986 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 386 Reward: -955.3278 total_loss = 10.0477 = 0.0402 + 0.5 * 20.0192 + 0.01 * -0.2022\n",
      "-----------------\n",
      "Finished episode: 387 Reward: -982.6283 total_loss = 10.4815 = 0.0662 + 0.5 * 20.8345 + 0.01 * -0.2016\n",
      "-----------------\n",
      "Finished episode: 388 Reward: -917.2043 total_loss = 8.6267 = -0.1453 + 0.5 * 17.5480 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 389 Reward: -895.7782 total_loss = 10.2897 = 0.0092 + 0.5 * 20.5651 + 0.01 * -0.1991\n",
      "-----------------\n",
      "Finished episode: 390 Reward: -905.8961 total_loss = 10.4960 = 0.0529 + 0.5 * 20.8901 + 0.01 * -0.2000\n",
      "-----------------\n",
      "Finished episode: 391 Reward: -922.5857 total_loss = 7.6614 = -0.1200 + 0.5 * 15.5668 + 0.01 * -0.2019\n",
      "-----------------\n",
      "Finished episode: 392 Reward: -913.7278 total_loss = 8.1897 = 0.0170 + 0.5 * 16.3495 + 0.01 * -0.2020\n",
      "-----------------\n",
      "Finished episode: 393 Reward: -837.9407 total_loss = 9.9845 = -0.0224 + 0.5 * 20.0180 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 394 Reward: -873.4886 total_loss = 8.7686 = -0.1373 + 0.5 * 17.8157 + 0.01 * -0.2035\n",
      "-----------------\n",
      "Finished episode: 395 Reward: -889.7099 total_loss = 7.1129 = -0.0548 + 0.5 * 14.3395 + 0.01 * -0.2023\n",
      "-----------------\n",
      "Finished episode: 396 Reward: -899.3741 total_loss = 8.2731 = 0.0496 + 0.5 * 16.4510 + 0.01 * -0.2020\n",
      "-----------------\n",
      "Finished episode: 397 Reward: -895.8004 total_loss = 8.2956 = 0.1573 + 0.5 * 16.2807 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 398 Reward: -899.6586 total_loss = 7.1735 = -0.0610 + 0.5 * 14.4731 + 0.01 * -0.2030\n",
      "-----------------\n",
      "Finished episode: 399 Reward: -963.4011 total_loss = 8.7246 = 0.0513 + 0.5 * 17.3507 + 0.01 * -0.2012\n",
      "-----------------\n",
      "Finished episode: 400 Reward: -890.8113 total_loss = 9.8662 = 0.0607 + 0.5 * 19.6150 + 0.01 * -0.2028\n",
      "-----------------\n",
      "Finished episode: 401 Reward: -921.4200 total_loss = 8.0763 = 0.0440 + 0.5 * 16.0688 + 0.01 * -0.2022\n",
      "-----------------\n",
      "Finished episode: 402 Reward: -923.7682 total_loss = 8.6648 = 0.0336 + 0.5 * 17.2664 + 0.01 * -0.2013\n",
      "-----------------\n",
      "Finished episode: 403 Reward: -878.6383 total_loss = 9.2671 = 0.0166 + 0.5 * 18.5050 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 404 Reward: -1000.7112 total_loss = 10.5299 = 0.0294 + 0.5 * 21.0050 + 0.01 * -0.1992\n",
      "-----------------\n",
      "Finished episode: 405 Reward: -918.1724 total_loss = 8.3805 = 0.0645 + 0.5 * 16.6360 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 406 Reward: -880.3890 total_loss = 11.0362 = 0.0041 + 0.5 * 22.0682 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 407 Reward: -935.3564 total_loss = 9.3579 = -0.0839 + 0.5 * 18.8875 + 0.01 * -0.1981\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 408 Reward: -946.5218 total_loss = 7.0013 = -0.0133 + 0.5 * 14.0332 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 409 Reward: -905.4894 total_loss = 6.7558 = 0.0496 + 0.5 * 13.4165 + 0.01 * -0.2005\n",
      "-----------------\n",
      "Finished episode: 410 Reward: -963.8491 total_loss = 8.9576 = -0.0086 + 0.5 * 17.9363 + 0.01 * -0.1995\n",
      "-----------------\n",
      "Finished episode: 411 Reward: -898.8858 total_loss = 8.1113 = 0.0996 + 0.5 * 16.0273 + 0.01 * -0.1990\n",
      "-----------------\n",
      "Finished episode: 412 Reward: -931.4079 total_loss = 9.1617 = 0.0411 + 0.5 * 18.2451 + 0.01 * -0.1995\n",
      "-----------------\n",
      "Finished episode: 413 Reward: -930.3701 total_loss = 8.6109 = -0.1115 + 0.5 * 17.4488 + 0.01 * -0.1996\n",
      "-----------------\n",
      "Finished episode: 414 Reward: -921.7602 total_loss = 8.7258 = 0.0351 + 0.5 * 17.3855 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 415 Reward: -921.8716 total_loss = 9.7305 = -0.0804 + 0.5 * 19.6259 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 416 Reward: -943.0817 total_loss = 8.4552 = -0.0769 + 0.5 * 17.0681 + 0.01 * -0.1992\n",
      "-----------------\n",
      "Finished episode: 417 Reward: -902.9570 total_loss = 11.1542 = -0.0461 + 0.5 * 22.4046 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 418 Reward: -959.7923 total_loss = 9.2329 = 0.0629 + 0.5 * 18.3440 + 0.01 * -0.1992\n",
      "-----------------\n",
      "Finished episode: 419 Reward: -895.7593 total_loss = 7.6624 = 0.0039 + 0.5 * 15.3210 + 0.01 * -0.1996\n",
      "-----------------\n",
      "Finished episode: 420 Reward: -943.6363 total_loss = 10.2704 = 0.0337 + 0.5 * 20.4775 + 0.01 * -0.1991\n",
      "-----------------\n",
      "Finished episode: 421 Reward: -894.6532 total_loss = 9.7696 = -0.1185 + 0.5 * 19.7803 + 0.01 * -0.1997\n",
      "-----------------\n",
      "Finished episode: 422 Reward: -921.4315 total_loss = 6.5497 = -0.0260 + 0.5 * 13.1555 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 423 Reward: -887.3456 total_loss = 8.0391 = 0.0748 + 0.5 * 15.9327 + 0.01 * -0.2018\n",
      "-----------------\n",
      "Finished episode: 424 Reward: -868.5832 total_loss = 11.0612 = -0.0391 + 0.5 * 22.2045 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 425 Reward: -913.7446 total_loss = 8.3175 = -0.0672 + 0.5 * 16.7733 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 426 Reward: -917.8001 total_loss = 8.0423 = 0.0139 + 0.5 * 16.0608 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 427 Reward: -943.2338 total_loss = 10.0358 = -0.0465 + 0.5 * 20.1686 + 0.01 * -0.2009\n",
      "-----------------\n",
      "Finished episode: 428 Reward: -961.9029 total_loss = 8.9662 = -0.0391 + 0.5 * 18.0146 + 0.01 * -0.1988\n",
      "-----------------\n",
      "Finished episode: 429 Reward: -915.3958 total_loss = 8.1242 = 0.0436 + 0.5 * 16.1651 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 430 Reward: -896.3326 total_loss = 9.5609 = -0.0476 + 0.5 * 19.2212 + 0.01 * -0.2018\n",
      "-----------------\n",
      "Finished episode: 431 Reward: -884.9896 total_loss = 9.2461 = 0.0172 + 0.5 * 18.4618 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 432 Reward: -802.4186 total_loss = 9.1538 = 0.0475 + 0.5 * 18.2166 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 433 Reward: -886.8393 total_loss = 7.9842 = -0.0230 + 0.5 * 16.0185 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 434 Reward: -858.1735 total_loss = 7.2480 = 0.0996 + 0.5 * 14.3009 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 435 Reward: -863.4415 total_loss = 9.9664 = -0.1492 + 0.5 * 20.2353 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 436 Reward: -840.6150 total_loss = 7.7321 = -0.0080 + 0.5 * 15.4841 + 0.01 * -0.2002\n",
      "-----------------\n",
      "Finished episode: 437 Reward: -910.3726 total_loss = 8.8704 = 0.1327 + 0.5 * 17.4795 + 0.01 * -0.1989\n",
      "-----------------\n",
      "Finished episode: 438 Reward: -910.1450 total_loss = 8.0853 = 0.0332 + 0.5 * 16.1082 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 439 Reward: -941.0350 total_loss = 9.1907 = -0.0797 + 0.5 * 18.5450 + 0.01 * -0.2020\n",
      "-----------------\n",
      "Finished episode: 440 Reward: -925.3156 total_loss = 10.1751 = 0.0025 + 0.5 * 20.3492 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 441 Reward: -892.2568 total_loss = 6.2990 = 0.0343 + 0.5 * 12.5334 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 442 Reward: -870.9530 total_loss = 7.9304 = 0.0021 + 0.5 * 15.8607 + 0.01 * -0.2025\n",
      "-----------------\n",
      "Finished episode: 443 Reward: -951.9736 total_loss = 9.0647 = -0.0789 + 0.5 * 18.2911 + 0.01 * -0.2023\n",
      "-----------------\n",
      "Finished episode: 444 Reward: -868.9069 total_loss = 7.4078 = -0.0354 + 0.5 * 14.8905 + 0.01 * -0.2029\n",
      "-----------------\n",
      "Finished episode: 445 Reward: -938.4608 total_loss = 8.5196 = -0.0870 + 0.5 * 17.2173 + 0.01 * -0.2016\n",
      "-----------------\n",
      "Finished episode: 446 Reward: -977.1022 total_loss = 8.7759 = -0.0197 + 0.5 * 17.5953 + 0.01 * -0.2029\n",
      "-----------------\n",
      "Finished episode: 447 Reward: -946.0164 total_loss = 9.5645 = 0.0902 + 0.5 * 18.9527 + 0.01 * -0.2020\n",
      "-----------------\n",
      "Finished episode: 448 Reward: -978.4666 total_loss = 10.1025 = -0.0565 + 0.5 * 20.3220 + 0.01 * -0.2003\n",
      "-----------------\n",
      "Finished episode: 449 Reward: -988.1617 total_loss = 9.2017 = -0.0502 + 0.5 * 18.5077 + 0.01 * -0.2003\n",
      "-----------------\n",
      "Finished episode: 450 Reward: -1009.3368 total_loss = 9.2973 = -0.0352 + 0.5 * 18.6690 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 451 Reward: -968.5777 total_loss = 7.1282 = -0.0791 + 0.5 * 14.4186 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 452 Reward: -1027.2162 total_loss = 8.5940 = 0.0460 + 0.5 * 17.1000 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 453 Reward: -971.2107 total_loss = 9.2742 = 0.0859 + 0.5 * 18.3806 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 454 Reward: -962.0892 total_loss = 8.4569 = -0.0236 + 0.5 * 16.9649 + 0.01 * -0.1994\n",
      "-----------------\n",
      "Finished episode: 455 Reward: -1043.1061 total_loss = 9.1551 = 0.0084 + 0.5 * 18.2975 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 456 Reward: -959.0836 total_loss = 10.4954 = 0.1061 + 0.5 * 20.7826 + 0.01 * -0.2005\n",
      "-----------------\n",
      "Finished episode: 457 Reward: -1004.7360 total_loss = 11.3442 = -0.0979 + 0.5 * 22.8882 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 458 Reward: -957.8573 total_loss = 9.1562 = -0.0571 + 0.5 * 18.4306 + 0.01 * -0.1980\n",
      "-----------------\n",
      "Finished episode: 459 Reward: -920.9350 total_loss = 9.0835 = -0.1047 + 0.5 * 18.3805 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 460 Reward: -952.4291 total_loss = 9.0075 = -0.0525 + 0.5 * 18.1242 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 461 Reward: -937.3224 total_loss = 10.7947 = -0.0202 + 0.5 * 21.6338 + 0.01 * -0.1993\n",
      "-----------------\n",
      "Finished episode: 462 Reward: -941.4532 total_loss = 9.1541 = 0.0532 + 0.5 * 18.2058 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 463 Reward: -961.6542 total_loss = 9.9593 = -0.0106 + 0.5 * 19.9437 + 0.01 * -0.1991\n",
      "-----------------\n",
      "Finished episode: 464 Reward: -933.8626 total_loss = 9.3150 = 0.0102 + 0.5 * 18.6138 + 0.01 * -0.2003\n",
      "-----------------\n",
      "Finished episode: 465 Reward: -977.2157 total_loss = 12.2552 = 0.0140 + 0.5 * 24.4865 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 466 Reward: -954.6133 total_loss = 9.4801 = -0.0709 + 0.5 * 19.1061 + 0.01 * -0.2005\n",
      "-----------------\n",
      "Finished episode: 467 Reward: -928.2237 total_loss = 8.8662 = -0.0484 + 0.5 * 17.8333 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 468 Reward: -948.6407 total_loss = 8.1040 = -0.0984 + 0.5 * 16.4089 + 0.01 * -0.2012\n",
      "-----------------\n",
      "Finished episode: 469 Reward: -877.0595 total_loss = 9.2847 = -0.0771 + 0.5 * 18.7275 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 470 Reward: -920.4711 total_loss = 7.2639 = 0.0883 + 0.5 * 14.3551 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 471 Reward: -879.1650 total_loss = 8.5887 = 0.0178 + 0.5 * 17.1458 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 472 Reward: -916.7587 total_loss = 6.3488 = -0.1217 + 0.5 * 12.9449 + 0.01 * -0.2036\n",
      "-----------------\n",
      "Finished episode: 473 Reward: -913.8288 total_loss = 7.6593 = -0.0455 + 0.5 * 15.4138 + 0.01 * -0.2012\n",
      "-----------------\n",
      "Finished episode: 474 Reward: -907.2683 total_loss = 6.3843 = -0.1273 + 0.5 * 13.0272 + 0.01 * -0.2030\n",
      "-----------------\n",
      "Finished episode: 475 Reward: -895.3498 total_loss = 9.4180 = 0.0119 + 0.5 * 18.8162 + 0.01 * -0.2016\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 476 Reward: -921.3841 total_loss = 7.1381 = -0.0040 + 0.5 * 14.2882 + 0.01 * -0.2043\n",
      "-----------------\n",
      "Finished episode: 477 Reward: -902.6110 total_loss = 7.4433 = 0.0294 + 0.5 * 14.8319 + 0.01 * -0.2037\n",
      "-----------------\n",
      "Finished episode: 478 Reward: -889.2508 total_loss = 7.5566 = 0.0402 + 0.5 * 15.0369 + 0.01 * -0.2053\n",
      "-----------------\n",
      "Finished episode: 479 Reward: -942.1231 total_loss = 7.0602 = -0.0850 + 0.5 * 14.2946 + 0.01 * -0.2042\n",
      "-----------------\n",
      "Finished episode: 480 Reward: -969.2881 total_loss = 7.4152 = -0.0070 + 0.5 * 14.8485 + 0.01 * -0.2027\n",
      "-----------------\n",
      "Finished episode: 481 Reward: -924.5879 total_loss = 10.2415 = -0.0583 + 0.5 * 20.6037 + 0.01 * -0.2041\n",
      "-----------------\n",
      "Finished episode: 482 Reward: -913.7627 total_loss = 8.9385 = -0.0348 + 0.5 * 17.9507 + 0.01 * -0.2034\n",
      "-----------------\n",
      "Finished episode: 483 Reward: -922.3230 total_loss = 8.8817 = -0.0241 + 0.5 * 17.8156 + 0.01 * -0.2036\n",
      "-----------------\n",
      "Finished episode: 484 Reward: -906.9684 total_loss = 10.2118 = -0.1286 + 0.5 * 20.6847 + 0.01 * -0.2030\n",
      "-----------------\n",
      "Finished episode: 485 Reward: -888.7420 total_loss = 6.6324 = 0.0721 + 0.5 * 13.1248 + 0.01 * -0.2043\n",
      "-----------------\n",
      "Finished episode: 486 Reward: -958.4189 total_loss = 6.1705 = 0.0111 + 0.5 * 12.3230 + 0.01 * -0.2040\n",
      "-----------------\n",
      "Finished episode: 487 Reward: -896.9585 total_loss = 8.4731 = -0.0326 + 0.5 * 17.0155 + 0.01 * -0.2028\n",
      "-----------------\n",
      "Finished episode: 488 Reward: -877.2798 total_loss = 8.8557 = 0.0473 + 0.5 * 17.6208 + 0.01 * -0.2030\n",
      "-----------------\n",
      "Finished episode: 489 Reward: -949.7813 total_loss = 9.1359 = 0.0133 + 0.5 * 18.2492 + 0.01 * -0.2035\n",
      "-----------------\n",
      "Finished episode: 490 Reward: -886.6618 total_loss = 10.3040 = -0.1071 + 0.5 * 20.8262 + 0.01 * -0.2040\n",
      "-----------------\n",
      "Finished episode: 491 Reward: -907.2837 total_loss = 7.7970 = 0.0495 + 0.5 * 15.4990 + 0.01 * -0.2041\n",
      "-----------------\n",
      "Finished episode: 492 Reward: -933.6806 total_loss = 9.0380 = 0.1379 + 0.5 * 17.8044 + 0.01 * -0.2045\n",
      "-----------------\n",
      "Finished episode: 493 Reward: -914.4723 total_loss = 9.7516 = -0.0267 + 0.5 * 19.5607 + 0.01 * -0.2046\n",
      "-----------------\n",
      "Finished episode: 494 Reward: -955.9260 total_loss = 7.3704 = 0.0240 + 0.5 * 14.6968 + 0.01 * -0.2047\n",
      "-----------------\n",
      "Finished episode: 495 Reward: -913.7691 total_loss = 9.7397 = -0.0608 + 0.5 * 19.6051 + 0.01 * -0.2041\n",
      "-----------------\n",
      "Finished episode: 496 Reward: -913.6029 total_loss = 7.7459 = 0.0548 + 0.5 * 15.3864 + 0.01 * -0.2049\n",
      "-----------------\n",
      "Finished episode: 497 Reward: -894.6805 total_loss = 9.9998 = -0.0362 + 0.5 * 20.0760 + 0.01 * -0.2044\n",
      "-----------------\n",
      "Finished episode: 498 Reward: -904.0704 total_loss = 7.6453 = 0.1086 + 0.5 * 15.0775 + 0.01 * -0.2031\n",
      "-----------------\n",
      "Finished episode: 499 Reward: -933.2479 total_loss = 8.9935 = -0.0636 + 0.5 * 18.1184 + 0.01 * -0.2039\n",
      "-----------------\n",
      "Finished episode: 500 Reward: -899.3359 total_loss = 8.3313 = 0.1241 + 0.5 * 16.4184 + 0.01 * -0.2022\n",
      "-----------------\n",
      "Finished episode: 501 Reward: -922.6134 total_loss = 8.1885 = 0.0544 + 0.5 * 16.2723 + 0.01 * -0.2018\n",
      "-----------------\n",
      "Finished episode: 502 Reward: -886.8983 total_loss = 10.6804 = -0.0322 + 0.5 * 21.4291 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 503 Reward: -879.2512 total_loss = 7.8763 = -0.0839 + 0.5 * 15.9245 + 0.01 * -0.2030\n",
      "-----------------\n",
      "Finished episode: 504 Reward: -920.0158 total_loss = 8.9507 = -0.0414 + 0.5 * 17.9884 + 0.01 * -0.2031\n",
      "-----------------\n",
      "Finished episode: 505 Reward: -922.1777 total_loss = 8.2455 = 0.0035 + 0.5 * 16.4880 + 0.01 * -0.2037\n",
      "-----------------\n",
      "Finished episode: 506 Reward: -869.3030 total_loss = 9.6297 = -0.0701 + 0.5 * 19.4037 + 0.01 * -0.2041\n",
      "-----------------\n",
      "Finished episode: 507 Reward: -931.5452 total_loss = 6.9901 = -0.0079 + 0.5 * 14.0001 + 0.01 * -0.2043\n",
      "-----------------\n",
      "Finished episode: 508 Reward: -954.5334 total_loss = 6.8297 = -0.0472 + 0.5 * 13.7578 + 0.01 * -0.2044\n",
      "-----------------\n",
      "Finished episode: 509 Reward: -915.6606 total_loss = 7.9506 = 0.0334 + 0.5 * 15.8385 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 510 Reward: -935.7423 total_loss = 8.0030 = 0.0683 + 0.5 * 15.8733 + 0.01 * -0.2026\n",
      "-----------------\n",
      "Finished episode: 511 Reward: -935.8098 total_loss = 10.8226 = 0.0443 + 0.5 * 21.5607 + 0.01 * -0.2040\n",
      "-----------------\n",
      "Finished episode: 512 Reward: -966.3891 total_loss = 9.3574 = 0.0634 + 0.5 * 18.5920 + 0.01 * -0.2035\n",
      "-----------------\n",
      "Finished episode: 513 Reward: -907.7907 total_loss = 9.1596 = -0.0258 + 0.5 * 18.3747 + 0.01 * -0.2047\n",
      "-----------------\n",
      "Finished episode: 514 Reward: -907.2965 total_loss = 9.1960 = -0.0340 + 0.5 * 18.4640 + 0.01 * -0.2049\n",
      "-----------------\n",
      "Finished episode: 515 Reward: -885.3339 total_loss = 10.7445 = 0.0573 + 0.5 * 21.3787 + 0.01 * -0.2057\n",
      "-----------------\n",
      "Finished episode: 516 Reward: -933.2273 total_loss = 8.1580 = 0.0982 + 0.5 * 16.1237 + 0.01 * -0.2045\n",
      "-----------------\n",
      "Finished episode: 517 Reward: -893.6798 total_loss = 8.7132 = -0.1101 + 0.5 * 17.6507 + 0.01 * -0.2053\n",
      "-----------------\n",
      "Finished episode: 518 Reward: -879.9903 total_loss = 8.6016 = 0.0651 + 0.5 * 17.0772 + 0.01 * -0.2046\n",
      "-----------------\n",
      "Finished episode: 519 Reward: -899.1464 total_loss = 8.4766 = -0.0718 + 0.5 * 17.1010 + 0.01 * -0.2056\n",
      "-----------------\n",
      "Finished episode: 520 Reward: -953.8948 total_loss = 6.9966 = 0.0143 + 0.5 * 13.9687 + 0.01 * -0.2045\n",
      "-----------------\n",
      "Finished episode: 521 Reward: -967.4718 total_loss = 7.4381 = -0.0037 + 0.5 * 14.8877 + 0.01 * -0.2050\n",
      "-----------------\n",
      "Finished episode: 522 Reward: -936.8136 total_loss = 9.3777 = -0.0570 + 0.5 * 18.8735 + 0.01 * -0.2063\n",
      "-----------------\n",
      "Finished episode: 523 Reward: -961.8614 total_loss = 9.4643 = 0.0215 + 0.5 * 18.8896 + 0.01 * -0.2051\n",
      "-----------------\n",
      "Finished episode: 524 Reward: -914.9360 total_loss = 8.5341 = 0.0481 + 0.5 * 16.9760 + 0.01 * -0.2054\n",
      "-----------------\n",
      "Finished episode: 525 Reward: -925.8065 total_loss = 7.0368 = 0.0659 + 0.5 * 13.9459 + 0.01 * -0.2068\n",
      "-----------------\n",
      "Finished episode: 526 Reward: -933.1189 total_loss = 8.1986 = -0.0614 + 0.5 * 16.5243 + 0.01 * -0.2052\n",
      "-----------------\n",
      "Finished episode: 527 Reward: -904.0044 total_loss = 8.2175 = 0.0860 + 0.5 * 16.2671 + 0.01 * -0.2059\n",
      "-----------------\n",
      "Finished episode: 528 Reward: -926.1283 total_loss = 10.3730 = 0.0948 + 0.5 * 20.5605 + 0.01 * -0.2044\n",
      "-----------------\n",
      "Finished episode: 529 Reward: -890.7468 total_loss = 8.1319 = 0.0770 + 0.5 * 16.1139 + 0.01 * -0.2064\n",
      "-----------------\n",
      "Finished episode: 530 Reward: -914.1393 total_loss = 8.0199 = 0.0761 + 0.5 * 15.8918 + 0.01 * -0.2054\n",
      "-----------------\n",
      "Finished episode: 531 Reward: -900.2720 total_loss = 9.5201 = 0.0763 + 0.5 * 18.8918 + 0.01 * -0.2047\n",
      "-----------------\n",
      "Finished episode: 532 Reward: -940.4011 total_loss = 10.8508 = -0.1112 + 0.5 * 21.9281 + 0.01 * -0.2065\n",
      "-----------------\n",
      "Finished episode: 533 Reward: -881.9270 total_loss = 9.4190 = -0.1317 + 0.5 * 19.1056 + 0.01 * -0.2058\n",
      "-----------------\n",
      "Finished episode: 534 Reward: -988.5584 total_loss = 9.7906 = -0.0312 + 0.5 * 19.6477 + 0.01 * -0.2063\n",
      "-----------------\n",
      "Finished episode: 535 Reward: -973.6838 total_loss = 7.3751 = 0.0056 + 0.5 * 14.7431 + 0.01 * -0.2067\n",
      "-----------------\n",
      "Finished episode: 536 Reward: -950.6362 total_loss = 7.6681 = 0.0135 + 0.5 * 15.3133 + 0.01 * -0.2079\n",
      "-----------------\n",
      "Finished episode: 537 Reward: -933.9330 total_loss = 9.2464 = -0.0281 + 0.5 * 18.5531 + 0.01 * -0.2072\n",
      "-----------------\n",
      "Finished episode: 538 Reward: -916.8625 total_loss = 7.5914 = -0.0204 + 0.5 * 15.2278 + 0.01 * -0.2070\n",
      "-----------------\n",
      "Finished episode: 539 Reward: -922.3556 total_loss = 9.3988 = -0.0737 + 0.5 * 18.9492 + 0.01 * -0.2082\n",
      "-----------------\n",
      "Finished episode: 540 Reward: -940.6582 total_loss = 8.8333 = 0.0800 + 0.5 * 17.5107 + 0.01 * -0.2073\n",
      "-----------------\n",
      "Finished episode: 541 Reward: -907.3877 total_loss = 9.9011 = 0.0249 + 0.5 * 19.7566 + 0.01 * -0.2078\n",
      "-----------------\n",
      "Finished episode: 542 Reward: -901.0677 total_loss = 8.6501 = 0.0233 + 0.5 * 17.2578 + 0.01 * -0.2064\n",
      "-----------------\n",
      "Finished episode: 543 Reward: -931.1214 total_loss = 7.8780 = 0.1058 + 0.5 * 15.5486 + 0.01 * -0.2076\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 544 Reward: -945.6641 total_loss = 10.5577 = -0.0307 + 0.5 * 21.1810 + 0.01 * -0.2065\n",
      "-----------------\n",
      "Finished episode: 545 Reward: -929.4354 total_loss = 9.7358 = 0.0333 + 0.5 * 19.4091 + 0.01 * -0.2081\n",
      "-----------------\n",
      "Finished episode: 546 Reward: -903.9882 total_loss = 9.3319 = -0.0338 + 0.5 * 18.7356 + 0.01 * -0.2065\n",
      "-----------------\n",
      "Finished episode: 547 Reward: -986.6851 total_loss = 10.2854 = -0.0073 + 0.5 * 20.5896 + 0.01 * -0.2066\n",
      "-----------------\n",
      "Finished episode: 548 Reward: -958.1843 total_loss = 12.0257 = 0.0025 + 0.5 * 24.0504 + 0.01 * -0.2066\n",
      "-----------------\n",
      "Finished episode: 549 Reward: -943.7803 total_loss = 9.6187 = 0.0673 + 0.5 * 19.1069 + 0.01 * -0.2058\n",
      "-----------------\n",
      "Finished episode: 550 Reward: -911.8739 total_loss = 9.5033 = 0.0176 + 0.5 * 18.9753 + 0.01 * -0.2057\n",
      "-----------------\n",
      "Finished episode: 551 Reward: -995.4586 total_loss = 9.0289 = -0.0399 + 0.5 * 18.1416 + 0.01 * -0.2049\n",
      "-----------------\n",
      "Finished episode: 552 Reward: -994.5756 total_loss = 7.8575 = -0.0121 + 0.5 * 15.7432 + 0.01 * -0.2052\n",
      "-----------------\n",
      "Finished episode: 553 Reward: -916.5917 total_loss = 9.4449 = -0.0935 + 0.5 * 19.0809 + 0.01 * -0.2054\n",
      "-----------------\n",
      "Finished episode: 554 Reward: -1000.0273 total_loss = 8.6470 = -0.0444 + 0.5 * 17.3870 + 0.01 * -0.2053\n",
      "-----------------\n",
      "Finished episode: 555 Reward: -973.7576 total_loss = 10.6038 = 0.0979 + 0.5 * 21.0159 + 0.01 * -0.2048\n",
      "-----------------\n",
      "Finished episode: 556 Reward: -969.0759 total_loss = 10.1275 = 0.0319 + 0.5 * 20.1953 + 0.01 * -0.2066\n",
      "-----------------\n",
      "Finished episode: 557 Reward: -950.1705 total_loss = 9.8186 = 0.0721 + 0.5 * 19.4973 + 0.01 * -0.2053\n",
      "-----------------\n",
      "Finished episode: 558 Reward: -994.5509 total_loss = 10.0493 = -0.0701 + 0.5 * 20.2428 + 0.01 * -0.2068\n",
      "-----------------\n",
      "Finished episode: 559 Reward: -975.6831 total_loss = 10.2418 = -0.0391 + 0.5 * 20.5659 + 0.01 * -0.2051\n",
      "-----------------\n",
      "Finished episode: 560 Reward: -942.9089 total_loss = 9.3473 = 0.0833 + 0.5 * 18.5321 + 0.01 * -0.2052\n",
      "-----------------\n",
      "Finished episode: 561 Reward: -888.2813 total_loss = 10.5276 = -0.1078 + 0.5 * 21.2750 + 0.01 * -0.2071\n",
      "-----------------\n",
      "Finished episode: 562 Reward: -921.4468 total_loss = 8.6928 = 0.0078 + 0.5 * 17.3740 + 0.01 * -0.2056\n",
      "-----------------\n",
      "Finished episode: 563 Reward: -992.2808 total_loss = 10.0126 = -0.0535 + 0.5 * 20.1364 + 0.01 * -0.2056\n",
      "-----------------\n",
      "Finished episode: 564 Reward: -914.0773 total_loss = 10.9913 = 0.0138 + 0.5 * 21.9593 + 0.01 * -0.2044\n",
      "-----------------\n",
      "Finished episode: 565 Reward: -973.1997 total_loss = 9.7247 = 0.0333 + 0.5 * 19.3868 + 0.01 * -0.2054\n",
      "-----------------\n",
      "Finished episode: 566 Reward: -927.4631 total_loss = 9.2275 = 0.0248 + 0.5 * 18.4093 + 0.01 * -0.2042\n",
      "-----------------\n",
      "Finished episode: 567 Reward: -979.2002 total_loss = 7.4125 = 0.0081 + 0.5 * 14.8131 + 0.01 * -0.2057\n",
      "-----------------\n",
      "Finished episode: 568 Reward: -899.7343 total_loss = 9.2963 = -0.0213 + 0.5 * 18.6393 + 0.01 * -0.2052\n",
      "-----------------\n",
      "Finished episode: 569 Reward: -928.1589 total_loss = 6.8135 = -0.0514 + 0.5 * 13.7339 + 0.01 * -0.2054\n",
      "-----------------\n",
      "Finished episode: 570 Reward: -908.5386 total_loss = 11.6650 = 0.0332 + 0.5 * 23.2677 + 0.01 * -0.2047\n",
      "-----------------\n",
      "Finished episode: 571 Reward: -959.5796 total_loss = 8.1891 = -0.0025 + 0.5 * 16.3873 + 0.01 * -0.2039\n",
      "-----------------\n",
      "Finished episode: 572 Reward: -977.2370 total_loss = 10.0147 = -0.0544 + 0.5 * 20.1424 + 0.01 * -0.2046\n",
      "-----------------\n",
      "Finished episode: 573 Reward: -945.3927 total_loss = 12.8344 = -0.0875 + 0.5 * 25.8479 + 0.01 * -0.2047\n",
      "-----------------\n",
      "Finished episode: 574 Reward: -1002.8225 total_loss = 9.5264 = -0.0052 + 0.5 * 19.0673 + 0.01 * -0.2045\n",
      "-----------------\n",
      "Finished episode: 575 Reward: -915.2905 total_loss = 10.2413 = 0.0081 + 0.5 * 20.4706 + 0.01 * -0.2060\n",
      "-----------------\n",
      "Finished episode: 576 Reward: -921.2728 total_loss = 8.5762 = 0.0573 + 0.5 * 17.0419 + 0.01 * -0.2057\n",
      "-----------------\n",
      "Finished episode: 577 Reward: -944.5505 total_loss = 9.1996 = -0.0305 + 0.5 * 18.4643 + 0.01 * -0.2046\n",
      "-----------------\n",
      "Finished episode: 578 Reward: -925.3070 total_loss = 8.9730 = -0.0885 + 0.5 * 18.1272 + 0.01 * -0.2059\n",
      "-----------------\n",
      "Finished episode: 579 Reward: -914.5034 total_loss = 9.5660 = -0.0576 + 0.5 * 19.2514 + 0.01 * -0.2050\n",
      "-----------------\n",
      "Finished episode: 580 Reward: -985.2976 total_loss = 9.4720 = -0.0165 + 0.5 * 18.9810 + 0.01 * -0.2052\n",
      "-----------------\n",
      "Finished episode: 581 Reward: -998.1693 total_loss = 12.6683 = -0.0077 + 0.5 * 25.3559 + 0.01 * -0.2056\n",
      "-----------------\n",
      "Finished episode: 582 Reward: -975.2948 total_loss = 9.3995 = 0.0190 + 0.5 * 18.7652 + 0.01 * -0.2050\n",
      "-----------------\n",
      "Finished episode: 583 Reward: -879.8476 total_loss = 8.8563 = -0.1504 + 0.5 * 18.0175 + 0.01 * -0.2061\n",
      "-----------------\n",
      "Finished episode: 584 Reward: -942.3414 total_loss = 10.3666 = -0.1568 + 0.5 * 21.0509 + 0.01 * -0.2056\n",
      "-----------------\n",
      "Finished episode: 585 Reward: -932.1284 total_loss = 12.1385 = -0.0121 + 0.5 * 24.3054 + 0.01 * -0.2044\n",
      "-----------------\n",
      "Finished episode: 586 Reward: -960.4801 total_loss = 8.3151 = 0.0768 + 0.5 * 16.4807 + 0.01 * -0.2051\n",
      "-----------------\n",
      "Finished episode: 587 Reward: -928.9166 total_loss = 9.2086 = -0.0193 + 0.5 * 18.4600 + 0.01 * -0.2053\n",
      "-----------------\n",
      "Finished episode: 588 Reward: -962.8161 total_loss = 8.0364 = -0.0702 + 0.5 * 16.2173 + 0.01 * -0.2046\n",
      "-----------------\n",
      "Finished episode: 589 Reward: -939.1807 total_loss = 8.3191 = -0.0539 + 0.5 * 16.7500 + 0.01 * -0.2058\n",
      "-----------------\n",
      "Finished episode: 590 Reward: -969.6901 total_loss = 9.7208 = -0.1279 + 0.5 * 19.7016 + 0.01 * -0.2052\n",
      "-----------------\n",
      "Finished episode: 591 Reward: -991.8652 total_loss = 9.0590 = 0.0010 + 0.5 * 18.1201 + 0.01 * -0.2044\n",
      "-----------------\n",
      "Finished episode: 592 Reward: -968.3297 total_loss = 11.5110 = 0.0476 + 0.5 * 22.9309 + 0.01 * -0.2034\n",
      "-----------------\n",
      "Finished episode: 593 Reward: -971.0632 total_loss = 9.1283 = 0.0492 + 0.5 * 18.1623 + 0.01 * -0.2034\n",
      "-----------------\n",
      "Finished episode: 594 Reward: -974.1785 total_loss = 9.5398 = 0.0658 + 0.5 * 18.9522 + 0.01 * -0.2035\n",
      "-----------------\n",
      "Finished episode: 595 Reward: -883.9017 total_loss = 9.0858 = 0.0057 + 0.5 * 18.1643 + 0.01 * -0.2044\n",
      "-----------------\n",
      "Finished episode: 596 Reward: -981.8908 total_loss = 10.1304 = -0.0422 + 0.5 * 20.3493 + 0.01 * -0.2043\n",
      "-----------------\n",
      "Finished episode: 597 Reward: -945.1267 total_loss = 8.0423 = 0.0050 + 0.5 * 16.0787 + 0.01 * -0.2039\n",
      "-----------------\n",
      "Finished episode: 598 Reward: -969.3500 total_loss = 9.0846 = 0.0982 + 0.5 * 17.9769 + 0.01 * -0.2040\n",
      "-----------------\n",
      "Finished episode: 599 Reward: -941.3696 total_loss = 7.8284 = -0.0289 + 0.5 * 15.7188 + 0.01 * -0.2044\n",
      "-----------------\n",
      "Finished episode: 600 Reward: -979.1727 total_loss = 11.4027 = -0.0961 + 0.5 * 23.0017 + 0.01 * -0.2039\n",
      "-----------------\n",
      "Finished episode: 601 Reward: -970.9537 total_loss = 7.7703 = 0.0539 + 0.5 * 15.4370 + 0.01 * -0.2043\n",
      "-----------------\n",
      "Finished episode: 602 Reward: -887.5578 total_loss = 9.9111 = 0.0969 + 0.5 * 19.6325 + 0.01 * -0.2047\n",
      "-----------------\n",
      "Finished episode: 603 Reward: -992.1890 total_loss = 7.8911 = 0.0145 + 0.5 * 15.7573 + 0.01 * -0.2039\n",
      "-----------------\n",
      "Finished episode: 604 Reward: -919.3178 total_loss = 10.2590 = -0.0339 + 0.5 * 20.5898 + 0.01 * -0.2054\n",
      "-----------------\n",
      "Finished episode: 605 Reward: -996.1300 total_loss = 7.0966 = -0.0223 + 0.5 * 14.2418 + 0.01 * -0.2034\n",
      "-----------------\n",
      "Finished episode: 606 Reward: -1019.6348 total_loss = 8.5498 = -0.0291 + 0.5 * 17.1619 + 0.01 * -0.2028\n",
      "-----------------\n",
      "Finished episode: 607 Reward: -983.4758 total_loss = 7.5882 = 0.0611 + 0.5 * 15.0583 + 0.01 * -0.2025\n",
      "-----------------\n",
      "Finished episode: 608 Reward: -982.0244 total_loss = 8.7191 = -0.0764 + 0.5 * 17.5951 + 0.01 * -0.2029\n",
      "-----------------\n",
      "Finished episode: 609 Reward: -957.1440 total_loss = 8.5389 = 0.0572 + 0.5 * 16.9675 + 0.01 * -0.2027\n",
      "-----------------\n",
      "Finished episode: 610 Reward: -979.1621 total_loss = 8.6515 = -0.0780 + 0.5 * 17.4630 + 0.01 * -0.2030\n",
      "-----------------\n",
      "Finished episode: 611 Reward: -918.4252 total_loss = 10.4294 = -0.0616 + 0.5 * 20.9862 + 0.01 * -0.2031\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 612 Reward: -954.8995 total_loss = 9.1617 = -0.0143 + 0.5 * 18.3561 + 0.01 * -0.2032\n",
      "-----------------\n",
      "Finished episode: 613 Reward: -956.9004 total_loss = 10.7530 = -0.0382 + 0.5 * 21.5864 + 0.01 * -0.2028\n",
      "-----------------\n",
      "Finished episode: 614 Reward: -968.0407 total_loss = 9.2849 = 0.0398 + 0.5 * 18.4941 + 0.01 * -0.2025\n",
      "-----------------\n",
      "Finished episode: 615 Reward: -908.4820 total_loss = 9.0367 = -0.0424 + 0.5 * 18.1623 + 0.01 * -0.2038\n",
      "-----------------\n",
      "Finished episode: 616 Reward: -925.5572 total_loss = 10.1670 = 0.0975 + 0.5 * 20.1430 + 0.01 * -0.2039\n",
      "-----------------\n",
      "Finished episode: 617 Reward: -966.8928 total_loss = 9.0985 = 0.1248 + 0.5 * 17.9513 + 0.01 * -0.2026\n",
      "-----------------\n",
      "Finished episode: 618 Reward: -976.5394 total_loss = 10.2060 = -0.0803 + 0.5 * 20.5766 + 0.01 * -0.2037\n",
      "-----------------\n",
      "Finished episode: 619 Reward: -930.5230 total_loss = 9.3627 = 0.1067 + 0.5 * 18.5161 + 0.01 * -0.2031\n",
      "-----------------\n",
      "Finished episode: 620 Reward: -898.0062 total_loss = 9.6656 = -0.0564 + 0.5 * 19.4482 + 0.01 * -0.2038\n",
      "-----------------\n",
      "Finished episode: 621 Reward: -998.0776 total_loss = 9.3101 = 0.0001 + 0.5 * 18.6241 + 0.01 * -0.2031\n",
      "-----------------\n",
      "Finished episode: 622 Reward: -959.7558 total_loss = 9.9246 = -0.0356 + 0.5 * 19.9246 + 0.01 * -0.2038\n",
      "-----------------\n",
      "Finished episode: 623 Reward: -998.5643 total_loss = 8.5919 = -0.0109 + 0.5 * 17.2097 + 0.01 * -0.2034\n",
      "-----------------\n",
      "Finished episode: 624 Reward: -964.4818 total_loss = 8.5220 = 0.0274 + 0.5 * 16.9934 + 0.01 * -0.2039\n",
      "-----------------\n",
      "Finished episode: 625 Reward: -924.5795 total_loss = 7.7564 = 0.0044 + 0.5 * 15.5081 + 0.01 * -0.2032\n",
      "-----------------\n",
      "Finished episode: 626 Reward: -923.5947 total_loss = 8.5411 = 0.0707 + 0.5 * 16.9449 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 627 Reward: -950.4316 total_loss = 10.2786 = 0.0517 + 0.5 * 20.4578 + 0.01 * -0.2019\n",
      "-----------------\n",
      "Finished episode: 628 Reward: -950.0913 total_loss = 9.5105 = -0.0197 + 0.5 * 19.0645 + 0.01 * -0.2030\n",
      "-----------------\n",
      "Finished episode: 629 Reward: -884.0724 total_loss = 12.2270 = -0.0996 + 0.5 * 24.6572 + 0.01 * -0.2026\n",
      "-----------------\n",
      "Finished episode: 630 Reward: -930.6865 total_loss = 10.9260 = -0.0629 + 0.5 * 21.9817 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 631 Reward: -959.0606 total_loss = 10.6409 = -0.0151 + 0.5 * 21.3160 + 0.01 * -0.2022\n",
      "-----------------\n",
      "Finished episode: 632 Reward: -958.8793 total_loss = 9.5660 = -0.0538 + 0.5 * 19.2436 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 633 Reward: -1008.9219 total_loss = 6.8564 = -0.0288 + 0.5 * 13.7745 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 634 Reward: -978.0011 total_loss = 9.4772 = 0.0512 + 0.5 * 18.8560 + 0.01 * -0.2018\n",
      "-----------------\n",
      "Finished episode: 635 Reward: -1003.4733 total_loss = 8.6104 = -0.1044 + 0.5 * 17.4337 + 0.01 * -0.2012\n",
      "-----------------\n",
      "Finished episode: 636 Reward: -982.1373 total_loss = 11.4508 = 0.0215 + 0.5 * 22.8625 + 0.01 * -0.2024\n",
      "-----------------\n",
      "Finished episode: 637 Reward: -995.7052 total_loss = 9.2970 = -0.0312 + 0.5 * 18.6606 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 638 Reward: -984.2099 total_loss = 8.6023 = -0.0140 + 0.5 * 17.2367 + 0.01 * -0.2025\n",
      "-----------------\n",
      "Finished episode: 639 Reward: -992.9318 total_loss = 8.4758 = -0.0020 + 0.5 * 16.9597 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 640 Reward: -929.5226 total_loss = 7.8019 = -0.0112 + 0.5 * 15.6302 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 641 Reward: -970.8983 total_loss = 8.0018 = 0.0927 + 0.5 * 15.8222 + 0.01 * -0.2012\n",
      "-----------------\n",
      "Finished episode: 642 Reward: -1004.7324 total_loss = 9.5979 = -0.0218 + 0.5 * 19.2433 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 643 Reward: -941.6394 total_loss = 10.1733 = 0.0316 + 0.5 * 20.2874 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 644 Reward: -1023.1184 total_loss = 7.6026 = -0.0584 + 0.5 * 15.3260 + 0.01 * -0.1996\n",
      "-----------------\n",
      "Finished episode: 645 Reward: -942.4300 total_loss = 7.8870 = 0.0881 + 0.5 * 15.6019 + 0.01 * -0.2026\n",
      "-----------------\n",
      "Finished episode: 646 Reward: -911.9839 total_loss = 7.5869 = 0.0841 + 0.5 * 15.0096 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 647 Reward: -1010.0365 total_loss = 9.7738 = 0.0090 + 0.5 * 19.5335 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 648 Reward: -988.9447 total_loss = 8.3026 = -0.0011 + 0.5 * 16.6114 + 0.01 * -0.2027\n",
      "-----------------\n",
      "Finished episode: 649 Reward: -952.3327 total_loss = 9.6166 = 0.0269 + 0.5 * 19.1836 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 650 Reward: -923.7097 total_loss = 8.2556 = -0.0230 + 0.5 * 16.5613 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 651 Reward: -886.9703 total_loss = 9.0982 = 0.0744 + 0.5 * 18.0516 + 0.01 * -0.2030\n",
      "-----------------\n",
      "Finished episode: 652 Reward: -978.1916 total_loss = 11.4353 = -0.0496 + 0.5 * 22.9739 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 653 Reward: -966.4028 total_loss = 9.0157 = -0.0930 + 0.5 * 18.2215 + 0.01 * -0.2018\n",
      "-----------------\n",
      "Finished episode: 654 Reward: -953.7929 total_loss = 9.0309 = 0.0345 + 0.5 * 17.9967 + 0.01 * -0.2023\n",
      "-----------------\n",
      "Finished episode: 655 Reward: -963.7191 total_loss = 10.1459 = 0.0051 + 0.5 * 20.2857 + 0.01 * -0.2026\n",
      "-----------------\n",
      "Finished episode: 656 Reward: -900.8517 total_loss = 11.2728 = 0.0195 + 0.5 * 22.5107 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 657 Reward: -1001.4819 total_loss = 8.3329 = 0.0617 + 0.5 * 16.5464 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 658 Reward: -980.6550 total_loss = 8.7483 = 0.0152 + 0.5 * 17.4702 + 0.01 * -0.2013\n",
      "-----------------\n",
      "Finished episode: 659 Reward: -1004.4923 total_loss = 10.9342 = 0.1111 + 0.5 * 21.6503 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 660 Reward: -1000.6792 total_loss = 9.9727 = -0.0201 + 0.5 * 19.9898 + 0.01 * -0.2005\n",
      "-----------------\n",
      "Finished episode: 661 Reward: -971.2316 total_loss = 7.8030 = -0.0465 + 0.5 * 15.7031 + 0.01 * -0.2024\n",
      "-----------------\n",
      "Finished episode: 662 Reward: -969.1072 total_loss = 9.2855 = -0.0484 + 0.5 * 18.6718 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 663 Reward: -979.8726 total_loss = 9.0347 = -0.0072 + 0.5 * 18.0878 + 0.01 * -0.2011\n",
      "-----------------\n",
      "Finished episode: 664 Reward: -930.0784 total_loss = 8.9208 = 0.0675 + 0.5 * 17.7106 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 665 Reward: -972.4035 total_loss = 8.6211 = 0.0811 + 0.5 * 17.0841 + 0.01 * -0.2009\n",
      "-----------------\n",
      "Finished episode: 666 Reward: -1014.3948 total_loss = 11.0767 = 0.0241 + 0.5 * 22.1092 + 0.01 * -0.2024\n",
      "-----------------\n",
      "Finished episode: 667 Reward: -991.5810 total_loss = 10.3975 = -0.0403 + 0.5 * 20.8797 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 668 Reward: -986.6370 total_loss = 11.4219 = 0.0595 + 0.5 * 22.7288 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 669 Reward: -989.7208 total_loss = 10.4228 = -0.0372 + 0.5 * 20.9240 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 670 Reward: -997.3716 total_loss = 8.2342 = -0.0378 + 0.5 * 16.5481 + 0.01 * -0.2016\n",
      "-----------------\n",
      "Finished episode: 671 Reward: -994.3682 total_loss = 7.4440 = 0.0135 + 0.5 * 14.8650 + 0.01 * -0.2020\n",
      "-----------------\n",
      "Finished episode: 672 Reward: -1007.7681 total_loss = 6.8411 = 0.0257 + 0.5 * 13.6347 + 0.01 * -0.2019\n",
      "-----------------\n",
      "Finished episode: 673 Reward: -1004.7863 total_loss = 9.4014 = -0.0852 + 0.5 * 18.9772 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 674 Reward: -1020.2942 total_loss = 9.9150 = 0.0324 + 0.5 * 19.7692 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 675 Reward: -976.6676 total_loss = 11.0030 = -0.0640 + 0.5 * 22.1381 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 676 Reward: -1006.8872 total_loss = 8.0524 = 0.0327 + 0.5 * 16.0433 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 677 Reward: -955.4964 total_loss = 9.6444 = 0.1027 + 0.5 * 19.0875 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 678 Reward: -943.7382 total_loss = 11.1162 = -0.1173 + 0.5 * 22.4711 + 0.01 * -0.2021\n",
      "-----------------\n",
      "Finished episode: 679 Reward: -978.4625 total_loss = 11.3523 = 0.0183 + 0.5 * 22.6721 + 0.01 * -0.2011\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 680 Reward: -979.1627 total_loss = 8.2047 = 0.0503 + 0.5 * 16.3128 + 0.01 * -0.2011\n",
      "-----------------\n",
      "Finished episode: 681 Reward: -1001.9501 total_loss = 11.7639 = -0.0282 + 0.5 * 23.5882 + 0.01 * -0.2019\n",
      "-----------------\n",
      "Finished episode: 682 Reward: -982.9258 total_loss = 9.9019 = -0.0469 + 0.5 * 19.9015 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 683 Reward: -1009.3097 total_loss = 10.5267 = -0.0071 + 0.5 * 21.0717 + 0.01 * -0.2018\n",
      "-----------------\n",
      "Finished episode: 684 Reward: -966.0409 total_loss = 9.4769 = 0.0676 + 0.5 * 18.8226 + 0.01 * -0.2017\n",
      "-----------------\n",
      "Finished episode: 685 Reward: -961.6917 total_loss = 8.6882 = 0.0463 + 0.5 * 17.2878 + 0.01 * -0.2016\n",
      "-----------------\n",
      "Finished episode: 686 Reward: -945.3526 total_loss = 8.5847 = 0.1007 + 0.5 * 16.9721 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 687 Reward: -1033.9137 total_loss = 10.7329 = -0.0263 + 0.5 * 21.5225 + 0.01 * -0.2011\n",
      "-----------------\n",
      "Finished episode: 688 Reward: -963.5145 total_loss = 9.2301 = -0.0315 + 0.5 * 18.5272 + 0.01 * -0.2013\n",
      "-----------------\n",
      "Finished episode: 689 Reward: -1000.1779 total_loss = 9.1624 = -0.0012 + 0.5 * 18.3312 + 0.01 * -0.2009\n",
      "-----------------\n",
      "Finished episode: 690 Reward: -981.4993 total_loss = 10.2703 = -0.0983 + 0.5 * 20.7414 + 0.01 * -0.2016\n",
      "-----------------\n",
      "Finished episode: 691 Reward: -955.9832 total_loss = 9.7936 = -0.0434 + 0.5 * 19.6779 + 0.01 * -0.2012\n",
      "-----------------\n",
      "Finished episode: 692 Reward: -913.4729 total_loss = 10.4847 = -0.0638 + 0.5 * 21.1010 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 693 Reward: -992.5226 total_loss = 10.8951 = 0.0528 + 0.5 * 21.6887 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 694 Reward: -933.8472 total_loss = 10.8306 = -0.0871 + 0.5 * 21.8394 + 0.01 * -0.2012\n",
      "-----------------\n",
      "Finished episode: 695 Reward: -1000.5096 total_loss = 8.0612 = -0.0831 + 0.5 * 16.2926 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 696 Reward: -941.1374 total_loss = 8.8713 = 0.0224 + 0.5 * 17.7019 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 697 Reward: -995.9524 total_loss = 8.8990 = -0.0638 + 0.5 * 17.9296 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 698 Reward: -994.0154 total_loss = 8.7616 = 0.0118 + 0.5 * 17.5036 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 699 Reward: -982.5043 total_loss = 9.4919 = 0.0068 + 0.5 * 18.9741 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 700 Reward: -1001.1790 total_loss = 8.0755 = 0.0509 + 0.5 * 16.0533 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 701 Reward: -1010.8409 total_loss = 10.1129 = 0.0596 + 0.5 * 20.1105 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 702 Reward: -1006.4796 total_loss = 10.1489 = 0.0885 + 0.5 * 20.1249 + 0.01 * -0.2002\n",
      "-----------------\n",
      "Finished episode: 703 Reward: -1025.5097 total_loss = 11.4954 = -0.0357 + 0.5 * 23.0661 + 0.01 * -0.2013\n",
      "-----------------\n",
      "Finished episode: 704 Reward: -1018.7995 total_loss = 11.8401 = 0.0568 + 0.5 * 23.5706 + 0.01 * -0.2011\n",
      "-----------------\n",
      "Finished episode: 705 Reward: -1008.6607 total_loss = 11.8440 = 0.0528 + 0.5 * 23.5863 + 0.01 * -0.1996\n",
      "-----------------\n",
      "Finished episode: 706 Reward: -1008.0835 total_loss = 9.7076 = -0.0066 + 0.5 * 19.4323 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 707 Reward: -961.0053 total_loss = 9.0750 = -0.0281 + 0.5 * 18.2101 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 708 Reward: -953.4189 total_loss = 10.5688 = 0.1082 + 0.5 * 20.9252 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 709 Reward: -963.6984 total_loss = 9.3372 = -0.0262 + 0.5 * 18.7308 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 710 Reward: -1037.0437 total_loss = 10.3591 = 0.0588 + 0.5 * 20.6046 + 0.01 * -0.2013\n",
      "-----------------\n",
      "Finished episode: 711 Reward: -939.0835 total_loss = 11.4264 = -0.0828 + 0.5 * 23.0225 + 0.01 * -0.2012\n",
      "-----------------\n",
      "Finished episode: 712 Reward: -994.3201 total_loss = 8.0783 = -0.0059 + 0.5 * 16.1724 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 713 Reward: -1044.4639 total_loss = 9.9405 = 0.0125 + 0.5 * 19.8600 + 0.01 * -0.1997\n",
      "-----------------\n",
      "Finished episode: 714 Reward: -1004.3797 total_loss = 9.1511 = 0.0548 + 0.5 * 18.1967 + 0.01 * -0.2002\n",
      "-----------------\n",
      "Finished episode: 715 Reward: -1030.6919 total_loss = 11.0006 = 0.0592 + 0.5 * 21.8868 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 716 Reward: -1002.2820 total_loss = 10.7432 = -0.0170 + 0.5 * 21.5245 + 0.01 * -0.2009\n",
      "-----------------\n",
      "Finished episode: 717 Reward: -1024.9328 total_loss = 10.2707 = 0.0219 + 0.5 * 20.5015 + 0.01 * -0.1997\n",
      "-----------------\n",
      "Finished episode: 718 Reward: -1037.4918 total_loss = 9.6957 = -0.0653 + 0.5 * 19.5259 + 0.01 * -0.2011\n",
      "-----------------\n",
      "Finished episode: 719 Reward: -1019.3670 total_loss = 8.4451 = 0.0212 + 0.5 * 16.8517 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 720 Reward: -1022.4522 total_loss = 8.5243 = 0.1248 + 0.5 * 16.8030 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 721 Reward: -983.8620 total_loss = 12.1581 = -0.0741 + 0.5 * 24.4685 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 722 Reward: -963.2897 total_loss = 9.8199 = -0.0856 + 0.5 * 19.8150 + 0.01 * -0.2016\n",
      "-----------------\n",
      "Finished episode: 723 Reward: -952.5717 total_loss = 9.4868 = 0.0100 + 0.5 * 18.9576 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 724 Reward: -1042.8654 total_loss = 9.7914 = -0.0289 + 0.5 * 19.6447 + 0.01 * -0.2002\n",
      "-----------------\n",
      "Finished episode: 725 Reward: -981.2700 total_loss = 10.7362 = 0.0304 + 0.5 * 21.4156 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 726 Reward: -973.7379 total_loss = 10.3477 = 0.0504 + 0.5 * 20.5985 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 727 Reward: -975.6881 total_loss = 10.6480 = 0.0521 + 0.5 * 21.1958 + 0.01 * -0.2016\n",
      "-----------------\n",
      "Finished episode: 728 Reward: -1013.5303 total_loss = 9.7457 = -0.0439 + 0.5 * 19.5833 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 729 Reward: -980.3463 total_loss = 9.8888 = -0.0178 + 0.5 * 19.8172 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 730 Reward: -1082.2628 total_loss = 11.4564 = -0.0006 + 0.5 * 22.9180 + 0.01 * -0.1996\n",
      "-----------------\n",
      "Finished episode: 731 Reward: -1006.2492 total_loss = 11.0844 = -0.0639 + 0.5 * 22.3006 + 0.01 * -0.2015\n",
      "-----------------\n",
      "Finished episode: 732 Reward: -1035.7178 total_loss = 10.4732 = 0.0416 + 0.5 * 20.8673 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 733 Reward: -1075.0234 total_loss = 9.9458 = -0.0639 + 0.5 * 20.0233 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 734 Reward: -1017.5299 total_loss = 8.5288 = 0.0304 + 0.5 * 17.0008 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 735 Reward: -969.0844 total_loss = 10.8784 = 0.0661 + 0.5 * 21.6287 + 0.01 * -0.2002\n",
      "-----------------\n",
      "Finished episode: 736 Reward: -1032.4575 total_loss = 10.7680 = -0.0387 + 0.5 * 21.6174 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 737 Reward: -1020.6931 total_loss = 11.4095 = 0.0676 + 0.5 * 22.6879 + 0.01 * -0.2008\n",
      "-----------------\n",
      "Finished episode: 738 Reward: -1067.3382 total_loss = 10.7695 = -0.0891 + 0.5 * 21.7213 + 0.01 * -0.2010\n",
      "-----------------\n",
      "Finished episode: 739 Reward: -1009.1730 total_loss = 9.6929 = 0.0835 + 0.5 * 19.2229 + 0.01 * -0.2000\n",
      "-----------------\n",
      "Finished episode: 740 Reward: -1056.6319 total_loss = 9.0644 = 0.0105 + 0.5 * 18.1117 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 741 Reward: -1013.1549 total_loss = 11.8733 = -0.0679 + 0.5 * 23.8864 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 742 Reward: -990.5362 total_loss = 11.1364 = 0.0768 + 0.5 * 22.1232 + 0.01 * -0.2000\n",
      "-----------------\n",
      "Finished episode: 743 Reward: -993.5505 total_loss = 12.0820 = -0.0369 + 0.5 * 24.2419 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 744 Reward: -990.8565 total_loss = 11.5539 = 0.1043 + 0.5 * 22.9033 + 0.01 * -0.2005\n",
      "-----------------\n",
      "Finished episode: 745 Reward: -990.3362 total_loss = 11.4049 = -0.0205 + 0.5 * 22.8548 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 746 Reward: -1012.6038 total_loss = 9.2811 = -0.0124 + 0.5 * 18.5909 + 0.01 * -0.2003\n",
      "-----------------\n",
      "Finished episode: 747 Reward: -998.1706 total_loss = 8.6037 = 0.0109 + 0.5 * 17.1897 + 0.01 * -0.2006\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 748 Reward: -955.8878 total_loss = 9.6672 = -0.0338 + 0.5 * 19.4062 + 0.01 * -0.2014\n",
      "-----------------\n",
      "Finished episode: 749 Reward: -1012.1188 total_loss = 10.6350 = -0.0933 + 0.5 * 21.4606 + 0.01 * -0.2011\n",
      "-----------------\n",
      "Finished episode: 750 Reward: -1037.1851 total_loss = 8.2455 = 0.0372 + 0.5 * 16.4206 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 751 Reward: -981.5060 total_loss = 9.3491 = -0.0377 + 0.5 * 18.7776 + 0.01 * -0.2019\n",
      "-----------------\n",
      "Finished episode: 752 Reward: -996.1754 total_loss = 10.6187 = 0.0070 + 0.5 * 21.2273 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 753 Reward: -1014.3536 total_loss = 9.9199 = 0.0977 + 0.5 * 19.6484 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 754 Reward: -1046.3428 total_loss = 9.4356 = 0.0091 + 0.5 * 18.8569 + 0.01 * -0.2013\n",
      "-----------------\n",
      "Finished episode: 755 Reward: -1002.7620 total_loss = 10.2124 = 0.0114 + 0.5 * 20.4058 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 756 Reward: -1003.0589 total_loss = 11.1578 = -0.0577 + 0.5 * 22.4349 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 757 Reward: -991.7860 total_loss = 12.1153 = -0.0115 + 0.5 * 24.2576 + 0.01 * -0.2005\n",
      "-----------------\n",
      "Finished episode: 758 Reward: -987.3381 total_loss = 11.2134 = -0.1275 + 0.5 * 22.6860 + 0.01 * -0.2013\n",
      "-----------------\n",
      "Finished episode: 759 Reward: -1019.3200 total_loss = 7.9360 = 0.0768 + 0.5 * 15.7225 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 760 Reward: -1024.9084 total_loss = 9.9948 = 0.0283 + 0.5 * 19.9371 + 0.01 * -0.2007\n",
      "-----------------\n",
      "Finished episode: 761 Reward: -992.5036 total_loss = 9.9841 = 0.0112 + 0.5 * 19.9498 + 0.01 * -0.2000\n",
      "-----------------\n",
      "Finished episode: 762 Reward: -978.9702 total_loss = 11.6900 = -0.0370 + 0.5 * 23.4580 + 0.01 * -0.2006\n",
      "-----------------\n",
      "Finished episode: 763 Reward: -1027.3772 total_loss = 9.2532 = -0.0661 + 0.5 * 18.6426 + 0.01 * -0.1994\n",
      "-----------------\n",
      "Finished episode: 764 Reward: -1048.7742 total_loss = 9.5440 = 0.1066 + 0.5 * 18.8788 + 0.01 * -0.2000\n",
      "-----------------\n",
      "Finished episode: 765 Reward: -988.1552 total_loss = 10.6716 = -0.0004 + 0.5 * 21.3480 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 766 Reward: -1054.8323 total_loss = 8.4602 = 0.0783 + 0.5 * 16.7677 + 0.01 * -0.1991\n",
      "-----------------\n",
      "Finished episode: 767 Reward: -1017.5244 total_loss = 8.6076 = 0.0323 + 0.5 * 17.1546 + 0.01 * -0.2002\n",
      "-----------------\n",
      "Finished episode: 768 Reward: -963.9487 total_loss = 10.6879 = 0.0458 + 0.5 * 21.2883 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 769 Reward: -1018.1858 total_loss = 10.2958 = 0.0512 + 0.5 * 20.4932 + 0.01 * -0.2005\n",
      "-----------------\n",
      "Finished episode: 770 Reward: -1013.1694 total_loss = 10.0784 = -0.0316 + 0.5 * 20.2239 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 771 Reward: -1051.9405 total_loss = 7.5521 = 0.0256 + 0.5 * 15.0569 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 772 Reward: -991.2060 total_loss = 10.1879 = -0.0253 + 0.5 * 20.4303 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 773 Reward: -1022.2746 total_loss = 9.3173 = 0.0142 + 0.5 * 18.6101 + 0.01 * -0.2004\n",
      "-----------------\n",
      "Finished episode: 774 Reward: -961.8097 total_loss = 10.3118 = -0.0817 + 0.5 * 20.7910 + 0.01 * -0.1993\n",
      "-----------------\n",
      "Finished episode: 775 Reward: -1073.0322 total_loss = 9.0261 = 0.0105 + 0.5 * 18.0352 + 0.01 * -0.1994\n",
      "-----------------\n",
      "Finished episode: 776 Reward: -1039.3457 total_loss = 8.0015 = 0.0457 + 0.5 * 15.9156 + 0.01 * -0.1997\n",
      "-----------------\n",
      "Finished episode: 777 Reward: -1081.9565 total_loss = 8.2240 = -0.0607 + 0.5 * 16.5734 + 0.01 * -0.1991\n",
      "-----------------\n",
      "Finished episode: 778 Reward: -984.3759 total_loss = 10.2917 = 0.0077 + 0.5 * 20.5719 + 0.01 * -0.1996\n",
      "-----------------\n",
      "Finished episode: 779 Reward: -1019.2304 total_loss = 8.9202 = 0.0615 + 0.5 * 17.7213 + 0.01 * -0.1999\n",
      "-----------------\n",
      "Finished episode: 780 Reward: -996.0965 total_loss = 9.5841 = 0.0528 + 0.5 * 19.0666 + 0.01 * -0.2001\n",
      "-----------------\n",
      "Finished episode: 781 Reward: -983.8095 total_loss = 10.4855 = 0.0565 + 0.5 * 20.8620 + 0.01 * -0.1997\n",
      "-----------------\n",
      "Finished episode: 782 Reward: -1002.6599 total_loss = 12.1000 = 0.0454 + 0.5 * 24.1131 + 0.01 * -0.1987\n",
      "-----------------\n",
      "Finished episode: 783 Reward: -993.6240 total_loss = 10.0123 = 0.0147 + 0.5 * 19.9992 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 784 Reward: -1030.5747 total_loss = 11.2066 = -0.0636 + 0.5 * 22.5445 + 0.01 * -0.1993\n",
      "-----------------\n",
      "Finished episode: 785 Reward: -1032.1635 total_loss = 10.2504 = 0.0204 + 0.5 * 20.4640 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 786 Reward: -1024.3459 total_loss = 11.7333 = -0.0804 + 0.5 * 23.6314 + 0.01 * -0.1986\n",
      "-----------------\n",
      "Finished episode: 787 Reward: -1025.0645 total_loss = 9.5975 = 0.0037 + 0.5 * 19.1915 + 0.01 * -0.1992\n",
      "-----------------\n",
      "Finished episode: 788 Reward: -1043.0193 total_loss = 9.5832 = -0.0636 + 0.5 * 19.2976 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 789 Reward: -985.7732 total_loss = 10.0092 = 0.0023 + 0.5 * 20.0177 + 0.01 * -0.2000\n",
      "-----------------\n",
      "Finished episode: 790 Reward: -1086.6565 total_loss = 9.6394 = -0.0138 + 0.5 * 19.3105 + 0.01 * -0.1992\n",
      "-----------------\n",
      "Finished episode: 791 Reward: -1012.0992 total_loss = 11.1529 = -0.0881 + 0.5 * 22.4860 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 792 Reward: -1048.5090 total_loss = 9.4783 = 0.0829 + 0.5 * 18.7948 + 0.01 * -0.1993\n",
      "-----------------\n",
      "Finished episode: 793 Reward: -1054.6186 total_loss = 9.5647 = 0.0072 + 0.5 * 19.1189 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 794 Reward: -988.2624 total_loss = 10.5008 = 0.0696 + 0.5 * 20.8664 + 0.01 * -0.1998\n",
      "-----------------\n",
      "Finished episode: 795 Reward: -1008.4045 total_loss = 13.1389 = -0.0087 + 0.5 * 26.2990 + 0.01 * -0.1987\n",
      "-----------------\n",
      "Finished episode: 796 Reward: -956.1458 total_loss = 11.3434 = -0.0215 + 0.5 * 22.7336 + 0.01 * -0.1993\n",
      "-----------------\n",
      "Finished episode: 797 Reward: -993.5341 total_loss = 9.2969 = 0.0930 + 0.5 * 18.4118 + 0.01 * -0.1992\n",
      "-----------------\n",
      "Finished episode: 798 Reward: -1034.7148 total_loss = 11.0618 = 0.0338 + 0.5 * 22.0600 + 0.01 * -0.1988\n",
      "-----------------\n",
      "Finished episode: 799 Reward: -993.6451 total_loss = 9.4772 = 0.1214 + 0.5 * 18.7155 + 0.01 * -0.1989\n",
      "-----------------\n",
      "Finished episode: 800 Reward: -1091.2011 total_loss = 8.4272 = 0.0118 + 0.5 * 16.8349 + 0.01 * -0.1986\n",
      "-----------------\n",
      "Finished episode: 801 Reward: -1068.6978 total_loss = 9.6154 = -0.0175 + 0.5 * 19.2698 + 0.01 * -0.1986\n",
      "-----------------\n",
      "Finished episode: 802 Reward: -1018.6145 total_loss = 9.7791 = -0.0190 + 0.5 * 19.6002 + 0.01 * -0.1991\n",
      "-----------------\n",
      "Finished episode: 803 Reward: -1009.1723 total_loss = 9.9110 = 0.1400 + 0.5 * 19.5458 + 0.01 * -0.1982\n",
      "-----------------\n",
      "Finished episode: 804 Reward: -1109.5470 total_loss = 10.8249 = 0.0882 + 0.5 * 21.4772 + 0.01 * -0.1979\n",
      "-----------------\n",
      "Finished episode: 805 Reward: -1045.5122 total_loss = 11.0571 = -0.0456 + 0.5 * 22.2093 + 0.01 * -0.1988\n",
      "-----------------\n",
      "Finished episode: 806 Reward: -1016.8831 total_loss = 12.7403 = 0.0203 + 0.5 * 25.4439 + 0.01 * -0.1982\n",
      "-----------------\n",
      "Finished episode: 807 Reward: -1070.6588 total_loss = 11.8024 = -0.0077 + 0.5 * 23.6241 + 0.01 * -0.1984\n",
      "-----------------\n",
      "Finished episode: 808 Reward: -1125.7262 total_loss = 8.9441 = -0.0288 + 0.5 * 17.9499 + 0.01 * -0.1988\n",
      "-----------------\n",
      "Finished episode: 809 Reward: -1069.3170 total_loss = 12.0029 = -0.0184 + 0.5 * 24.0466 + 0.01 * -0.1981\n",
      "-----------------\n",
      "Finished episode: 810 Reward: -1043.3738 total_loss = 9.3633 = 0.0827 + 0.5 * 18.5651 + 0.01 * -0.1978\n",
      "-----------------\n",
      "Finished episode: 811 Reward: -1095.5570 total_loss = 9.0087 = 0.0756 + 0.5 * 17.8703 + 0.01 * -0.1978\n",
      "-----------------\n",
      "Finished episode: 812 Reward: -1067.7916 total_loss = 10.3697 = -0.0096 + 0.5 * 20.7625 + 0.01 * -0.1979\n",
      "-----------------\n",
      "Finished episode: 813 Reward: -1028.5584 total_loss = 11.0580 = 0.0109 + 0.5 * 22.0983 + 0.01 * -0.1981\n",
      "-----------------\n",
      "Finished episode: 814 Reward: -1073.2303 total_loss = 10.4862 = 0.0127 + 0.5 * 20.9510 + 0.01 * -0.1986\n",
      "-----------------\n",
      "Finished episode: 815 Reward: -1017.1165 total_loss = 10.8584 = 0.0245 + 0.5 * 21.6716 + 0.01 * -0.1982\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 816 Reward: -1100.7885 total_loss = 8.1767 = -0.0623 + 0.5 * 16.4819 + 0.01 * -0.1989\n",
      "-----------------\n",
      "Finished episode: 817 Reward: -1088.0240 total_loss = 8.1036 = -0.1048 + 0.5 * 16.4208 + 0.01 * -0.1991\n",
      "-----------------\n",
      "Finished episode: 818 Reward: -1066.0966 total_loss = 8.0532 = 0.0682 + 0.5 * 15.9740 + 0.01 * -0.1985\n",
      "-----------------\n",
      "Finished episode: 819 Reward: -1050.1435 total_loss = 9.3189 = -0.0077 + 0.5 * 18.6571 + 0.01 * -0.1986\n",
      "-----------------\n",
      "Finished episode: 820 Reward: -1027.5868 total_loss = 12.1347 = -0.0565 + 0.5 * 24.3864 + 0.01 * -0.1983\n",
      "-----------------\n",
      "Finished episode: 821 Reward: -1043.1729 total_loss = 10.8990 = 0.0286 + 0.5 * 21.7447 + 0.01 * -0.1985\n",
      "-----------------\n",
      "Finished episode: 822 Reward: -1059.7141 total_loss = 10.2747 = -0.0036 + 0.5 * 20.5605 + 0.01 * -0.1977\n",
      "-----------------\n",
      "Finished episode: 823 Reward: -962.2310 total_loss = 11.2287 = 0.0383 + 0.5 * 22.3847 + 0.01 * -0.1980\n",
      "-----------------\n",
      "Finished episode: 824 Reward: -1094.1648 total_loss = 9.9592 = 0.0825 + 0.5 * 19.7574 + 0.01 * -0.1976\n",
      "-----------------\n",
      "Finished episode: 825 Reward: -1013.4663 total_loss = 10.6431 = -0.0712 + 0.5 * 21.4326 + 0.01 * -0.1986\n",
      "-----------------\n",
      "Finished episode: 826 Reward: -1078.6328 total_loss = 12.9455 = -0.0330 + 0.5 * 25.9610 + 0.01 * -0.1973\n",
      "-----------------\n",
      "Finished episode: 827 Reward: -1052.4673 total_loss = 10.0035 = -0.0337 + 0.5 * 20.0782 + 0.01 * -0.1980\n",
      "-----------------\n",
      "Finished episode: 828 Reward: -1016.8838 total_loss = 12.8653 = -0.0896 + 0.5 * 25.9137 + 0.01 * -0.1973\n",
      "-----------------\n",
      "Finished episode: 829 Reward: -1065.5376 total_loss = 13.9245 = -0.0814 + 0.5 * 28.0158 + 0.01 * -0.1968\n",
      "-----------------\n",
      "Finished episode: 830 Reward: -1028.1765 total_loss = 11.8531 = -0.1120 + 0.5 * 23.9342 + 0.01 * -0.1974\n",
      "-----------------\n",
      "Finished episode: 831 Reward: -1075.3537 total_loss = 10.5709 = 0.0113 + 0.5 * 21.1231 + 0.01 * -0.1972\n",
      "-----------------\n",
      "Finished episode: 832 Reward: -1119.4761 total_loss = 13.0766 = -0.0341 + 0.5 * 26.2254 + 0.01 * -0.1968\n",
      "-----------------\n",
      "Finished episode: 833 Reward: -1122.3395 total_loss = 11.8490 = 0.0785 + 0.5 * 23.5448 + 0.01 * -0.1967\n",
      "-----------------\n",
      "Finished episode: 834 Reward: -1101.6108 total_loss = 12.0141 = 0.0367 + 0.5 * 23.9588 + 0.01 * -0.1969\n",
      "-----------------\n",
      "Finished episode: 835 Reward: -1091.3174 total_loss = 9.3184 = -0.0178 + 0.5 * 18.6764 + 0.01 * -0.1972\n",
      "-----------------\n",
      "Finished episode: 836 Reward: -1117.2088 total_loss = 10.8839 = 0.0066 + 0.5 * 21.7586 + 0.01 * -0.1976\n",
      "-----------------\n",
      "Finished episode: 837 Reward: -1022.3863 total_loss = 11.6662 = 0.0848 + 0.5 * 23.1667 + 0.01 * -0.1974\n",
      "-----------------\n",
      "Finished episode: 838 Reward: -1101.3034 total_loss = 9.0432 = -0.0319 + 0.5 * 18.1543 + 0.01 * -0.1974\n",
      "-----------------\n",
      "Finished episode: 839 Reward: -1103.5156 total_loss = 11.4431 = -0.0541 + 0.5 * 22.9984 + 0.01 * -0.1969\n",
      "-----------------\n",
      "Finished episode: 840 Reward: -1103.2084 total_loss = 12.0648 = -0.0534 + 0.5 * 24.2404 + 0.01 * -0.1972\n",
      "-----------------\n",
      "Finished episode: 841 Reward: -1033.9281 total_loss = 12.4585 = 0.1396 + 0.5 * 24.6417 + 0.01 * -0.1970\n",
      "-----------------\n",
      "Finished episode: 842 Reward: -1069.3904 total_loss = 10.1561 = 0.0640 + 0.5 * 20.1881 + 0.01 * -0.1966\n",
      "-----------------\n",
      "Finished episode: 843 Reward: -1064.4552 total_loss = 11.6407 = 0.0232 + 0.5 * 23.2389 + 0.01 * -0.1966\n",
      "-----------------\n",
      "Finished episode: 844 Reward: -1018.3568 total_loss = 12.5882 = 0.0391 + 0.5 * 25.1022 + 0.01 * -0.1968\n",
      "-----------------\n",
      "Finished episode: 845 Reward: -1059.3589 total_loss = 12.5024 = 0.0643 + 0.5 * 24.8801 + 0.01 * -0.1968\n",
      "-----------------\n",
      "Finished episode: 846 Reward: -1072.9968 total_loss = 12.3792 = -0.0566 + 0.5 * 24.8754 + 0.01 * -0.1967\n",
      "-----------------\n",
      "Finished episode: 847 Reward: -1032.0085 total_loss = 12.3604 = 0.0403 + 0.5 * 24.6441 + 0.01 * -0.1967\n",
      "-----------------\n",
      "Finished episode: 848 Reward: -1126.4489 total_loss = 10.0586 = 0.0047 + 0.5 * 20.1118 + 0.01 * -0.1968\n",
      "-----------------\n",
      "Finished episode: 849 Reward: -1103.6197 total_loss = 12.1479 = -0.0162 + 0.5 * 24.3320 + 0.01 * -0.1963\n",
      "-----------------\n",
      "Finished episode: 850 Reward: -1084.8237 total_loss = 11.2107 = 0.0460 + 0.5 * 22.3335 + 0.01 * -0.1969\n",
      "-----------------\n",
      "Finished episode: 851 Reward: -1055.0786 total_loss = 10.4768 = -0.0281 + 0.5 * 21.0138 + 0.01 * -0.1962\n",
      "-----------------\n",
      "Finished episode: 852 Reward: -1140.7658 total_loss = 12.8684 = 0.0091 + 0.5 * 25.7225 + 0.01 * -0.1966\n",
      "-----------------\n",
      "Finished episode: 853 Reward: -1082.9107 total_loss = 13.7505 = 0.0027 + 0.5 * 27.4994 + 0.01 * -0.1969\n",
      "-----------------\n",
      "Finished episode: 854 Reward: -1158.6164 total_loss = 11.5014 = 0.0449 + 0.5 * 22.9169 + 0.01 * -0.1965\n",
      "-----------------\n",
      "Finished episode: 855 Reward: -1066.4006 total_loss = 11.6725 = 0.0086 + 0.5 * 23.3317 + 0.01 * -0.1965\n",
      "-----------------\n",
      "Finished episode: 856 Reward: -1171.8393 total_loss = 15.2632 = -0.0579 + 0.5 * 30.6462 + 0.01 * -0.1964\n",
      "-----------------\n",
      "Finished episode: 857 Reward: -1156.2396 total_loss = 11.9633 = 0.0941 + 0.5 * 23.7423 + 0.01 * -0.1968\n",
      "-----------------\n",
      "Finished episode: 858 Reward: -1156.1721 total_loss = 11.5117 = 0.0683 + 0.5 * 22.8907 + 0.01 * -0.1963\n",
      "-----------------\n",
      "Finished episode: 859 Reward: -1130.5395 total_loss = 13.2823 = 0.0315 + 0.5 * 26.5055 + 0.01 * -0.1967\n",
      "-----------------\n",
      "Finished episode: 860 Reward: -1139.3215 total_loss = 12.0235 = -0.0565 + 0.5 * 24.1638 + 0.01 * -0.1961\n",
      "-----------------\n",
      "Finished episode: 861 Reward: -1095.1706 total_loss = 13.3098 = -0.0724 + 0.5 * 26.7684 + 0.01 * -0.1962\n",
      "-----------------\n",
      "Finished episode: 862 Reward: -1072.1837 total_loss = 16.7567 = 0.0214 + 0.5 * 33.4747 + 0.01 * -0.1961\n",
      "-----------------\n",
      "Finished episode: 863 Reward: -1125.2849 total_loss = 12.3765 = 0.0431 + 0.5 * 24.6707 + 0.01 * -0.1966\n",
      "-----------------\n",
      "Finished episode: 864 Reward: -1148.6610 total_loss = 12.4386 = 0.0756 + 0.5 * 24.7299 + 0.01 * -0.1966\n",
      "-----------------\n",
      "Finished episode: 865 Reward: -1171.0707 total_loss = 15.3086 = -0.0917 + 0.5 * 30.8046 + 0.01 * -0.1968\n",
      "-----------------\n",
      "Finished episode: 866 Reward: -1041.6696 total_loss = 13.2487 = 0.0883 + 0.5 * 26.3248 + 0.01 * -0.1967\n",
      "-----------------\n",
      "Finished episode: 867 Reward: -1148.6638 total_loss = 13.8341 = -0.0863 + 0.5 * 27.8446 + 0.01 * -0.1965\n",
      "-----------------\n",
      "Finished episode: 868 Reward: -1172.4608 total_loss = 11.8824 = 0.1026 + 0.5 * 23.5635 + 0.01 * -0.1962\n",
      "-----------------\n",
      "Finished episode: 869 Reward: -1154.2678 total_loss = 15.3516 = 0.0837 + 0.5 * 30.5396 + 0.01 * -0.1964\n",
      "-----------------\n",
      "Finished episode: 870 Reward: -1083.6867 total_loss = 12.6540 = -0.0878 + 0.5 * 25.4874 + 0.01 * -0.1965\n",
      "-----------------\n",
      "Finished episode: 871 Reward: -1096.7113 total_loss = 13.1459 = -0.0143 + 0.5 * 26.3243 + 0.01 * -0.1963\n",
      "-----------------\n",
      "Finished episode: 872 Reward: -1185.0415 total_loss = 15.5392 = 0.0363 + 0.5 * 31.0097 + 0.01 * -0.1955\n",
      "-----------------\n",
      "Finished episode: 873 Reward: -1127.4713 total_loss = 12.8793 = 0.0552 + 0.5 * 25.6521 + 0.01 * -0.1961\n",
      "-----------------\n",
      "Finished episode: 874 Reward: -1186.0235 total_loss = 15.3413 = -0.0305 + 0.5 * 30.7477 + 0.01 * -0.1960\n",
      "-----------------\n",
      "Finished episode: 875 Reward: -1223.0508 total_loss = 17.3132 = -0.0290 + 0.5 * 34.6884 + 0.01 * -0.1959\n",
      "-----------------\n",
      "Finished episode: 876 Reward: -1119.9027 total_loss = 11.7340 = -0.0014 + 0.5 * 23.4746 + 0.01 * -0.1957\n",
      "-----------------\n",
      "Finished episode: 877 Reward: -1116.8241 total_loss = 13.9077 = -0.0308 + 0.5 * 27.8810 + 0.01 * -0.1956\n",
      "-----------------\n",
      "Finished episode: 878 Reward: -1141.6220 total_loss = 15.0619 = 0.0527 + 0.5 * 30.0223 + 0.01 * -0.1952\n",
      "-----------------\n",
      "Finished episode: 879 Reward: -1197.6286 total_loss = 15.0727 = -0.0086 + 0.5 * 30.1665 + 0.01 * -0.1955\n",
      "-----------------\n",
      "Finished episode: 880 Reward: -1178.1395 total_loss = 13.4509 = 0.0905 + 0.5 * 26.7246 + 0.01 * -0.1962\n",
      "-----------------\n",
      "Finished episode: 881 Reward: -1082.5445 total_loss = 14.7759 = -0.0973 + 0.5 * 29.7502 + 0.01 * -0.1952\n",
      "-----------------\n",
      "Finished episode: 882 Reward: -1123.7867 total_loss = 13.2708 = 0.0268 + 0.5 * 26.4918 + 0.01 * -0.1956\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 883 Reward: -1173.7433 total_loss = 16.0021 = 0.0107 + 0.5 * 31.9867 + 0.01 * -0.1951\n",
      "-----------------\n",
      "Finished episode: 884 Reward: -1178.1972 total_loss = 15.2615 = -0.0311 + 0.5 * 30.5892 + 0.01 * -0.1956\n",
      "-----------------\n",
      "Finished episode: 885 Reward: -1202.8844 total_loss = 15.2613 = 0.0128 + 0.5 * 30.5010 + 0.01 * -0.1950\n",
      "-----------------\n",
      "Finished episode: 886 Reward: -1145.6037 total_loss = 13.6880 = 0.0907 + 0.5 * 27.1984 + 0.01 * -0.1955\n",
      "-----------------\n",
      "Finished episode: 887 Reward: -1103.1397 total_loss = 15.5783 = -0.1445 + 0.5 * 31.4496 + 0.01 * -0.1953\n",
      "-----------------\n",
      "Finished episode: 888 Reward: -1113.6866 total_loss = 14.3704 = -0.0195 + 0.5 * 28.7837 + 0.01 * -0.1950\n",
      "-----------------\n",
      "Finished episode: 889 Reward: -1086.9363 total_loss = 12.7669 = 0.0574 + 0.5 * 25.4228 + 0.01 * -0.1952\n",
      "-----------------\n",
      "Finished episode: 890 Reward: -1166.3235 total_loss = 15.1953 = 0.0647 + 0.5 * 30.2650 + 0.01 * -0.1948\n",
      "-----------------\n",
      "Finished episode: 891 Reward: -1072.8724 total_loss = 12.5817 = 0.1927 + 0.5 * 24.7820 + 0.01 * -0.1944\n",
      "-----------------\n",
      "Finished episode: 892 Reward: -1124.6388 total_loss = 14.3893 = -0.0052 + 0.5 * 28.7928 + 0.01 * -0.1947\n",
      "-----------------\n",
      "Finished episode: 893 Reward: -1112.4986 total_loss = 14.3878 = -0.0271 + 0.5 * 28.8338 + 0.01 * -0.1946\n",
      "-----------------\n",
      "Finished episode: 894 Reward: -1137.6352 total_loss = 12.7126 = -0.0577 + 0.5 * 25.5445 + 0.01 * -0.1945\n",
      "-----------------\n",
      "Finished episode: 895 Reward: -1110.2553 total_loss = 13.4553 = 0.0497 + 0.5 * 26.8151 + 0.01 * -0.1950\n",
      "-----------------\n",
      "Finished episode: 896 Reward: -1109.8305 total_loss = 12.9104 = 0.0964 + 0.5 * 25.6319 + 0.01 * -0.1948\n",
      "-----------------\n",
      "Finished episode: 897 Reward: -1176.9662 total_loss = 14.2592 = 0.0411 + 0.5 * 28.4401 + 0.01 * -0.1944\n",
      "-----------------\n",
      "Finished episode: 898 Reward: -1081.5713 total_loss = 10.6839 = 0.0589 + 0.5 * 21.2539 + 0.01 * -0.1948\n",
      "-----------------\n",
      "Finished episode: 899 Reward: -1109.9523 total_loss = 14.0508 = 0.0151 + 0.5 * 28.0752 + 0.01 * -0.1940\n",
      "-----------------\n",
      "Finished episode: 900 Reward: -1085.5046 total_loss = 13.4302 = 0.0139 + 0.5 * 26.8365 + 0.01 * -0.1944\n",
      "-----------------\n",
      "Finished episode: 901 Reward: -1126.2373 total_loss = 12.1641 = 0.0647 + 0.5 * 24.2027 + 0.01 * -0.1943\n",
      "-----------------\n",
      "Finished episode: 902 Reward: -1115.7487 total_loss = 14.6204 = 0.0333 + 0.5 * 29.1781 + 0.01 * -0.1941\n",
      "-----------------\n",
      "Finished episode: 903 Reward: -1074.1432 total_loss = 12.6100 = 0.0531 + 0.5 * 25.1175 + 0.01 * -0.1938\n",
      "-----------------\n",
      "Finished episode: 904 Reward: -1107.4177 total_loss = 13.2198 = -0.0081 + 0.5 * 26.4597 + 0.01 * -0.1941\n",
      "-----------------\n",
      "Finished episode: 905 Reward: -1163.3849 total_loss = 13.9915 = -0.0345 + 0.5 * 28.0559 + 0.01 * -0.1934\n",
      "-----------------\n",
      "Finished episode: 906 Reward: -1072.4199 total_loss = 15.6199 = 0.0260 + 0.5 * 31.1917 + 0.01 * -0.1940\n",
      "-----------------\n",
      "Finished episode: 907 Reward: -1149.8152 total_loss = 13.7802 = -0.0219 + 0.5 * 27.6080 + 0.01 * -0.1941\n",
      "-----------------\n",
      "Finished episode: 908 Reward: -1129.8059 total_loss = 13.1220 = -0.0035 + 0.5 * 26.2549 + 0.01 * -0.1943\n",
      "-----------------\n",
      "Finished episode: 909 Reward: -1199.5088 total_loss = 13.1326 = -0.0279 + 0.5 * 26.3247 + 0.01 * -0.1941\n",
      "-----------------\n",
      "Finished episode: 910 Reward: -1154.2667 total_loss = 12.8649 = -0.0641 + 0.5 * 25.8618 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 911 Reward: -1065.6842 total_loss = 11.4981 = 0.0249 + 0.5 * 22.9503 + 0.01 * -0.1943\n",
      "-----------------\n",
      "Finished episode: 912 Reward: -1174.5073 total_loss = 13.9925 = 0.0398 + 0.5 * 27.9092 + 0.01 * -0.1944\n",
      "-----------------\n",
      "Finished episode: 913 Reward: -1210.9605 total_loss = 13.9640 = 0.0991 + 0.5 * 27.7337 + 0.01 * -0.1939\n",
      "-----------------\n",
      "Finished episode: 914 Reward: -1218.6709 total_loss = 12.7653 = 0.0827 + 0.5 * 25.3690 + 0.01 * -0.1939\n",
      "-----------------\n",
      "Finished episode: 915 Reward: -1171.2584 total_loss = 14.4784 = 0.0509 + 0.5 * 28.8588 + 0.01 * -0.1934\n",
      "-----------------\n",
      "Finished episode: 916 Reward: -1153.5796 total_loss = 15.5654 = 0.0785 + 0.5 * 30.9776 + 0.01 * -0.1935\n",
      "-----------------\n",
      "Finished episode: 917 Reward: -1241.2440 total_loss = 16.6494 = 0.1181 + 0.5 * 33.0665 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 918 Reward: -1143.2603 total_loss = 16.1695 = -0.0544 + 0.5 * 32.4516 + 0.01 * -0.1933\n",
      "-----------------\n",
      "Finished episode: 919 Reward: -1194.9269 total_loss = 12.6942 = 0.0854 + 0.5 * 25.2216 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 920 Reward: -1154.0091 total_loss = 13.9341 = -0.0913 + 0.5 * 28.0548 + 0.01 * -0.1934\n",
      "-----------------\n",
      "Finished episode: 921 Reward: -1105.8614 total_loss = 13.4400 = 0.0169 + 0.5 * 26.8501 + 0.01 * -0.1936\n",
      "-----------------\n",
      "Finished episode: 922 Reward: -1141.7286 total_loss = 15.6830 = -0.0431 + 0.5 * 31.4560 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 923 Reward: -1099.9377 total_loss = 13.9744 = -0.0349 + 0.5 * 28.0225 + 0.01 * -0.1937\n",
      "-----------------\n",
      "Finished episode: 924 Reward: -1180.1486 total_loss = 14.9671 = 0.0875 + 0.5 * 29.7630 + 0.01 * -0.1934\n",
      "-----------------\n",
      "Finished episode: 925 Reward: -1126.0686 total_loss = 14.1161 = 0.0487 + 0.5 * 28.1385 + 0.01 * -0.1935\n",
      "-----------------\n",
      "Finished episode: 926 Reward: -1153.2940 total_loss = 12.5544 = 0.0075 + 0.5 * 25.0978 + 0.01 * -0.1934\n",
      "-----------------\n",
      "Finished episode: 927 Reward: -1163.7400 total_loss = 14.4878 = 0.0251 + 0.5 * 28.9293 + 0.01 * -0.1921\n",
      "-----------------\n",
      "Finished episode: 928 Reward: -1218.7882 total_loss = 16.3718 = -0.0201 + 0.5 * 32.7877 + 0.01 * -0.1932\n",
      "-----------------\n",
      "Finished episode: 929 Reward: -1173.7398 total_loss = 13.2765 = 0.0489 + 0.5 * 26.4590 + 0.01 * -0.1936\n",
      "-----------------\n",
      "Finished episode: 930 Reward: -1142.7321 total_loss = 16.2962 = 0.0529 + 0.5 * 32.4905 + 0.01 * -0.1929\n",
      "-----------------\n",
      "Finished episode: 931 Reward: -1156.0405 total_loss = 15.9962 = 0.0485 + 0.5 * 31.8993 + 0.01 * -0.1923\n",
      "-----------------\n",
      "Finished episode: 932 Reward: -1093.5502 total_loss = 14.2237 = 0.0325 + 0.5 * 28.3862 + 0.01 * -0.1927\n",
      "-----------------\n",
      "Finished episode: 933 Reward: -1164.4594 total_loss = 17.8514 = 0.0023 + 0.5 * 35.7020 + 0.01 * -0.1931\n",
      "-----------------\n",
      "Finished episode: 934 Reward: -1240.5346 total_loss = 15.6980 = 0.0754 + 0.5 * 31.2491 + 0.01 * -0.1932\n",
      "-----------------\n",
      "Finished episode: 935 Reward: -1181.5922 total_loss = 17.0512 = 0.0587 + 0.5 * 33.9888 + 0.01 * -0.1927\n",
      "-----------------\n",
      "Finished episode: 936 Reward: -1202.8428 total_loss = 16.7953 = -0.1194 + 0.5 * 33.8333 + 0.01 * -0.1928\n",
      "-----------------\n",
      "Finished episode: 937 Reward: -1157.1269 total_loss = 13.4056 = 0.0392 + 0.5 * 26.7367 + 0.01 * -0.1927\n",
      "-----------------\n",
      "Finished episode: 938 Reward: -1134.4020 total_loss = 14.7727 = 0.1305 + 0.5 * 29.2884 + 0.01 * -0.1930\n",
      "-----------------\n",
      "Finished episode: 939 Reward: -1059.2765 total_loss = 14.8438 = 0.0293 + 0.5 * 29.6329 + 0.01 * -0.1926\n",
      "-----------------\n",
      "Finished episode: 940 Reward: -1247.4409 total_loss = 16.1106 = 0.0835 + 0.5 * 32.0580 + 0.01 * -0.1927\n",
      "-----------------\n",
      "Finished episode: 941 Reward: -1090.9084 total_loss = 15.1093 = 0.1751 + 0.5 * 29.8722 + 0.01 * -0.1929\n",
      "-----------------\n",
      "Finished episode: 942 Reward: -1143.5303 total_loss = 15.2776 = 0.0092 + 0.5 * 30.5406 + 0.01 * -0.1931\n",
      "-----------------\n",
      "Finished episode: 943 Reward: -1205.9212 total_loss = 14.4610 = -0.0060 + 0.5 * 28.9378 + 0.01 * -0.1931\n",
      "-----------------\n",
      "Finished episode: 944 Reward: -1177.1366 total_loss = 14.8818 = 0.0657 + 0.5 * 29.6362 + 0.01 * -0.1924\n",
      "-----------------\n",
      "Finished episode: 945 Reward: -1166.3638 total_loss = 17.0468 = -0.0545 + 0.5 * 34.2065 + 0.01 * -0.1923\n",
      "-----------------\n",
      "Finished episode: 946 Reward: -1163.0690 total_loss = 16.5382 = -0.0769 + 0.5 * 33.2342 + 0.01 * -0.1927\n",
      "-----------------\n",
      "Finished episode: 947 Reward: -1144.2189 total_loss = 15.6465 = 0.0170 + 0.5 * 31.2628 + 0.01 * -0.1926\n",
      "-----------------\n",
      "Finished episode: 948 Reward: -1169.8267 total_loss = 16.8559 = -0.0302 + 0.5 * 33.7761 + 0.01 * -0.1922\n",
      "-----------------\n",
      "Finished episode: 949 Reward: -1172.3386 total_loss = 17.7596 = 0.0499 + 0.5 * 35.4233 + 0.01 * -0.1924\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode: 950 Reward: -1200.2054 total_loss = 15.9862 = 0.0390 + 0.5 * 31.8982 + 0.01 * -0.1923\n",
      "-----------------\n",
      "Finished episode: 951 Reward: -1121.3748 total_loss = 13.9739 = 0.0285 + 0.5 * 27.8947 + 0.01 * -0.1923\n",
      "-----------------\n",
      "Finished episode: 952 Reward: -1191.4676 total_loss = 14.5934 = 0.0807 + 0.5 * 29.0292 + 0.01 * -0.1924\n",
      "-----------------\n",
      "Finished episode: 953 Reward: -1175.5378 total_loss = 15.7380 = -0.0185 + 0.5 * 31.5167 + 0.01 * -0.1925\n",
      "-----------------\n",
      "Finished episode: 954 Reward: -1134.5522 total_loss = 15.3083 = -0.0361 + 0.5 * 30.6927 + 0.01 * -0.1928\n",
      "-----------------\n",
      "Finished episode: 955 Reward: -1258.1683 total_loss = 16.1245 = 0.0790 + 0.5 * 32.0949 + 0.01 * -0.1922\n",
      "-----------------\n",
      "Finished episode: 956 Reward: -1139.6217 total_loss = 15.1223 = -0.0586 + 0.5 * 30.3656 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 957 Reward: -1236.0511 total_loss = 17.1138 = -0.0088 + 0.5 * 34.2490 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 958 Reward: -1176.3946 total_loss = 16.8616 = -0.1390 + 0.5 * 34.0049 + 0.01 * -0.1924\n",
      "-----------------\n",
      "Finished episode: 959 Reward: -1256.9965 total_loss = 16.5240 = -0.0261 + 0.5 * 33.1040 + 0.01 * -0.1921\n",
      "-----------------\n",
      "Finished episode: 960 Reward: -1200.1737 total_loss = 15.4328 = -0.0335 + 0.5 * 30.9365 + 0.01 * -0.1923\n",
      "-----------------\n",
      "Finished episode: 961 Reward: -1204.5032 total_loss = 19.8377 = -0.0610 + 0.5 * 39.8013 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 962 Reward: -1193.1826 total_loss = 16.2551 = -0.0554 + 0.5 * 32.6249 + 0.01 * -0.1923\n",
      "-----------------\n",
      "Finished episode: 963 Reward: -1265.0502 total_loss = 15.5858 = -0.0275 + 0.5 * 31.2303 + 0.01 * -0.1916\n",
      "-----------------\n",
      "Finished episode: 964 Reward: -1257.3995 total_loss = 17.1676 = -0.0864 + 0.5 * 34.5119 + 0.01 * -0.1921\n",
      "-----------------\n",
      "Finished episode: 965 Reward: -1161.6117 total_loss = 14.0736 = 0.0852 + 0.5 * 27.9806 + 0.01 * -0.1922\n",
      "-----------------\n",
      "Finished episode: 966 Reward: -1181.6419 total_loss = 13.2587 = 0.1031 + 0.5 * 26.3151 + 0.01 * -0.1919\n",
      "-----------------\n",
      "Finished episode: 967 Reward: -1184.9074 total_loss = 17.3228 = -0.0265 + 0.5 * 34.7024 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 968 Reward: -1199.0253 total_loss = 15.5044 = 0.0019 + 0.5 * 31.0089 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 969 Reward: -1155.0399 total_loss = 14.0687 = -0.0353 + 0.5 * 28.2118 + 0.01 * -0.1916\n",
      "-----------------\n",
      "Finished episode: 970 Reward: -1212.7252 total_loss = 15.3644 = -0.0019 + 0.5 * 30.7364 + 0.01 * -0.1919\n",
      "-----------------\n",
      "Finished episode: 971 Reward: -1179.2680 total_loss = 16.9486 = -0.0354 + 0.5 * 33.9719 + 0.01 * -0.1914\n",
      "-----------------\n",
      "Finished episode: 972 Reward: -1184.4927 total_loss = 16.4526 = -0.0304 + 0.5 * 32.9698 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 973 Reward: -1222.3352 total_loss = 17.0414 = 0.0246 + 0.5 * 34.0374 + 0.01 * -0.1919\n",
      "-----------------\n",
      "Finished episode: 974 Reward: -1241.0513 total_loss = 20.6181 = -0.1036 + 0.5 * 41.4472 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 975 Reward: -1242.7404 total_loss = 19.5308 = -0.0967 + 0.5 * 39.2586 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 976 Reward: -1253.5635 total_loss = 17.7178 = 0.0800 + 0.5 * 35.2794 + 0.01 * -0.1917\n",
      "-----------------\n",
      "Finished episode: 977 Reward: -1196.0721 total_loss = 15.6965 = -0.0289 + 0.5 * 31.4547 + 0.01 * -0.1919\n",
      "-----------------\n",
      "Finished episode: 978 Reward: -1252.3738 total_loss = 17.5114 = -0.0464 + 0.5 * 35.1194 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 979 Reward: -1261.7102 total_loss = 16.1491 = 0.0425 + 0.5 * 32.2169 + 0.01 * -0.1913\n",
      "-----------------\n",
      "Finished episode: 980 Reward: -1176.7050 total_loss = 14.5635 = 0.0573 + 0.5 * 29.0163 + 0.01 * -0.1915\n",
      "-----------------\n",
      "Finished episode: 981 Reward: -1252.2033 total_loss = 18.8332 = 0.0262 + 0.5 * 37.6178 + 0.01 * -0.1914\n",
      "-----------------\n",
      "Finished episode: 982 Reward: -1272.1154 total_loss = 16.0833 = -0.0923 + 0.5 * 32.3551 + 0.01 * -0.1920\n",
      "-----------------\n",
      "Finished episode: 983 Reward: -1219.9099 total_loss = 16.6436 = 0.0300 + 0.5 * 33.2309 + 0.01 * -0.1913\n",
      "-----------------\n",
      "Finished episode: 984 Reward: -1163.5873 total_loss = 17.9126 = -0.0567 + 0.5 * 35.9425 + 0.01 * -0.1916\n",
      "-----------------\n",
      "Finished episode: 985 Reward: -1220.9289 total_loss = 16.8107 = -0.0667 + 0.5 * 33.7586 + 0.01 * -0.1919\n",
      "-----------------\n",
      "Finished episode: 986 Reward: -1225.2909 total_loss = 17.5152 = 0.0001 + 0.5 * 35.0340 + 0.01 * -0.1916\n",
      "-----------------\n",
      "Finished episode: 987 Reward: -1203.3125 total_loss = 16.2123 = 0.0723 + 0.5 * 32.2838 + 0.01 * -0.1912\n",
      "-----------------\n",
      "Finished episode: 988 Reward: -1163.0728 total_loss = 17.5870 = -0.0397 + 0.5 * 35.2573 + 0.01 * -0.1916\n",
      "-----------------\n",
      "Finished episode: 989 Reward: -1267.9568 total_loss = 18.6290 = -0.0749 + 0.5 * 37.4115 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 990 Reward: -1208.2808 total_loss = 15.7996 = 0.0772 + 0.5 * 31.4485 + 0.01 * -0.1916\n",
      "-----------------\n",
      "Finished episode: 991 Reward: -1306.8216 total_loss = 18.8332 = 0.0889 + 0.5 * 37.4925 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 992 Reward: -1202.2502 total_loss = 16.0111 = 0.0631 + 0.5 * 31.8998 + 0.01 * -0.1915\n",
      "-----------------\n",
      "Finished episode: 993 Reward: -1139.1533 total_loss = 16.0789 = -0.0603 + 0.5 * 32.2822 + 0.01 * -0.1916\n",
      "-----------------\n",
      "Finished episode: 994 Reward: -1132.7647 total_loss = 17.3247 = 0.0874 + 0.5 * 34.4784 + 0.01 * -0.1915\n",
      "-----------------\n",
      "Finished episode: 995 Reward: -1223.1608 total_loss = 17.0073 = -0.0018 + 0.5 * 34.0220 + 0.01 * -0.1918\n",
      "-----------------\n",
      "Finished episode: 996 Reward: -1182.0626 total_loss = 18.4357 = -0.1089 + 0.5 * 37.0930 + 0.01 * -0.1912\n",
      "-----------------\n",
      "Finished episode: 997 Reward: -1163.7673 total_loss = 18.5033 = 0.0078 + 0.5 * 36.9948 + 0.01 * -0.1921\n",
      "-----------------\n",
      "Finished episode: 998 Reward: -1285.7665 total_loss = 20.1445 = -0.0789 + 0.5 * 40.4507 + 0.01 * -0.1913\n",
      "-----------------\n",
      "Finished episode: 999 Reward: -1213.5419 total_loss = 18.2474 = 0.0573 + 0.5 * 36.3842 + 0.01 * -0.1917\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Here, you need to finish the first 5 tasks.\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, layer_norm=True):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        '''\n",
    "        Q1:\n",
    "        Initialize your networks\n",
    "        '''\n",
    "        self.actor_fc1 = nn.Linear(num_inputs, args.hid_num)\n",
    "        self.actor_fc2 = nn.Linear(args.hid_num, args.hid_num)\n",
    "        self.actor_fc3 = nn.Linear(args.hid_num, num_outputs)\n",
    "        self.actor_fc = nn.Sequential(\n",
    "            self.actor_fc1,\n",
    "            nn.ReLU(),\n",
    "            self.actor_fc2,\n",
    "            nn.ReLU(),\n",
    "            self.actor_fc3,\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.actor_logstd = nn.Parameter(torch.zeros(1, num_outputs))\n",
    "\n",
    "        self.critic_fc1 = nn.Linear(num_inputs, args.hid_num)\n",
    "        self.critic_fc2 = nn.Linear(args.hid_num, args.hid_num)\n",
    "        self.critic_fc3 = nn.Linear(args.hid_num, num_outputs)\n",
    "        self.critic_fc = nn.Sequential(\n",
    "            self.critic_fc1,\n",
    "            nn.ReLU(),\n",
    "            self.critic_fc2,\n",
    "            nn.ReLU(),\n",
    "            self.critic_fc3\n",
    "        )\n",
    "\n",
    "        if layer_norm:\n",
    "            self.layer_norm(self.actor_fc1, std=1.0)\n",
    "            self.layer_norm(self.actor_fc2, std=1.0)\n",
    "            self.layer_norm(self.actor_fc3, std=0.01)\n",
    "\n",
    "            self.layer_norm(self.critic_fc1, std=1.0)\n",
    "            self.layer_norm(self.critic_fc2, std=1.0)\n",
    "            self.layer_norm(self.critic_fc3, std=1.0)\n",
    "\n",
    "    @staticmethod\n",
    "    def layer_norm(layer, std=1.0, bias_const=0.0):\n",
    "        torch.nn.init.orthogonal_(layer.weight, std)\n",
    "        torch.nn.init.constant_(layer.bias, bias_const)\n",
    "\n",
    "    def forward(self, states):\n",
    "        \"\"\"\n",
    "        Q2.1:\n",
    "        run policy network (actor) as well as value network (critic)\n",
    "        :param states: a tensor represents states\n",
    "        :return: 3 Tensor2\n",
    "        your _forward_actor() function should return both the mean value of action and the log-standard deviation of the action\n",
    "        \"\"\"\n",
    "\n",
    "        action_mean, action_logstd = self._forward_actor(states)\n",
    "        critic_value = self._forward_critic(states)\n",
    "        return action_mean, action_logstd, critic_value\n",
    "\n",
    "    def _forward_actor(self, states):\n",
    "        '''\n",
    "        Q2.2:\n",
    "        build something like \n",
    "        x = activation (actor_fc(state))\n",
    "        the logstd output has already been provided\n",
    "        '''\n",
    "        action_mean = self.actor_fc(states) * 2 # [-2, 2]\n",
    "        action_logstd = self.actor_logstd.expand_as(action_mean)\n",
    "        return action_mean, action_logstd\n",
    "\n",
    "    def _forward_critic(self, states):\n",
    "        '''\n",
    "        Q2.3:\n",
    "        build something like \n",
    "        x = activation (critic_fc(state))'''\n",
    "\n",
    "        critic_value = self.critic_fc(states)\n",
    "        return critic_value\n",
    "\n",
    "    def select_action(self, action_mean, action_logstd, return_logproba=True):\n",
    "        \"\"\"\n",
    "        Q3.1:\n",
    "        given mean and std, sample an action from normal(mean, std)\n",
    "        also returns probability of the given chosen\n",
    "        \"\"\"\n",
    "        \n",
    "        D = torch.distributions.Normal(action_mean, torch.exp(action_logstd)+EPS)\n",
    "        action = torch.clamp(D.sample(), -2, 2)\n",
    "        logproba = D.log_prob(action)\n",
    "        return action, logproba\n",
    "\n",
    "    @staticmethod\n",
    "    def _normal_logproba(x, mean, logstd, std=None):\n",
    "        '''\n",
    "        Q3.2:\n",
    "        given a mean and logstd of a gaussian,\n",
    "        calculate the log-probability of a given x'''\n",
    "\n",
    "        D = torch.distributions.Normal(mean, torch.exp(logstd)+EPS)\n",
    "        logproba = D.log_prob(x)\n",
    "        \n",
    "        return logproba.sum(1)\n",
    "\n",
    "    def get_logproba(self, states, actions):\n",
    "        \"\"\"\n",
    "        return probability of chosen the given actions under corresponding states of current network\n",
    "        :param states: Tensor\n",
    "        :param actions: Tensor\n",
    "        \"\"\"\n",
    "        action_mean, action_logstd = self._forward_actor(states)\n",
    "        action_mean = action_mean.cpu()\n",
    "        action_logstd = action_logstd.cpu()\n",
    "        logproba = self._normal_logproba(actions, action_mean, action_logstd)\n",
    "        return logproba\n",
    "\n",
    "\n",
    "class Memory(object):\n",
    "    def __init__(self):\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self):\n",
    "        return Transition(*zip(*self.memory))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "env = gym.make(ENV_NAME)  \n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.shape[0]\n",
    "network = ActorCritic(num_inputs, num_actions, layer_norm=args.layer_norm)\n",
    "network.train()\n",
    "def ppo(args):\n",
    "    env = gym.make(args.env_name)\n",
    "    num_inputs = env.observation_space.shape[0]\n",
    "    num_actions = env.action_space.shape[0]\n",
    "\n",
    "    env.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    network = ActorCritic(num_inputs, num_actions, layer_norm=args.layer_norm)\n",
    "    optimizer = opt.Adam(network.parameters(), lr=args.lr)\n",
    "\n",
    "    running_state = ZFilter((num_inputs,), clip=5.0)\n",
    "\n",
    "    # record average 1-round cumulative reward in every episode\n",
    "    reward_record = []\n",
    "    global_steps = 0\n",
    "\n",
    "    lr_now = args.lr\n",
    "    clip_now = args.clip\n",
    "\n",
    "    for i_episode in range(args.num_episode):\n",
    "        # step1: perform current policy to collect trajectories\n",
    "        # this is an on-policy method!\n",
    "        memory = Memory()\n",
    "        num_steps = 0\n",
    "        reward_list = []\n",
    "        len_list = []\n",
    "        while num_steps < args.batch_size:\n",
    "            state = env.reset()\n",
    "            if args.state_norm:\n",
    "                state = running_state(state)\n",
    "            reward_sum = 0\n",
    "            for t in range(args.max_step_per_round):\n",
    "                action_mean, action_logstd, value = network(Tensor(state).unsqueeze(0))\n",
    "                action, logproba = network.select_action(action_mean, action_logstd)\n",
    "                action = action.cpu().data.numpy()[0]\n",
    "                logproba = logproba.cpu().data.numpy()[0]\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "                reward_sum += reward\n",
    "                if args.state_norm:\n",
    "                    next_state = running_state(next_state)\n",
    "                mask = 0 if done else 1\n",
    "\n",
    "                memory.push(state, value, action, logproba, mask, next_state, reward)\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "            num_steps += (t + 1)\n",
    "            global_steps += (t + 1)\n",
    "            reward_list.append(reward_sum)\n",
    "            len_list.append(t + 1)\n",
    "        reward_record.append({\n",
    "            'episode': i_episode, \n",
    "            'steps': global_steps, \n",
    "            'meanepreward': np.mean(reward_list), \n",
    "            'meaneplen': np.mean(len_list)})\n",
    "        rwds.extend(reward_list)\n",
    "        batch = memory.sample()\n",
    "        batch_size = len(memory)\n",
    "\n",
    "        # step2: extract variables from trajectories\n",
    "        rewards = Tensor(batch.reward)\n",
    "        values = Tensor(batch.value)\n",
    "        masks = Tensor(batch.mask)\n",
    "        actions = Tensor(batch.action)\n",
    "        states = Tensor(batch.state)\n",
    "        oldlogproba = Tensor(batch.logproba)\n",
    "\n",
    "        returns = Tensor(batch_size)\n",
    "        deltas = Tensor(batch_size)\n",
    "        advantages = Tensor(batch_size)\n",
    "\n",
    "        prev_return = 0\n",
    "        prev_value = 0\n",
    "        prev_advantage = 0\n",
    "        for i in reversed(range(batch_size)):\n",
    "            returns[i] = rewards[i] + args.gamma * prev_return * masks[i]\n",
    "            deltas[i] = rewards[i] + args.gamma * prev_value * masks[i] - values[i]\n",
    "            # ref: https://arxiv.org/pdf/1506.02438.pdf (generalization advantage estimate)\n",
    "            advantages[i] = deltas[i] + args.gamma * args.lamda * prev_advantage * masks[i]\n",
    "\n",
    "            prev_return = returns[i]\n",
    "            prev_value = values[i]\n",
    "            prev_advantage = advantages[i]\n",
    "        if args.advantage_norm:\n",
    "            advantages = (advantages - advantages.mean()) / (advantages.std() + EPS)\n",
    "\n",
    "        for i_epoch in range(int(args.num_epoch * batch_size / args.minibatch_size)):\n",
    "            # sample from current batch\n",
    "            minibatch_ind = np.random.choice(batch_size, args.minibatch_size, replace=False)\n",
    "            minibatch_states = states[minibatch_ind]\n",
    "            minibatch_actions = actions[minibatch_ind]\n",
    "            minibatch_oldlogproba = oldlogproba[minibatch_ind]\n",
    "            minibatch_newlogproba = network.get_logproba(minibatch_states, minibatch_actions)\n",
    "            minibatch_advantages = advantages[minibatch_ind]\n",
    "            minibatch_returns = returns[minibatch_ind]\n",
    "            minibatch_newvalues = network._forward_critic(minibatch_states).flatten()\n",
    "\n",
    "\n",
    "\n",
    "            '''\n",
    "            Q4: \n",
    "\n",
    "            HERE: \n",
    "            now you have the advantages, and log-probabilities (both pi_new and pi_old)\n",
    "            you need to do optimization according to the CLIP loss\n",
    "            \n",
    "            '''\n",
    "            r = torch.exp(minibatch_newlogproba - minibatch_oldlogproba)\n",
    "            s1 = r * minibatch_advantages\n",
    "            s2 = torch.clamp(r, 1 - clip_now, 1 + clip_now) * minibatch_advantages\n",
    "            loss_surr = -torch.mean(torch.min(s1, s2))\n",
    "\n",
    "            if args.lossvalue_norm:\n",
    "                minibatch_return_6std = 6 * minibatch_returns.std()\n",
    "                loss_value = torch.mean((minibatch_newvalues - minibatch_returns).pow(2)) / minibatch_return_6std\n",
    "            else:\n",
    "                loss_value = torch.mean((minibatch_newvalues - minibatch_returns).pow(2))\n",
    "\n",
    "            loss_entropy = torch.mean(torch.exp(minibatch_newlogproba) * minibatch_newlogproba)\n",
    "\n",
    "            total_loss = loss_surr + args.loss_coeff_value * loss_value + args.loss_coeff_entropy * loss_entropy\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if args.schedule_clip == 'linear':\n",
    "            ep_ratio = 1 - (i_episode / args.num_episode)\n",
    "            clip_now = args.clip * ep_ratio\n",
    "\n",
    "        if args.schedule_adam == 'linear':\n",
    "            ep_ratio = 1 - (i_episode / args.num_episode)\n",
    "            lr_now = args.lr * ep_ratio\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = lr_now\n",
    "\n",
    "        if i_episode % args.log_num_episode == 0:\n",
    "            print('Finished episode: {} Reward: {:.4f} total_loss = {:.4f} = {:.4f} + {} * {:.4f} + {} * {:.4f}' \\\n",
    "                .format(i_episode, reward_record[-1]['meanepreward'], total_loss.data, loss_surr.data, args.loss_coeff_value, \n",
    "                loss_value.data, args.loss_coeff_entropy, loss_entropy.data))\n",
    "            print('-----------------')\n",
    "\n",
    "    return reward_record\n",
    "\n",
    "def test(args):\n",
    "    record_dfs = []\n",
    "    for i in range(args.num_parallel_run):\n",
    "        args.seed += 1\n",
    "        reward_record = pd.DataFrame(ppo(args))\n",
    "        reward_record['#parallel_run'] = i\n",
    "        record_dfs.append(reward_record)\n",
    "    record_dfs = pd.concat(record_dfs, axis=0)\n",
    "    record_dfs.to_csv(joindir(RESULT_DIR, 'ppo-record-{}.csv'.format(args.env_name)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for envname in [ENV_NAME]:\n",
    "        args.env_name = envname\n",
    "        test(args)\n",
    "\n",
    "torch.save(network.state_dict(),args.env_name.split('-')[0]+'/CheckPoints/checkpoint_hidden_{0}'.format(args.hid_num)) \n",
    "np.savetxt(args.env_name.split('-')[0]+'/Rwds/rwds_hidden_{0}'.format(args.hid_num),rwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVV1-fJWArMt"
   },
   "source": [
    "# DDPG and TD3\n",
    "\n",
    "The Deterministic Policy Gradient method was proposed by Silver et. al. 2014 (http://proceedings.mlr.press/v32/silver14.pdf), and DDPG is its deep version.\n",
    "\n",
    "The DPG also uses the actor-critic paradigm, but maitains a deterministic version of policy. It optimizes the critic through the Bellman Equation, and optimize the actor through the chain rule. \n",
    "\n",
    "In this assignment, you may need to import some python files like DDPG.py and TD3.py to insert the method into training.\n",
    "Here are some solutions from stackoverflow: https://stackoverflow.com/questions/48905127/importing-py-files-in-google-colab.\n",
    "\n",
    "It is easier to just copy it from Drive than upload it.\n",
    "1. Store MYLIB.py in your Drive. (for this assignment, it will be the utils.py, DDPG.py and TD3.py)\n",
    "2. Open the Colab.\n",
    "3. Open the left side pane, select Files view (the file icon).\n",
    "4. Click Mount Drive then Connect to Google Drive (the folder with google drive icon).\n",
    "5. Copy it by running \"! cp drive/My\\ Drive/MYLIB.py . \" in your Colab file code line.\n",
    "6. import MYLIB\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6OJdsG_MJz_"
   },
   "source": [
    "## TODOs for You (Please write down the answer in this block)\n",
    "\n",
    "The TD3 is short for *Twin Delayed Deep Deterministic Policy Gradient*, their official open-source implementation is extremely clear and easy to follow! So I believe there is no need for you to build up the wheels one more time.\n",
    "\n",
    "However, you really need to know about how this method works!\n",
    "TD3 proposes several improvements based on the method of DDPG to improve its sample efficiency.\n",
    "\n",
    "- Q6. In this part, your task is to read the paper, and read the code of the official implementation of TD3 and DDPG at:\n",
    "\n",
    "https://github.com/sfujim/TD3/blob/master/DDPG.py\n",
    "\n",
    "https://github.com/sfujim/TD3/blob/master/TD3.py\n",
    "\n",
    "Then, please try to find the proposed improvements in TD3 over DDPG and summary them HERE:\n",
    "\n",
    "\n",
    "1. Delay the policy network update frequency\n",
    "    - code:\n",
    "    ```\n",
    "    \t\t# Delayed policy updates\n",
    "\t\tif self.total_it % self.policy_freq == 0:\n",
    "    ```\n",
    "2. Double-Q learning to reduce the overestimation of Q-values\n",
    "    - code:\n",
    "    ```\n",
    "\t\t\ttarget_Q1, target_Q2 = self.critic_target(next_state, next_action)\n",
    "\t\t\ttarget_Q = torch.min(target_Q1, target_Q2)\n",
    "    ```\n",
    "3. Use noised action to smooth the target policy\n",
    "    - code:\n",
    "    ```\n",
    "\t\t\tnoise = (\n",
    "\t\t\t\ttorch.randn_like(action) * self.policy_noise\n",
    "\t\t\t).clamp(-self.noise_clip, self.noise_clip)\n",
    "\t\t\t\n",
    "\t\t\tnext_action = (\n",
    "\t\t\t\tself.actor_target(next_state) + noise\n",
    "\t\t\t).clamp(-self.max_action, self.max_action)\n",
    "    ```\n",
    "4. Compute the critic loss from both of the two Q networks\n",
    "    - code:\n",
    "    ```\n",
    "    \t\tcritic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(current_Q2, target_Q)\n",
    "    ```\n",
    "\n",
    "- Q7. Among all those improvements, which do you believe is the most important one? You may take some ablation studies to support your claim.  (i.e., draw some learning curves with different settings together and draw your conclusions)\n",
    "\n",
    "- Q8. What is the difference between TD3(DDPG) and PPO in the OPTIMIZATION step (including but not restricted in terms of the sampling-training proportion)? Actually the improvements of PPO over TRPO was pointed  as a benefit of more training iterations, can you further improve the sample efficiency of TD3?\n",
    "\n",
    "\n",
    "```\n",
    "A8: \n",
    "1. The optimization of PPO is based on the advantage value, which is computed from the state value function, while TD3(DDPG) is based on the Q function.\n",
    "2. PPO train the networks with multiple epoches once sampled, while TD3 only train once with each sample. Therefore PPO can do more training efforts. We can also applie this strategy to TD3.\n",
    "3. PPO use an online policy but TD3/DDPG use an offline policy.\n",
    "```\n",
    "\n",
    "- Q9. (i) Please describe the difference of the exploration strategies between PPO, DDPG and TD3. (ii) Provide a comparison between the exploration strategies of those continuous control algorithms and DQN.\n",
    "\n",
    "\n",
    "(i)\n",
    "\n",
    "PPO: sample an action from the normal distribution that centered at action_mean.\n",
    "\n",
    "DDPG: either use the optimal action or sample an action uniformly in the action space.\n",
    "TD3: Further add an gaussian noise to the selected action based on DDPG.\n",
    "\n",
    "(ii)\n",
    "DQN: 1) Use epsilon-greedy algorithm that uniformly sample a categorical action with an epsilon probability. 2) Use a target Q function when training to reduce variance.\n",
    "\n",
    "DDPG/TD3: 1) Compared with DQN, it samples the actionfrom a continuous space $a_{TD3} \\in R^n$  rather than a discrete space $a_{DQN} \\in Z^+$. 2) DQN and DDPG/TD3 both use the target Q function when training.\n",
    "\n",
    "- Q10. (Bonus, 20 points) An open question. Do you think an epsilon-greedy-like exploration strategy you used in DQN/Q-learning is useful for continuous control? Will there be any problem of applying epsilon-greedy method in DDPG/TD3/PPO? Try to implement the idea and report the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following four blocks download the code in official implementation to your google drive so that the following script can run them. Note that the downloaded files may disappear due to some colab mechansim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "R2jXxeaWoCPM",
    "outputId": "31d18c26-8186-49ba-bcfc-ee72300fed50"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/sfujim/TD3.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "66Sy-dOQ8Qo5"
   },
   "outputs": [],
   "source": [
    "!cp TD3/DDPG.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5TuZqwcHottp"
   },
   "outputs": [],
   "source": [
    "!cp TD3/TD3.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "259dqcCpotrJ"
   },
   "outputs": [],
   "source": [
    "!cp TD3/utils.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2X3lvH_5pKkS"
   },
   "outputs": [],
   "source": [
    "from os import makedirs as mkdir\n",
    "mkdir('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Lboiuk9vHDhD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 200 Episode Num: 1 Episode T: 200 Reward: -1514.878\n",
      "Total T: 400 Episode Num: 2 Episode T: 200 Reward: -1448.276\n",
      "Total T: 600 Episode Num: 3 Episode T: 200 Reward: -1390.877\n",
      "Total T: 800 Episode Num: 4 Episode T: 200 Reward: -1509.185\n",
      "Total T: 1000 Episode Num: 5 Episode T: 200 Reward: -1575.625\n",
      "recent Evaluation: -1414.6877126206898\n",
      "Total T: 1200 Episode Num: 6 Episode T: 200 Reward: -1514.355\n",
      "Total T: 1400 Episode Num: 7 Episode T: 200 Reward: -1602.583\n",
      "Total T: 1600 Episode Num: 8 Episode T: 200 Reward: -1555.670\n",
      "Total T: 1800 Episode Num: 9 Episode T: 200 Reward: -1408.073\n",
      "Total T: 2000 Episode Num: 10 Episode T: 200 Reward: -1457.917\n",
      "recent Evaluation: -1257.1985194271979\n",
      "Total T: 2200 Episode Num: 11 Episode T: 200 Reward: -1263.587\n",
      "Total T: 2400 Episode Num: 12 Episode T: 200 Reward: -1185.657\n",
      "Total T: 2600 Episode Num: 13 Episode T: 200 Reward: -1079.949\n",
      "Total T: 2800 Episode Num: 14 Episode T: 200 Reward: -1030.095\n",
      "Total T: 3000 Episode Num: 15 Episode T: 200 Reward: -947.609\n",
      "recent Evaluation: -978.5410290513548\n",
      "Total T: 3200 Episode Num: 16 Episode T: 200 Reward: -933.026\n",
      "Total T: 3400 Episode Num: 17 Episode T: 200 Reward: -982.105\n",
      "Total T: 3600 Episode Num: 18 Episode T: 200 Reward: -996.622\n",
      "Total T: 3800 Episode Num: 19 Episode T: 200 Reward: -955.034\n",
      "Total T: 4000 Episode Num: 20 Episode T: 200 Reward: -905.137\n",
      "recent Evaluation: -808.8036493937452\n",
      "Total T: 4200 Episode Num: 21 Episode T: 200 Reward: -860.063\n",
      "Total T: 4400 Episode Num: 22 Episode T: 200 Reward: -913.436\n",
      "Total T: 4600 Episode Num: 23 Episode T: 200 Reward: -899.308\n",
      "Total T: 4800 Episode Num: 24 Episode T: 200 Reward: -903.529\n",
      "Total T: 5000 Episode Num: 25 Episode T: 200 Reward: -266.311\n",
      "recent Evaluation: -160.6337092430761\n",
      "Total T: 5200 Episode Num: 26 Episode T: 200 Reward: -798.964\n",
      "Total T: 5400 Episode Num: 27 Episode T: 200 Reward: -651.041\n",
      "Total T: 5600 Episode Num: 28 Episode T: 200 Reward: -525.789\n",
      "Total T: 5800 Episode Num: 29 Episode T: 200 Reward: -266.044\n",
      "Total T: 6000 Episode Num: 30 Episode T: 200 Reward: -3.627\n",
      "recent Evaluation: -154.38558714141072\n",
      "Total T: 6200 Episode Num: 31 Episode T: 200 Reward: -394.277\n",
      "Total T: 6400 Episode Num: 32 Episode T: 200 Reward: -380.721\n",
      "Total T: 6600 Episode Num: 33 Episode T: 200 Reward: -390.669\n",
      "Total T: 6800 Episode Num: 34 Episode T: 200 Reward: -131.975\n",
      "Total T: 7000 Episode Num: 35 Episode T: 200 Reward: -388.998\n",
      "recent Evaluation: -138.6307113869862\n",
      "Total T: 7200 Episode Num: 36 Episode T: 200 Reward: -250.440\n",
      "Total T: 7400 Episode Num: 37 Episode T: 200 Reward: -130.956\n",
      "Total T: 7600 Episode Num: 38 Episode T: 200 Reward: -376.967\n",
      "Total T: 7800 Episode Num: 39 Episode T: 200 Reward: -132.046\n",
      "Total T: 8000 Episode Num: 40 Episode T: 200 Reward: -132.115\n",
      "recent Evaluation: -194.51147077335412\n",
      "Total T: 8200 Episode Num: 41 Episode T: 200 Reward: -248.428\n",
      "Total T: 8400 Episode Num: 42 Episode T: 200 Reward: -126.586\n",
      "Total T: 8600 Episode Num: 43 Episode T: 200 Reward: -505.145\n",
      "Total T: 8800 Episode Num: 44 Episode T: 200 Reward: -118.340\n",
      "Total T: 9000 Episode Num: 45 Episode T: 200 Reward: -248.725\n",
      "recent Evaluation: -197.349676079096\n",
      "Total T: 9200 Episode Num: 46 Episode T: 200 Reward: -122.877\n",
      "Total T: 9400 Episode Num: 47 Episode T: 200 Reward: -129.172\n",
      "Total T: 9600 Episode Num: 48 Episode T: 200 Reward: -127.223\n",
      "Total T: 9800 Episode Num: 49 Episode T: 200 Reward: -251.615\n",
      "Total T: 10000 Episode Num: 50 Episode T: 200 Reward: -121.151\n",
      "recent Evaluation: -175.30436334787154\n",
      "Total T: 10200 Episode Num: 51 Episode T: 200 Reward: -129.612\n",
      "Total T: 10400 Episode Num: 52 Episode T: 200 Reward: -123.326\n",
      "Total T: 10600 Episode Num: 53 Episode T: 200 Reward: -0.446\n",
      "Total T: 10800 Episode Num: 54 Episode T: 200 Reward: -132.067\n",
      "Total T: 11000 Episode Num: 55 Episode T: 200 Reward: -601.371\n",
      "recent Evaluation: -127.94335652528439\n",
      "Total T: 11200 Episode Num: 56 Episode T: 200 Reward: -485.054\n",
      "Total T: 11400 Episode Num: 57 Episode T: 200 Reward: -118.299\n",
      "Total T: 11600 Episode Num: 58 Episode T: 200 Reward: -128.664\n",
      "Total T: 11800 Episode Num: 59 Episode T: 200 Reward: -117.277\n",
      "Total T: 12000 Episode Num: 60 Episode T: 200 Reward: -0.565\n",
      "recent Evaluation: -147.94535172251545\n",
      "Total T: 12200 Episode Num: 61 Episode T: 200 Reward: -248.350\n",
      "Total T: 12400 Episode Num: 62 Episode T: 200 Reward: -245.600\n",
      "Total T: 12600 Episode Num: 63 Episode T: 200 Reward: -243.445\n",
      "Total T: 12800 Episode Num: 64 Episode T: 200 Reward: -121.964\n",
      "Total T: 13000 Episode Num: 65 Episode T: 200 Reward: -1.124\n",
      "recent Evaluation: -166.88314039811357\n",
      "Total T: 13200 Episode Num: 66 Episode T: 200 Reward: -122.306\n",
      "Total T: 13400 Episode Num: 67 Episode T: 200 Reward: -1.779\n",
      "Total T: 13600 Episode Num: 68 Episode T: 200 Reward: -124.965\n",
      "Total T: 13800 Episode Num: 69 Episode T: 200 Reward: -128.494\n",
      "Total T: 14000 Episode Num: 70 Episode T: 200 Reward: -382.939\n",
      "recent Evaluation: -172.81178438506663\n",
      "Total T: 14200 Episode Num: 71 Episode T: 200 Reward: -125.891\n",
      "Total T: 14400 Episode Num: 72 Episode T: 200 Reward: -129.153\n",
      "Total T: 14600 Episode Num: 73 Episode T: 200 Reward: -358.460\n",
      "Total T: 14800 Episode Num: 74 Episode T: 200 Reward: -4.609\n",
      "Total T: 15000 Episode Num: 75 Episode T: 200 Reward: -128.306\n",
      "recent Evaluation: -161.2790623254994\n",
      "Total T: 15200 Episode Num: 76 Episode T: 200 Reward: -1.715\n",
      "Total T: 15400 Episode Num: 77 Episode T: 200 Reward: -123.545\n",
      "Total T: 15600 Episode Num: 78 Episode T: 200 Reward: -127.657\n",
      "Total T: 15800 Episode Num: 79 Episode T: 200 Reward: -351.372\n",
      "Total T: 16000 Episode Num: 80 Episode T: 200 Reward: -238.450\n",
      "recent Evaluation: -159.8074448458723\n",
      "Total T: 16200 Episode Num: 81 Episode T: 200 Reward: -123.666\n",
      "Total T: 16400 Episode Num: 82 Episode T: 200 Reward: -115.840\n",
      "Total T: 16600 Episode Num: 83 Episode T: 200 Reward: -117.375\n",
      "Total T: 16800 Episode Num: 84 Episode T: 200 Reward: -239.914\n",
      "Total T: 17000 Episode Num: 85 Episode T: 200 Reward: -365.447\n",
      "recent Evaluation: -164.68304240363906\n",
      "Total T: 17200 Episode Num: 86 Episode T: 200 Reward: -0.899\n",
      "Total T: 17400 Episode Num: 87 Episode T: 200 Reward: -118.653\n",
      "Total T: 17600 Episode Num: 88 Episode T: 200 Reward: -2.429\n",
      "Total T: 17800 Episode Num: 89 Episode T: 200 Reward: -366.009\n",
      "Total T: 18000 Episode Num: 90 Episode T: 200 Reward: -408.290\n",
      "recent Evaluation: -146.16028859910426\n",
      "Total T: 18200 Episode Num: 91 Episode T: 200 Reward: -239.374\n",
      "Total T: 18400 Episode Num: 92 Episode T: 200 Reward: -2.110\n",
      "Total T: 18600 Episode Num: 93 Episode T: 200 Reward: -129.224\n",
      "Total T: 18800 Episode Num: 94 Episode T: 200 Reward: -117.043\n",
      "Total T: 19000 Episode Num: 95 Episode T: 200 Reward: -126.589\n",
      "recent Evaluation: -145.2190773409383\n",
      "Total T: 19200 Episode Num: 96 Episode T: 200 Reward: -233.981\n",
      "Total T: 19400 Episode Num: 97 Episode T: 200 Reward: -1.066\n",
      "Total T: 19600 Episode Num: 98 Episode T: 200 Reward: -1.142\n",
      "Total T: 19800 Episode Num: 99 Episode T: 200 Reward: -126.953\n",
      "Total T: 20000 Episode Num: 100 Episode T: 200 Reward: -236.388\n",
      "recent Evaluation: -122.79234590670868\n",
      "Total T: 20200 Episode Num: 101 Episode T: 200 Reward: -239.131\n",
      "Total T: 20400 Episode Num: 102 Episode T: 200 Reward: -127.397\n",
      "Total T: 20600 Episode Num: 103 Episode T: 200 Reward: -249.860\n",
      "Total T: 20800 Episode Num: 104 Episode T: 200 Reward: -126.329\n",
      "Total T: 21000 Episode Num: 105 Episode T: 200 Reward: -115.943\n",
      "recent Evaluation: -127.62295176028219\n",
      "Total T: 21200 Episode Num: 106 Episode T: 200 Reward: -119.593\n",
      "Total T: 21400 Episode Num: 107 Episode T: 200 Reward: -237.846\n",
      "Total T: 21600 Episode Num: 108 Episode T: 200 Reward: -120.975\n",
      "Total T: 21800 Episode Num: 109 Episode T: 200 Reward: -238.659\n",
      "Total T: 22000 Episode Num: 110 Episode T: 200 Reward: -128.473\n",
      "recent Evaluation: -180.6222400053502\n",
      "Total T: 22200 Episode Num: 111 Episode T: 200 Reward: -125.210\n",
      "Total T: 22400 Episode Num: 112 Episode T: 200 Reward: -349.234\n",
      "Total T: 22600 Episode Num: 113 Episode T: 200 Reward: -124.257\n",
      "Total T: 22800 Episode Num: 114 Episode T: 200 Reward: -127.129\n",
      "Total T: 23000 Episode Num: 115 Episode T: 200 Reward: -124.484\n",
      "recent Evaluation: -132.92735107264184\n",
      "Total T: 23200 Episode Num: 116 Episode T: 200 Reward: -126.728\n",
      "Total T: 23400 Episode Num: 117 Episode T: 200 Reward: -123.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 23600 Episode Num: 118 Episode T: 200 Reward: -117.265\n",
      "Total T: 23800 Episode Num: 119 Episode T: 200 Reward: -353.471\n",
      "Total T: 24000 Episode Num: 120 Episode T: 200 Reward: -120.831\n",
      "recent Evaluation: -123.73558012844316\n",
      "Total T: 24200 Episode Num: 121 Episode T: 200 Reward: -127.234\n",
      "Total T: 24400 Episode Num: 122 Episode T: 200 Reward: -117.895\n",
      "Total T: 24600 Episode Num: 123 Episode T: 200 Reward: -121.637\n",
      "Total T: 24800 Episode Num: 124 Episode T: 200 Reward: -126.568\n",
      "Total T: 25000 Episode Num: 125 Episode T: 200 Reward: -234.141\n",
      "recent Evaluation: -133.3020174099737\n",
      "Total T: 25200 Episode Num: 126 Episode T: 200 Reward: -365.004\n",
      "Total T: 25400 Episode Num: 127 Episode T: 200 Reward: -115.620\n",
      "Total T: 25600 Episode Num: 128 Episode T: 200 Reward: -1.717\n",
      "Total T: 25800 Episode Num: 129 Episode T: 200 Reward: -118.602\n",
      "Total T: 26000 Episode Num: 130 Episode T: 200 Reward: -119.785\n",
      "recent Evaluation: -157.46882118705662\n",
      "Total T: 26200 Episode Num: 131 Episode T: 200 Reward: -239.751\n",
      "Total T: 26400 Episode Num: 132 Episode T: 200 Reward: -124.744\n",
      "Total T: 26600 Episode Num: 133 Episode T: 200 Reward: -128.013\n",
      "Total T: 26800 Episode Num: 134 Episode T: 200 Reward: -128.880\n",
      "Total T: 27000 Episode Num: 135 Episode T: 200 Reward: -126.781\n",
      "recent Evaluation: -109.95272226619743\n",
      "Total T: 27200 Episode Num: 136 Episode T: 200 Reward: -242.541\n",
      "Total T: 27400 Episode Num: 137 Episode T: 200 Reward: -344.689\n",
      "Total T: 27600 Episode Num: 138 Episode T: 200 Reward: -1.370\n",
      "Total T: 27800 Episode Num: 139 Episode T: 200 Reward: -119.403\n",
      "Total T: 28000 Episode Num: 140 Episode T: 200 Reward: -243.012\n",
      "recent Evaluation: -109.31871892884719\n",
      "Total T: 28200 Episode Num: 141 Episode T: 200 Reward: -242.663\n",
      "Total T: 28400 Episode Num: 142 Episode T: 200 Reward: -361.848\n",
      "Total T: 28600 Episode Num: 143 Episode T: 200 Reward: -126.642\n",
      "Total T: 28800 Episode Num: 144 Episode T: 200 Reward: -122.286\n",
      "Total T: 29000 Episode Num: 145 Episode T: 200 Reward: -126.720\n",
      "recent Evaluation: -153.78375665489244\n",
      "Total T: 29200 Episode Num: 146 Episode T: 200 Reward: -125.684\n",
      "Total T: 29400 Episode Num: 147 Episode T: 200 Reward: -115.872\n",
      "Total T: 29600 Episode Num: 148 Episode T: 200 Reward: -121.908\n",
      "Total T: 29800 Episode Num: 149 Episode T: 200 Reward: -1.309\n",
      "Total T: 30000 Episode Num: 150 Episode T: 200 Reward: -253.297\n",
      "recent Evaluation: -134.96956599682076\n",
      "Total T: 30200 Episode Num: 151 Episode T: 200 Reward: -126.106\n",
      "Total T: 30400 Episode Num: 152 Episode T: 200 Reward: -116.387\n",
      "Total T: 30600 Episode Num: 153 Episode T: 200 Reward: -122.047\n",
      "Total T: 30800 Episode Num: 154 Episode T: 200 Reward: -121.987\n",
      "Total T: 31000 Episode Num: 155 Episode T: 200 Reward: -1.013\n",
      "recent Evaluation: -167.9931749681445\n",
      "Total T: 31200 Episode Num: 156 Episode T: 200 Reward: -119.068\n",
      "Total T: 31400 Episode Num: 157 Episode T: 200 Reward: -129.752\n",
      "Total T: 31600 Episode Num: 158 Episode T: 200 Reward: -122.390\n",
      "Total T: 31800 Episode Num: 159 Episode T: 200 Reward: -240.175\n",
      "Total T: 32000 Episode Num: 160 Episode T: 200 Reward: -237.856\n",
      "recent Evaluation: -111.36517920460335\n",
      "Total T: 32200 Episode Num: 161 Episode T: 200 Reward: -235.632\n",
      "Total T: 32400 Episode Num: 162 Episode T: 200 Reward: -125.643\n",
      "Total T: 32600 Episode Num: 163 Episode T: 200 Reward: -241.554\n",
      "Total T: 32800 Episode Num: 164 Episode T: 200 Reward: -341.456\n",
      "Total T: 33000 Episode Num: 165 Episode T: 200 Reward: -244.695\n",
      "recent Evaluation: -158.572523122349\n",
      "Total T: 33200 Episode Num: 166 Episode T: 200 Reward: -236.718\n",
      "Total T: 33400 Episode Num: 167 Episode T: 200 Reward: -125.758\n",
      "Total T: 33600 Episode Num: 168 Episode T: 200 Reward: -374.022\n",
      "Total T: 33800 Episode Num: 169 Episode T: 200 Reward: -119.968\n",
      "Total T: 34000 Episode Num: 170 Episode T: 200 Reward: -1.489\n",
      "recent Evaluation: -131.79637229503498\n",
      "Total T: 34200 Episode Num: 171 Episode T: 200 Reward: -126.886\n",
      "Total T: 34400 Episode Num: 172 Episode T: 200 Reward: -249.481\n",
      "Total T: 34600 Episode Num: 173 Episode T: 200 Reward: -122.514\n",
      "Total T: 34800 Episode Num: 174 Episode T: 200 Reward: -396.763\n",
      "Total T: 35000 Episode Num: 175 Episode T: 200 Reward: -375.439\n",
      "recent Evaluation: -145.15959659519217\n",
      "Total T: 35200 Episode Num: 176 Episode T: 200 Reward: -1.299\n",
      "Total T: 35400 Episode Num: 177 Episode T: 200 Reward: -123.271\n",
      "Total T: 35600 Episode Num: 178 Episode T: 200 Reward: -118.879\n",
      "Total T: 35800 Episode Num: 179 Episode T: 200 Reward: -125.404\n",
      "Total T: 36000 Episode Num: 180 Episode T: 200 Reward: -127.533\n",
      "recent Evaluation: -108.45237632316393\n",
      "Total T: 36200 Episode Num: 181 Episode T: 200 Reward: -124.668\n",
      "Total T: 36400 Episode Num: 182 Episode T: 200 Reward: -238.298\n",
      "Total T: 36600 Episode Num: 183 Episode T: 200 Reward: -122.482\n",
      "Total T: 36800 Episode Num: 184 Episode T: 200 Reward: -347.481\n",
      "Total T: 37000 Episode Num: 185 Episode T: 200 Reward: -126.028\n",
      "recent Evaluation: -157.61998092735828\n",
      "Total T: 37200 Episode Num: 186 Episode T: 200 Reward: -123.718\n",
      "Total T: 37400 Episode Num: 187 Episode T: 200 Reward: -243.957\n",
      "Total T: 37600 Episode Num: 188 Episode T: 200 Reward: -225.628\n",
      "Total T: 37800 Episode Num: 189 Episode T: 200 Reward: -239.018\n",
      "Total T: 38000 Episode Num: 190 Episode T: 200 Reward: -3.528\n",
      "recent Evaluation: -133.951731696078\n",
      "Total T: 38200 Episode Num: 191 Episode T: 200 Reward: -244.801\n",
      "Total T: 38400 Episode Num: 192 Episode T: 200 Reward: -123.853\n",
      "Total T: 38600 Episode Num: 193 Episode T: 200 Reward: -242.161\n",
      "Total T: 38800 Episode Num: 194 Episode T: 200 Reward: -326.087\n",
      "Total T: 39000 Episode Num: 195 Episode T: 200 Reward: -238.264\n",
      "recent Evaluation: -109.29386984207193\n",
      "Total T: 39200 Episode Num: 196 Episode T: 200 Reward: -248.118\n",
      "Total T: 39400 Episode Num: 197 Episode T: 200 Reward: -228.485\n",
      "Total T: 39600 Episode Num: 198 Episode T: 200 Reward: -128.184\n",
      "Total T: 39800 Episode Num: 199 Episode T: 200 Reward: -122.717\n",
      "Total T: 40000 Episode Num: 200 Episode T: 200 Reward: -1.427\n",
      "recent Evaluation: -168.09351349432166\n",
      "Total T: 40200 Episode Num: 201 Episode T: 200 Reward: -249.694\n",
      "Total T: 40400 Episode Num: 202 Episode T: 200 Reward: -242.365\n",
      "Total T: 40600 Episode Num: 203 Episode T: 200 Reward: -246.057\n",
      "Total T: 40800 Episode Num: 204 Episode T: 200 Reward: -2.549\n",
      "Total T: 41000 Episode Num: 205 Episode T: 200 Reward: -364.377\n",
      "recent Evaluation: -120.65466102538012\n",
      "Total T: 41200 Episode Num: 206 Episode T: 200 Reward: -115.072\n",
      "Total T: 41400 Episode Num: 207 Episode T: 200 Reward: -125.356\n",
      "Total T: 41600 Episode Num: 208 Episode T: 200 Reward: -2.403\n",
      "Total T: 41800 Episode Num: 209 Episode T: 200 Reward: -354.156\n",
      "Total T: 42000 Episode Num: 210 Episode T: 200 Reward: -127.605\n",
      "recent Evaluation: -145.06836670537518\n",
      "Total T: 42200 Episode Num: 211 Episode T: 200 Reward: -236.466\n",
      "Total T: 42400 Episode Num: 212 Episode T: 200 Reward: -122.969\n",
      "Total T: 42600 Episode Num: 213 Episode T: 200 Reward: -125.004\n",
      "Total T: 42800 Episode Num: 214 Episode T: 200 Reward: -1.878\n",
      "Total T: 43000 Episode Num: 215 Episode T: 200 Reward: -128.901\n",
      "recent Evaluation: -132.9016253888738\n",
      "Total T: 43200 Episode Num: 216 Episode T: 200 Reward: -230.424\n",
      "Total T: 43400 Episode Num: 217 Episode T: 200 Reward: -4.491\n",
      "Total T: 43600 Episode Num: 218 Episode T: 200 Reward: -241.163\n",
      "Total T: 43800 Episode Num: 219 Episode T: 200 Reward: -1.742\n",
      "Total T: 44000 Episode Num: 220 Episode T: 200 Reward: -116.694\n",
      "recent Evaluation: -97.84248069573007\n",
      "Total T: 44200 Episode Num: 221 Episode T: 200 Reward: -237.941\n",
      "Total T: 44400 Episode Num: 222 Episode T: 200 Reward: -122.072\n",
      "Total T: 44600 Episode Num: 223 Episode T: 200 Reward: -124.731\n",
      "Total T: 44800 Episode Num: 224 Episode T: 200 Reward: -124.813\n",
      "Total T: 45000 Episode Num: 225 Episode T: 200 Reward: -363.787\n",
      "recent Evaluation: -84.7643539752122\n",
      "Total T: 45200 Episode Num: 226 Episode T: 200 Reward: -124.722\n",
      "Total T: 45400 Episode Num: 227 Episode T: 200 Reward: -125.909\n",
      "Total T: 45600 Episode Num: 228 Episode T: 200 Reward: -123.259\n",
      "Total T: 45800 Episode Num: 229 Episode T: 200 Reward: -118.214\n",
      "Total T: 46000 Episode Num: 230 Episode T: 200 Reward: -237.379\n",
      "recent Evaluation: -133.0742500702181\n",
      "Total T: 46200 Episode Num: 231 Episode T: 200 Reward: -126.703\n",
      "Total T: 46400 Episode Num: 232 Episode T: 200 Reward: -127.289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 46600 Episode Num: 233 Episode T: 200 Reward: -305.849\n",
      "Total T: 46800 Episode Num: 234 Episode T: 200 Reward: -126.534\n",
      "Total T: 47000 Episode Num: 235 Episode T: 200 Reward: -1.081\n",
      "recent Evaluation: -191.33812408344167\n",
      "Total T: 47200 Episode Num: 236 Episode T: 200 Reward: -121.116\n",
      "Total T: 47400 Episode Num: 237 Episode T: 200 Reward: -118.637\n",
      "Total T: 47600 Episode Num: 238 Episode T: 200 Reward: -243.419\n",
      "Total T: 47800 Episode Num: 239 Episode T: 200 Reward: -114.245\n",
      "Total T: 48000 Episode Num: 240 Episode T: 200 Reward: -240.785\n",
      "recent Evaluation: -193.95946099086848\n",
      "Total T: 48200 Episode Num: 241 Episode T: 200 Reward: -122.227\n",
      "Total T: 48400 Episode Num: 242 Episode T: 200 Reward: -119.180\n",
      "Total T: 48600 Episode Num: 243 Episode T: 200 Reward: -122.883\n",
      "Total T: 48800 Episode Num: 244 Episode T: 200 Reward: -121.227\n",
      "Total T: 49000 Episode Num: 245 Episode T: 200 Reward: -1.432\n",
      "recent Evaluation: -122.34200580331556\n",
      "Total T: 49200 Episode Num: 246 Episode T: 200 Reward: -125.076\n",
      "Total T: 49400 Episode Num: 247 Episode T: 200 Reward: -122.457\n",
      "Total T: 49600 Episode Num: 248 Episode T: 200 Reward: -119.866\n",
      "Total T: 49800 Episode Num: 249 Episode T: 200 Reward: -129.438\n",
      "Total T: 50000 Episode Num: 250 Episode T: 200 Reward: -122.976\n",
      "recent Evaluation: -120.60841675758397\n",
      "Total T: 50200 Episode Num: 251 Episode T: 200 Reward: -117.724\n",
      "Total T: 50400 Episode Num: 252 Episode T: 200 Reward: -122.374\n",
      "Total T: 50600 Episode Num: 253 Episode T: 200 Reward: -126.421\n",
      "Total T: 50800 Episode Num: 254 Episode T: 200 Reward: -240.409\n",
      "Total T: 51000 Episode Num: 255 Episode T: 200 Reward: -129.494\n",
      "recent Evaluation: -158.54747250647176\n",
      "Total T: 51200 Episode Num: 256 Episode T: 200 Reward: -116.965\n",
      "Total T: 51400 Episode Num: 257 Episode T: 200 Reward: -124.412\n",
      "Total T: 51600 Episode Num: 258 Episode T: 200 Reward: -124.024\n",
      "Total T: 51800 Episode Num: 259 Episode T: 200 Reward: -230.090\n",
      "Total T: 52000 Episode Num: 260 Episode T: 200 Reward: -341.223\n",
      "recent Evaluation: -207.20429611627682\n",
      "Total T: 52200 Episode Num: 261 Episode T: 200 Reward: -124.771\n",
      "Total T: 52400 Episode Num: 262 Episode T: 200 Reward: -250.454\n",
      "Total T: 52600 Episode Num: 263 Episode T: 200 Reward: -116.730\n",
      "Total T: 52800 Episode Num: 264 Episode T: 200 Reward: -1.069\n",
      "Total T: 53000 Episode Num: 265 Episode T: 200 Reward: -118.852\n",
      "recent Evaluation: -131.88973488089408\n",
      "Total T: 53200 Episode Num: 266 Episode T: 200 Reward: -1.033\n",
      "Total T: 53400 Episode Num: 267 Episode T: 200 Reward: -127.197\n",
      "Total T: 53600 Episode Num: 268 Episode T: 200 Reward: -117.518\n",
      "Total T: 53800 Episode Num: 269 Episode T: 200 Reward: -242.722\n",
      "Total T: 54000 Episode Num: 270 Episode T: 200 Reward: -124.501\n",
      "recent Evaluation: -178.31883084749842\n",
      "Total T: 54200 Episode Num: 271 Episode T: 200 Reward: -125.762\n",
      "Total T: 54400 Episode Num: 272 Episode T: 200 Reward: -120.719\n",
      "Total T: 54600 Episode Num: 273 Episode T: 200 Reward: -250.750\n",
      "Total T: 54800 Episode Num: 274 Episode T: 200 Reward: -1.532\n",
      "Total T: 55000 Episode Num: 275 Episode T: 200 Reward: -345.244\n",
      "recent Evaluation: -165.3510501126464\n",
      "Total T: 55200 Episode Num: 276 Episode T: 200 Reward: -366.571\n",
      "Total T: 55400 Episode Num: 277 Episode T: 200 Reward: -114.725\n",
      "Total T: 55600 Episode Num: 278 Episode T: 200 Reward: -236.854\n",
      "Total T: 55800 Episode Num: 279 Episode T: 200 Reward: -123.453\n",
      "Total T: 56000 Episode Num: 280 Episode T: 200 Reward: -118.014\n",
      "recent Evaluation: -152.5652256498527\n",
      "Total T: 56200 Episode Num: 281 Episode T: 200 Reward: -117.604\n",
      "Total T: 56400 Episode Num: 282 Episode T: 200 Reward: -126.073\n",
      "Total T: 56600 Episode Num: 283 Episode T: 200 Reward: -120.603\n",
      "Total T: 56800 Episode Num: 284 Episode T: 200 Reward: -124.222\n",
      "Total T: 57000 Episode Num: 285 Episode T: 200 Reward: -243.043\n",
      "recent Evaluation: -134.49194902373617\n",
      "Total T: 57200 Episode Num: 286 Episode T: 200 Reward: -125.650\n",
      "Total T: 57400 Episode Num: 287 Episode T: 200 Reward: -125.217\n",
      "Total T: 57600 Episode Num: 288 Episode T: 200 Reward: -353.539\n",
      "Total T: 57800 Episode Num: 289 Episode T: 200 Reward: -2.337\n",
      "Total T: 58000 Episode Num: 290 Episode T: 200 Reward: -418.422\n",
      "recent Evaluation: -169.09676108900308\n",
      "Total T: 58200 Episode Num: 291 Episode T: 200 Reward: -238.189\n",
      "Total T: 58400 Episode Num: 292 Episode T: 200 Reward: -120.374\n",
      "Total T: 58600 Episode Num: 293 Episode T: 200 Reward: -126.796\n",
      "Total T: 58800 Episode Num: 294 Episode T: 200 Reward: -121.772\n",
      "Total T: 59000 Episode Num: 295 Episode T: 200 Reward: -244.175\n",
      "recent Evaluation: -179.94693047644958\n",
      "Total T: 59200 Episode Num: 296 Episode T: 200 Reward: -125.794\n",
      "Total T: 59400 Episode Num: 297 Episode T: 200 Reward: -122.988\n",
      "Total T: 59600 Episode Num: 298 Episode T: 200 Reward: -121.717\n",
      "Total T: 59800 Episode Num: 299 Episode T: 200 Reward: -241.432\n",
      "Total T: 60000 Episode Num: 300 Episode T: 200 Reward: -239.982\n",
      "recent Evaluation: -140.21958357988686\n",
      "Total T: 60200 Episode Num: 301 Episode T: 200 Reward: -1.358\n",
      "Total T: 60400 Episode Num: 302 Episode T: 200 Reward: -125.196\n",
      "Total T: 60600 Episode Num: 303 Episode T: 200 Reward: -357.507\n",
      "Total T: 60800 Episode Num: 304 Episode T: 200 Reward: -128.121\n",
      "Total T: 61000 Episode Num: 305 Episode T: 200 Reward: -125.726\n",
      "recent Evaluation: -151.01894438293021\n",
      "Total T: 61200 Episode Num: 306 Episode T: 200 Reward: -234.340\n",
      "Total T: 61400 Episode Num: 307 Episode T: 200 Reward: -121.651\n",
      "Total T: 61600 Episode Num: 308 Episode T: 200 Reward: -242.054\n",
      "Total T: 61800 Episode Num: 309 Episode T: 200 Reward: -123.005\n",
      "Total T: 62000 Episode Num: 310 Episode T: 200 Reward: -125.293\n",
      "recent Evaluation: -121.64631668404061\n",
      "Total T: 62200 Episode Num: 311 Episode T: 200 Reward: -120.089\n",
      "Total T: 62400 Episode Num: 312 Episode T: 200 Reward: -2.811\n",
      "Total T: 62600 Episode Num: 313 Episode T: 200 Reward: -120.612\n",
      "Total T: 62800 Episode Num: 314 Episode T: 200 Reward: -125.278\n",
      "Total T: 63000 Episode Num: 315 Episode T: 200 Reward: -239.548\n",
      "recent Evaluation: -151.64488911498057\n",
      "Total T: 63200 Episode Num: 316 Episode T: 200 Reward: -331.330\n",
      "Total T: 63400 Episode Num: 317 Episode T: 200 Reward: -121.646\n",
      "Total T: 63600 Episode Num: 318 Episode T: 200 Reward: -0.736\n",
      "Total T: 63800 Episode Num: 319 Episode T: 200 Reward: -120.724\n",
      "Total T: 64000 Episode Num: 320 Episode T: 200 Reward: -244.310\n",
      "recent Evaluation: -189.9670235727509\n",
      "Total T: 64200 Episode Num: 321 Episode T: 200 Reward: -126.745\n",
      "Total T: 64400 Episode Num: 322 Episode T: 200 Reward: -122.260\n",
      "Total T: 64600 Episode Num: 323 Episode T: 200 Reward: -0.997\n",
      "Total T: 64800 Episode Num: 324 Episode T: 200 Reward: -117.179\n",
      "Total T: 65000 Episode Num: 325 Episode T: 200 Reward: -323.214\n",
      "recent Evaluation: -148.17378505300647\n",
      "Total T: 65200 Episode Num: 326 Episode T: 200 Reward: -122.044\n",
      "Total T: 65400 Episode Num: 327 Episode T: 200 Reward: -116.465\n",
      "Total T: 65600 Episode Num: 328 Episode T: 200 Reward: -123.555\n",
      "Total T: 65800 Episode Num: 329 Episode T: 200 Reward: -2.555\n",
      "Total T: 66000 Episode Num: 330 Episode T: 200 Reward: -123.392\n",
      "recent Evaluation: -122.067071350975\n",
      "Total T: 66200 Episode Num: 331 Episode T: 200 Reward: -229.457\n",
      "Total T: 66400 Episode Num: 332 Episode T: 200 Reward: -246.182\n",
      "Total T: 66600 Episode Num: 333 Episode T: 200 Reward: -240.830\n",
      "Total T: 66800 Episode Num: 334 Episode T: 200 Reward: -243.321\n",
      "Total T: 67000 Episode Num: 335 Episode T: 200 Reward: -123.332\n",
      "recent Evaluation: -172.72482534866307\n",
      "Total T: 67200 Episode Num: 336 Episode T: 200 Reward: -323.911\n",
      "Total T: 67400 Episode Num: 337 Episode T: 200 Reward: -117.836\n",
      "Total T: 67600 Episode Num: 338 Episode T: 200 Reward: -124.692\n",
      "Total T: 67800 Episode Num: 339 Episode T: 200 Reward: -121.057\n",
      "Total T: 68000 Episode Num: 340 Episode T: 200 Reward: -125.218\n",
      "recent Evaluation: -120.99836548418469\n",
      "Total T: 68200 Episode Num: 341 Episode T: 200 Reward: -125.169\n",
      "Total T: 68400 Episode Num: 342 Episode T: 200 Reward: -356.268\n",
      "Total T: 68600 Episode Num: 343 Episode T: 200 Reward: -125.682\n",
      "Total T: 68800 Episode Num: 344 Episode T: 200 Reward: -1.392\n",
      "Total T: 69000 Episode Num: 345 Episode T: 200 Reward: -1.567\n",
      "recent Evaluation: -132.620966351453\n",
      "Total T: 69200 Episode Num: 346 Episode T: 200 Reward: -248.447\n",
      "Total T: 69400 Episode Num: 347 Episode T: 200 Reward: -116.613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 69600 Episode Num: 348 Episode T: 200 Reward: -119.364\n",
      "Total T: 69800 Episode Num: 349 Episode T: 200 Reward: -1.199\n",
      "Total T: 70000 Episode Num: 350 Episode T: 200 Reward: -244.291\n",
      "recent Evaluation: -132.0543874007601\n",
      "Total T: 70200 Episode Num: 351 Episode T: 200 Reward: -119.988\n",
      "Total T: 70400 Episode Num: 352 Episode T: 200 Reward: -122.893\n",
      "Total T: 70600 Episode Num: 353 Episode T: 200 Reward: -247.563\n",
      "Total T: 70800 Episode Num: 354 Episode T: 200 Reward: -122.230\n",
      "Total T: 71000 Episode Num: 355 Episode T: 200 Reward: -238.401\n",
      "recent Evaluation: -97.03254072458876\n",
      "Total T: 71200 Episode Num: 356 Episode T: 200 Reward: -119.228\n",
      "Total T: 71400 Episode Num: 357 Episode T: 200 Reward: -238.424\n",
      "Total T: 71600 Episode Num: 358 Episode T: 200 Reward: -120.896\n",
      "Total T: 71800 Episode Num: 359 Episode T: 200 Reward: -234.536\n",
      "Total T: 72000 Episode Num: 360 Episode T: 200 Reward: -377.734\n",
      "recent Evaluation: -131.6689400999754\n",
      "Total T: 72200 Episode Num: 361 Episode T: 200 Reward: -247.715\n",
      "Total T: 72400 Episode Num: 362 Episode T: 200 Reward: -114.168\n",
      "Total T: 72600 Episode Num: 363 Episode T: 200 Reward: -346.110\n",
      "Total T: 72800 Episode Num: 364 Episode T: 200 Reward: -116.464\n",
      "Total T: 73000 Episode Num: 365 Episode T: 200 Reward: -128.086\n",
      "recent Evaluation: -153.06003090734868\n",
      "Total T: 73200 Episode Num: 366 Episode T: 200 Reward: -231.903\n",
      "Total T: 73400 Episode Num: 367 Episode T: 200 Reward: -116.736\n",
      "Total T: 73600 Episode Num: 368 Episode T: 200 Reward: -368.433\n",
      "Total T: 73800 Episode Num: 369 Episode T: 200 Reward: -240.191\n",
      "Total T: 74000 Episode Num: 370 Episode T: 200 Reward: -120.959\n",
      "recent Evaluation: -155.37729267331065\n",
      "Total T: 74200 Episode Num: 371 Episode T: 200 Reward: -118.189\n",
      "Total T: 74400 Episode Num: 372 Episode T: 200 Reward: -125.180\n",
      "Total T: 74600 Episode Num: 373 Episode T: 200 Reward: -239.567\n",
      "Total T: 74800 Episode Num: 374 Episode T: 200 Reward: -227.102\n",
      "Total T: 75000 Episode Num: 375 Episode T: 200 Reward: -128.832\n",
      "recent Evaluation: -131.08179357219882\n",
      "Total T: 75200 Episode Num: 376 Episode T: 200 Reward: -300.674\n",
      "Total T: 75400 Episode Num: 377 Episode T: 200 Reward: -121.293\n",
      "Total T: 75600 Episode Num: 378 Episode T: 200 Reward: -118.168\n",
      "Total T: 75800 Episode Num: 379 Episode T: 200 Reward: -338.889\n",
      "Total T: 76000 Episode Num: 380 Episode T: 200 Reward: -116.748\n",
      "recent Evaluation: -161.5175542914702\n",
      "Total T: 76200 Episode Num: 381 Episode T: 200 Reward: -127.923\n",
      "Total T: 76400 Episode Num: 382 Episode T: 200 Reward: -124.995\n",
      "Total T: 76600 Episode Num: 383 Episode T: 200 Reward: -123.492\n",
      "Total T: 76800 Episode Num: 384 Episode T: 200 Reward: -117.226\n",
      "Total T: 77000 Episode Num: 385 Episode T: 200 Reward: -228.370\n",
      "recent Evaluation: -112.53314260484493\n",
      "Total T: 77200 Episode Num: 386 Episode T: 200 Reward: -248.789\n",
      "Total T: 77400 Episode Num: 387 Episode T: 200 Reward: -120.898\n",
      "Total T: 77600 Episode Num: 388 Episode T: 200 Reward: -241.772\n",
      "Total T: 77800 Episode Num: 389 Episode T: 200 Reward: -244.566\n",
      "Total T: 78000 Episode Num: 390 Episode T: 200 Reward: -241.745\n",
      "recent Evaluation: -132.4244959291292\n",
      "Total T: 78200 Episode Num: 391 Episode T: 200 Reward: -233.792\n",
      "Total T: 78400 Episode Num: 392 Episode T: 200 Reward: -130.252\n",
      "Total T: 78600 Episode Num: 393 Episode T: 200 Reward: -119.798\n",
      "Total T: 78800 Episode Num: 394 Episode T: 200 Reward: -115.462\n",
      "Total T: 79000 Episode Num: 395 Episode T: 200 Reward: -250.336\n",
      "recent Evaluation: -204.29091392936195\n",
      "Total T: 79200 Episode Num: 396 Episode T: 200 Reward: -239.610\n",
      "Total T: 79400 Episode Num: 397 Episode T: 200 Reward: -124.731\n",
      "Total T: 79600 Episode Num: 398 Episode T: 200 Reward: -348.838\n",
      "Total T: 79800 Episode Num: 399 Episode T: 200 Reward: -117.566\n",
      "Total T: 80000 Episode Num: 400 Episode T: 200 Reward: -119.283\n",
      "recent Evaluation: -156.8456073589358\n",
      "Total T: 80200 Episode Num: 401 Episode T: 200 Reward: -119.443\n",
      "Total T: 80400 Episode Num: 402 Episode T: 200 Reward: -126.189\n",
      "Total T: 80600 Episode Num: 403 Episode T: 200 Reward: -122.286\n",
      "Total T: 80800 Episode Num: 404 Episode T: 200 Reward: -308.948\n",
      "Total T: 81000 Episode Num: 405 Episode T: 200 Reward: -122.791\n",
      "recent Evaluation: -157.4720010875135\n",
      "Total T: 81200 Episode Num: 406 Episode T: 200 Reward: -128.039\n",
      "Total T: 81400 Episode Num: 407 Episode T: 200 Reward: -363.771\n",
      "Total T: 81600 Episode Num: 408 Episode T: 200 Reward: -122.360\n",
      "Total T: 81800 Episode Num: 409 Episode T: 200 Reward: -117.002\n",
      "Total T: 82000 Episode Num: 410 Episode T: 200 Reward: -123.804\n",
      "recent Evaluation: -143.42780891399102\n",
      "Total T: 82200 Episode Num: 411 Episode T: 200 Reward: -117.298\n",
      "Total T: 82400 Episode Num: 412 Episode T: 200 Reward: -238.921\n",
      "Total T: 82600 Episode Num: 413 Episode T: 200 Reward: -126.225\n",
      "Total T: 82800 Episode Num: 414 Episode T: 200 Reward: -123.974\n",
      "Total T: 83000 Episode Num: 415 Episode T: 200 Reward: -1.193\n",
      "recent Evaluation: -156.10699515166783\n",
      "Total T: 83200 Episode Num: 416 Episode T: 200 Reward: -119.362\n",
      "Total T: 83400 Episode Num: 417 Episode T: 200 Reward: -238.756\n",
      "Total T: 83600 Episode Num: 418 Episode T: 200 Reward: -1.772\n",
      "Total T: 83800 Episode Num: 419 Episode T: 200 Reward: -121.996\n",
      "Total T: 84000 Episode Num: 420 Episode T: 200 Reward: -241.459\n",
      "recent Evaluation: -109.19115486706303\n",
      "Total T: 84200 Episode Num: 421 Episode T: 200 Reward: -359.897\n",
      "Total T: 84400 Episode Num: 422 Episode T: 200 Reward: -242.551\n",
      "Total T: 84600 Episode Num: 423 Episode T: 200 Reward: -239.277\n",
      "Total T: 84800 Episode Num: 424 Episode T: 200 Reward: -122.412\n",
      "Total T: 85000 Episode Num: 425 Episode T: 200 Reward: -1.525\n",
      "recent Evaluation: -146.28720753939726\n",
      "Total T: 85200 Episode Num: 426 Episode T: 200 Reward: -119.706\n",
      "Total T: 85400 Episode Num: 427 Episode T: 200 Reward: -124.944\n",
      "Total T: 85600 Episode Num: 428 Episode T: 200 Reward: -128.102\n",
      "Total T: 85800 Episode Num: 429 Episode T: 200 Reward: -3.014\n",
      "Total T: 86000 Episode Num: 430 Episode T: 200 Reward: -238.353\n",
      "recent Evaluation: -169.26985500810312\n",
      "Total T: 86200 Episode Num: 431 Episode T: 200 Reward: -375.861\n",
      "Total T: 86400 Episode Num: 432 Episode T: 200 Reward: -124.779\n",
      "Total T: 86600 Episode Num: 433 Episode T: 200 Reward: -237.066\n",
      "Total T: 86800 Episode Num: 434 Episode T: 200 Reward: -125.297\n",
      "Total T: 87000 Episode Num: 435 Episode T: 200 Reward: -360.122\n",
      "recent Evaluation: -158.5785962433709\n",
      "Total T: 87200 Episode Num: 436 Episode T: 200 Reward: -1.782\n",
      "Total T: 87400 Episode Num: 437 Episode T: 200 Reward: -115.844\n",
      "Total T: 87600 Episode Num: 438 Episode T: 200 Reward: -252.422\n",
      "Total T: 87800 Episode Num: 439 Episode T: 200 Reward: -120.998\n",
      "Total T: 88000 Episode Num: 440 Episode T: 200 Reward: -125.092\n",
      "recent Evaluation: -194.0693008143188\n",
      "Total T: 88200 Episode Num: 441 Episode T: 200 Reward: -6.398\n",
      "Total T: 88400 Episode Num: 442 Episode T: 200 Reward: -128.785\n",
      "Total T: 88600 Episode Num: 443 Episode T: 200 Reward: -245.593\n",
      "Total T: 88800 Episode Num: 444 Episode T: 200 Reward: -125.940\n",
      "Total T: 89000 Episode Num: 445 Episode T: 200 Reward: -120.500\n",
      "recent Evaluation: -163.93159286937097\n",
      "Total T: 89200 Episode Num: 446 Episode T: 200 Reward: -120.510\n",
      "Total T: 89400 Episode Num: 447 Episode T: 200 Reward: -244.853\n",
      "Total T: 89600 Episode Num: 448 Episode T: 200 Reward: -124.533\n",
      "Total T: 89800 Episode Num: 449 Episode T: 200 Reward: -127.601\n",
      "Total T: 90000 Episode Num: 450 Episode T: 200 Reward: -129.060\n",
      "recent Evaluation: -73.85213779568781\n",
      "Total T: 90200 Episode Num: 451 Episode T: 200 Reward: -4.046\n",
      "Total T: 90400 Episode Num: 452 Episode T: 200 Reward: -244.232\n",
      "Total T: 90600 Episode Num: 453 Episode T: 200 Reward: -2.258\n",
      "Total T: 90800 Episode Num: 454 Episode T: 200 Reward: -128.002\n",
      "Total T: 91000 Episode Num: 455 Episode T: 200 Reward: -289.984\n",
      "recent Evaluation: -154.18622418677717\n",
      "Total T: 91200 Episode Num: 456 Episode T: 200 Reward: -129.870\n",
      "Total T: 91400 Episode Num: 457 Episode T: 200 Reward: -1.159\n",
      "Total T: 91600 Episode Num: 458 Episode T: 200 Reward: -116.128\n",
      "Total T: 91800 Episode Num: 459 Episode T: 200 Reward: -2.357\n",
      "Total T: 92000 Episode Num: 460 Episode T: 200 Reward: -2.513\n",
      "recent Evaluation: -146.093743838266\n",
      "Total T: 92200 Episode Num: 461 Episode T: 200 Reward: -127.385\n",
      "Total T: 92400 Episode Num: 462 Episode T: 200 Reward: -239.939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 92600 Episode Num: 463 Episode T: 200 Reward: -127.560\n",
      "Total T: 92800 Episode Num: 464 Episode T: 200 Reward: -119.656\n",
      "Total T: 93000 Episode Num: 465 Episode T: 200 Reward: -255.179\n",
      "recent Evaluation: -144.83055500369113\n",
      "Total T: 93200 Episode Num: 466 Episode T: 200 Reward: -250.432\n",
      "Total T: 93400 Episode Num: 467 Episode T: 200 Reward: -349.822\n",
      "Total T: 93600 Episode Num: 468 Episode T: 200 Reward: -123.375\n",
      "Total T: 93800 Episode Num: 469 Episode T: 200 Reward: -121.372\n",
      "Total T: 94000 Episode Num: 470 Episode T: 200 Reward: -234.942\n",
      "recent Evaluation: -219.65795159696592\n",
      "Total T: 94200 Episode Num: 471 Episode T: 200 Reward: -236.889\n",
      "Total T: 94400 Episode Num: 472 Episode T: 200 Reward: -120.506\n",
      "Total T: 94600 Episode Num: 473 Episode T: 200 Reward: -239.806\n",
      "Total T: 94800 Episode Num: 474 Episode T: 200 Reward: -369.585\n",
      "Total T: 95000 Episode Num: 475 Episode T: 200 Reward: -130.987\n",
      "recent Evaluation: -134.32384092803673\n",
      "Total T: 95200 Episode Num: 476 Episode T: 200 Reward: -237.756\n",
      "Total T: 95400 Episode Num: 477 Episode T: 200 Reward: -123.077\n",
      "Total T: 95600 Episode Num: 478 Episode T: 200 Reward: -128.683\n",
      "Total T: 95800 Episode Num: 479 Episode T: 200 Reward: -121.701\n",
      "Total T: 96000 Episode Num: 480 Episode T: 200 Reward: -223.597\n",
      "recent Evaluation: -184.29908955950776\n",
      "Total T: 96200 Episode Num: 481 Episode T: 200 Reward: -231.344\n",
      "Total T: 96400 Episode Num: 482 Episode T: 200 Reward: -241.311\n",
      "Total T: 96600 Episode Num: 483 Episode T: 200 Reward: -233.951\n",
      "Total T: 96800 Episode Num: 484 Episode T: 200 Reward: -126.840\n",
      "Total T: 97000 Episode Num: 485 Episode T: 200 Reward: -121.716\n",
      "recent Evaluation: -110.28364367652019\n",
      "Total T: 97200 Episode Num: 486 Episode T: 200 Reward: -246.581\n",
      "Total T: 97400 Episode Num: 487 Episode T: 200 Reward: -247.013\n",
      "Total T: 97600 Episode Num: 488 Episode T: 200 Reward: -2.539\n",
      "Total T: 97800 Episode Num: 489 Episode T: 200 Reward: -122.639\n",
      "Total T: 98000 Episode Num: 490 Episode T: 200 Reward: -249.830\n",
      "recent Evaluation: -120.49448512507183\n",
      "Total T: 98200 Episode Num: 491 Episode T: 200 Reward: -2.292\n",
      "Total T: 98400 Episode Num: 492 Episode T: 200 Reward: -231.667\n",
      "Total T: 98600 Episode Num: 493 Episode T: 200 Reward: -232.154\n",
      "Total T: 98800 Episode Num: 494 Episode T: 200 Reward: -122.278\n",
      "Total T: 99000 Episode Num: 495 Episode T: 200 Reward: -251.048\n",
      "recent Evaluation: -160.2019400449095\n",
      "Total T: 99200 Episode Num: 496 Episode T: 200 Reward: -122.314\n",
      "Total T: 99400 Episode Num: 497 Episode T: 200 Reward: -122.088\n",
      "Total T: 99600 Episode Num: 498 Episode T: 200 Reward: -243.572\n",
      "Total T: 99800 Episode Num: 499 Episode T: 200 Reward: -1.201\n",
      "Total T: 100000 Episode Num: 500 Episode T: 200 Reward: -234.967\n",
      "recent Evaluation: -110.33574089865087\n"
     ]
    }
   ],
   "source": [
    "# The following scripts run the DDPG algorithm.\n",
    "\n",
    "alias = 'ddpg' # an alias of your experiment, used as a label\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import argparse\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import utils\n",
    "import TD3\n",
    "import DDPG\n",
    "\n",
    "def eval_policy(policy, eval_episodes=10):\n",
    "    eval_env = gym.make(ENV_NAME)\n",
    "\n",
    "    avg_reward = 0.\n",
    "    for _ in range(eval_episodes):\n",
    "        state, done = eval_env.reset(), False\n",
    "        while not done:\n",
    "            action = policy.select_action(np.array(state))\n",
    "            state, reward, done,_ = eval_env.step(action)\n",
    "            avg_reward += reward\n",
    "\n",
    "    avg_reward /= eval_episodes\n",
    "    #print(\"---------------------------------------\")\n",
    "    #print(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "    #print(\"---------------------------------------\")\n",
    "    return avg_reward\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = env.action_space.high[0]\n",
    "\n",
    "args_policy_noise = 0.2\n",
    "args_noise_clip = 0.5\n",
    "args_policy_freq = 2\n",
    "args_max_timesteps = 100000\n",
    "args_expl_noise = 0.1\n",
    "args_batch_size = 25\n",
    "args_eval_freq = 1000\n",
    "args_start_timesteps = 0\n",
    "\n",
    "kwargs = {\n",
    "    \"state_dim\": state_dim,\n",
    "    \"action_dim\": action_dim,\n",
    "    \"max_action\": max_action,\n",
    "    \"discount\": 0.99,\n",
    "    \"tau\": 0.005\n",
    "}\n",
    "\n",
    "\n",
    "args_policy = 'DDPG'\n",
    "\n",
    "if args_policy == \"TD3\":\n",
    "    # Target policy smoothing is scaled wrt the action scale\n",
    "    kwargs[\"policy_noise\"] = args_policy_noise * max_action\n",
    "    kwargs[\"noise_clip\"] = args_noise_clip * max_action\n",
    "    kwargs[\"policy_freq\"] = args_policy_freq\n",
    "    policy = TD3.TD3(**kwargs)\n",
    "elif args_policy == \"DDPG\":\n",
    "    policy = DDPG.DDPG(**kwargs)\n",
    "replay_buffer = utils.ReplayBuffer(state_dim, action_dim)\n",
    "\n",
    "# Evaluate untrained policy\n",
    "evaluations = [eval_policy(policy)]\n",
    "\n",
    "state, done = env.reset(), False\n",
    "episode_reward = 0\n",
    "episode_timesteps = 0\n",
    "episode_num = 0\n",
    "counter = 0\n",
    "msk_list = []        \n",
    "temp_curve = [eval_policy(policy)]\n",
    "temp_val = []\n",
    "for t in range(int(args_max_timesteps)):\n",
    "    episode_timesteps += 1\n",
    "    counter += 1\n",
    "    # Select action randomly or according to policy\n",
    "    if t < args_start_timesteps:\n",
    "        action = np.random.uniform(-max_action,max_action,action_dim)\n",
    "    else:\n",
    "        if np.random.uniform(0,1) < 0.1:\n",
    "            action = np.random.uniform(-max_action,max_action,action_dim)\n",
    "        else:\n",
    "            action = (\n",
    "                policy.select_action(np.array(state))\n",
    "                + np.random.normal(0, max_action * args_expl_noise, size=action_dim)\n",
    "            ).clip(-max_action, max_action)\n",
    "\n",
    "    # Perform action\n",
    "    next_state, reward, done,_ = env.step(action) \n",
    "    done_bool = float(done) if episode_timesteps < env._max_episode_steps else 0\n",
    "\n",
    "    replay_buffer.add(state, action, next_state, reward, done_bool)\n",
    "\n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "\n",
    "    if t >= args_start_timesteps:\n",
    "        '''TD3'''\n",
    "        last_val = 999.\n",
    "        patient = 5\n",
    "        for i in range(1):\n",
    "            policy.train(replay_buffer, args_batch_size)\n",
    "                \n",
    "\n",
    "    # Train agent after collecting sufficient data\n",
    "    if done: \n",
    "        print(f\"Total T: {t+1} Episode Num: {episode_num+1} Episode T: {episode_timesteps} Reward: {episode_reward:.3f}\")\n",
    "        msk_list = []\n",
    "        state, done = env.reset(), False\n",
    "        episode_reward = 0\n",
    "        episode_timesteps = 0\n",
    "        episode_num += 1 \n",
    "\n",
    "    # Evaluate episode\n",
    "    if (t + 1) % args_eval_freq == 0:\n",
    "        evaluations.append(eval_policy(policy))\n",
    "        print('recent Evaluation:',evaluations[-1])\n",
    "        np.save('results/evaluations_alias{}_ENV{}'.format(alias,ENV_NAME),evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YAVa6S3yG5m5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 200 Episode Num: 1 Episode T: 200 Reward: -1709.434\n",
      "Total T: 400 Episode Num: 2 Episode T: 200 Reward: -1568.199\n",
      "Total T: 600 Episode Num: 3 Episode T: 200 Reward: -1859.794\n",
      "Total T: 800 Episode Num: 4 Episode T: 200 Reward: -1642.587\n",
      "Total T: 1000 Episode Num: 5 Episode T: 200 Reward: -1596.824\n",
      "recent Evaluation: -1566.1190627581523\n",
      "Total T: 1200 Episode Num: 6 Episode T: 200 Reward: -1627.729\n",
      "Total T: 1400 Episode Num: 7 Episode T: 200 Reward: -1569.497\n",
      "Total T: 1600 Episode Num: 8 Episode T: 200 Reward: -1566.147\n",
      "Total T: 1800 Episode Num: 9 Episode T: 200 Reward: -1573.210\n",
      "Total T: 2000 Episode Num: 10 Episode T: 200 Reward: -1492.774\n",
      "recent Evaluation: -1517.972113374537\n",
      "Total T: 2200 Episode Num: 11 Episode T: 200 Reward: -1574.505\n",
      "Total T: 2400 Episode Num: 12 Episode T: 200 Reward: -1523.338\n",
      "Total T: 2600 Episode Num: 13 Episode T: 200 Reward: -1490.993\n",
      "Total T: 2800 Episode Num: 14 Episode T: 200 Reward: -1588.118\n",
      "Total T: 3000 Episode Num: 15 Episode T: 200 Reward: -1505.673\n",
      "recent Evaluation: -1483.4670820194267\n",
      "Total T: 3200 Episode Num: 16 Episode T: 200 Reward: -1452.117\n",
      "Total T: 3400 Episode Num: 17 Episode T: 200 Reward: -1426.638\n",
      "Total T: 3600 Episode Num: 18 Episode T: 200 Reward: -1333.666\n",
      "Total T: 3800 Episode Num: 19 Episode T: 200 Reward: -1360.178\n",
      "Total T: 4000 Episode Num: 20 Episode T: 200 Reward: -1333.804\n",
      "recent Evaluation: -1401.4553938316433\n",
      "Total T: 4200 Episode Num: 21 Episode T: 200 Reward: -1086.860\n",
      "Total T: 4400 Episode Num: 22 Episode T: 200 Reward: -1282.073\n",
      "Total T: 4600 Episode Num: 23 Episode T: 200 Reward: -1306.731\n",
      "Total T: 4800 Episode Num: 24 Episode T: 200 Reward: -1224.274\n",
      "Total T: 5000 Episode Num: 25 Episode T: 200 Reward: -1189.264\n",
      "recent Evaluation: -1262.6197325946873\n",
      "Total T: 5200 Episode Num: 26 Episode T: 200 Reward: -1191.012\n",
      "Total T: 5400 Episode Num: 27 Episode T: 200 Reward: -1138.113\n",
      "Total T: 5600 Episode Num: 28 Episode T: 200 Reward: -1131.499\n",
      "Total T: 5800 Episode Num: 29 Episode T: 200 Reward: -1149.697\n",
      "Total T: 6000 Episode Num: 30 Episode T: 200 Reward: -1353.746\n",
      "recent Evaluation: -930.9917222063947\n",
      "Total T: 6200 Episode Num: 31 Episode T: 200 Reward: -1014.507\n",
      "Total T: 6400 Episode Num: 32 Episode T: 200 Reward: -1028.303\n",
      "Total T: 6600 Episode Num: 33 Episode T: 200 Reward: -899.339\n",
      "Total T: 6800 Episode Num: 34 Episode T: 200 Reward: -1038.020\n",
      "Total T: 7000 Episode Num: 35 Episode T: 200 Reward: -892.992\n",
      "recent Evaluation: -999.4240870922124\n",
      "Total T: 7200 Episode Num: 36 Episode T: 200 Reward: -889.003\n",
      "Total T: 7400 Episode Num: 37 Episode T: 200 Reward: -907.271\n",
      "Total T: 7600 Episode Num: 38 Episode T: 200 Reward: -1212.124\n",
      "Total T: 7800 Episode Num: 39 Episode T: 200 Reward: -1302.092\n",
      "Total T: 8000 Episode Num: 40 Episode T: 200 Reward: -1067.360\n",
      "recent Evaluation: -1296.7562275074308\n",
      "Total T: 8200 Episode Num: 41 Episode T: 200 Reward: -1232.940\n",
      "Total T: 8400 Episode Num: 42 Episode T: 200 Reward: -1310.012\n",
      "Total T: 8600 Episode Num: 43 Episode T: 200 Reward: -1214.736\n",
      "Total T: 8800 Episode Num: 44 Episode T: 200 Reward: -1068.107\n",
      "Total T: 9000 Episode Num: 45 Episode T: 200 Reward: -1324.085\n",
      "recent Evaluation: -1274.9102420777656\n",
      "Total T: 9200 Episode Num: 46 Episode T: 200 Reward: -1355.575\n",
      "Total T: 9400 Episode Num: 47 Episode T: 200 Reward: -1233.286\n",
      "Total T: 9600 Episode Num: 48 Episode T: 200 Reward: -905.439\n",
      "Total T: 9800 Episode Num: 49 Episode T: 200 Reward: -887.077\n",
      "Total T: 10000 Episode Num: 50 Episode T: 200 Reward: -912.509\n",
      "recent Evaluation: -689.1085256061809\n",
      "Total T: 10200 Episode Num: 51 Episode T: 200 Reward: -796.510\n",
      "Total T: 10400 Episode Num: 52 Episode T: 200 Reward: -651.012\n",
      "Total T: 10600 Episode Num: 53 Episode T: 200 Reward: -644.394\n",
      "Total T: 10800 Episode Num: 54 Episode T: 200 Reward: -610.112\n",
      "Total T: 11000 Episode Num: 55 Episode T: 200 Reward: -520.559\n",
      "recent Evaluation: -356.5123292172772\n",
      "Total T: 11200 Episode Num: 56 Episode T: 200 Reward: -263.587\n",
      "Total T: 11400 Episode Num: 57 Episode T: 200 Reward: -7.845\n",
      "Total T: 11600 Episode Num: 58 Episode T: 200 Reward: -252.943\n",
      "Total T: 11800 Episode Num: 59 Episode T: 200 Reward: -252.323\n",
      "Total T: 12000 Episode Num: 60 Episode T: 200 Reward: -126.938\n",
      "recent Evaluation: -195.6787536403598\n",
      "Total T: 12200 Episode Num: 61 Episode T: 200 Reward: -126.502\n",
      "Total T: 12400 Episode Num: 62 Episode T: 200 Reward: -377.844\n",
      "Total T: 12600 Episode Num: 63 Episode T: 200 Reward: -126.499\n",
      "Total T: 12800 Episode Num: 64 Episode T: 200 Reward: -130.186\n",
      "Total T: 13000 Episode Num: 65 Episode T: 200 Reward: -265.276\n",
      "recent Evaluation: -233.5985243924455\n",
      "Total T: 13200 Episode Num: 66 Episode T: 200 Reward: -440.521\n",
      "Total T: 13400 Episode Num: 67 Episode T: 200 Reward: -128.158\n",
      "Total T: 13600 Episode Num: 68 Episode T: 200 Reward: -249.684\n",
      "Total T: 13800 Episode Num: 69 Episode T: 200 Reward: -1.502\n",
      "Total T: 14000 Episode Num: 70 Episode T: 200 Reward: -249.048\n",
      "recent Evaluation: -196.01268354299083\n",
      "Total T: 14200 Episode Num: 71 Episode T: 200 Reward: -122.642\n",
      "Total T: 14400 Episode Num: 72 Episode T: 200 Reward: -124.604\n",
      "Total T: 14600 Episode Num: 73 Episode T: 200 Reward: -130.202\n",
      "Total T: 14800 Episode Num: 74 Episode T: 200 Reward: -128.873\n",
      "Total T: 15000 Episode Num: 75 Episode T: 200 Reward: -1.547\n",
      "recent Evaluation: -204.73895842955682\n",
      "Total T: 15200 Episode Num: 76 Episode T: 200 Reward: -128.687\n",
      "Total T: 15400 Episode Num: 77 Episode T: 200 Reward: -125.405\n",
      "Total T: 15600 Episode Num: 78 Episode T: 200 Reward: -127.589\n",
      "Total T: 15800 Episode Num: 79 Episode T: 200 Reward: -117.764\n",
      "Total T: 16000 Episode Num: 80 Episode T: 200 Reward: -125.492\n",
      "recent Evaluation: -232.66723233132757\n",
      "Total T: 16200 Episode Num: 81 Episode T: 200 Reward: -123.059\n",
      "Total T: 16400 Episode Num: 82 Episode T: 200 Reward: -127.466\n",
      "Total T: 16600 Episode Num: 83 Episode T: 200 Reward: -124.097\n",
      "Total T: 16800 Episode Num: 84 Episode T: 200 Reward: -127.648\n",
      "Total T: 17000 Episode Num: 85 Episode T: 200 Reward: -250.053\n",
      "recent Evaluation: -167.87919263718112\n",
      "Total T: 17200 Episode Num: 86 Episode T: 200 Reward: -382.944\n",
      "Total T: 17400 Episode Num: 87 Episode T: 200 Reward: -121.641\n",
      "Total T: 17600 Episode Num: 88 Episode T: 200 Reward: -386.095\n",
      "Total T: 17800 Episode Num: 89 Episode T: 200 Reward: -127.349\n",
      "Total T: 18000 Episode Num: 90 Episode T: 200 Reward: -123.549\n",
      "recent Evaluation: -149.75261174054054\n",
      "Total T: 18200 Episode Num: 91 Episode T: 200 Reward: -255.051\n",
      "Total T: 18400 Episode Num: 92 Episode T: 200 Reward: -241.397\n",
      "Total T: 18600 Episode Num: 93 Episode T: 200 Reward: -239.038\n",
      "Total T: 18800 Episode Num: 94 Episode T: 200 Reward: -126.034\n",
      "Total T: 19000 Episode Num: 95 Episode T: 200 Reward: -264.364\n",
      "recent Evaluation: -154.7994616558761\n",
      "Total T: 19200 Episode Num: 96 Episode T: 200 Reward: -124.873\n",
      "Total T: 19400 Episode Num: 97 Episode T: 200 Reward: -124.501\n",
      "Total T: 19600 Episode Num: 98 Episode T: 200 Reward: -125.673\n",
      "Total T: 19800 Episode Num: 99 Episode T: 200 Reward: -257.588\n",
      "Total T: 20000 Episode Num: 100 Episode T: 200 Reward: -250.666\n",
      "recent Evaluation: -148.39210873622136\n",
      "Total T: 20200 Episode Num: 101 Episode T: 200 Reward: -251.451\n",
      "Total T: 20400 Episode Num: 102 Episode T: 200 Reward: -125.750\n",
      "Total T: 20600 Episode Num: 103 Episode T: 200 Reward: -345.622\n",
      "Total T: 20800 Episode Num: 104 Episode T: 200 Reward: -129.436\n",
      "Total T: 21000 Episode Num: 105 Episode T: 200 Reward: -118.370\n",
      "recent Evaluation: -121.51647031868193\n",
      "Total T: 21200 Episode Num: 106 Episode T: 200 Reward: -119.119\n",
      "Total T: 21400 Episode Num: 107 Episode T: 200 Reward: -239.312\n",
      "Total T: 21600 Episode Num: 108 Episode T: 200 Reward: -356.196\n",
      "Total T: 21800 Episode Num: 109 Episode T: 200 Reward: -123.379\n",
      "Total T: 22000 Episode Num: 110 Episode T: 200 Reward: -121.327\n",
      "recent Evaluation: -281.9019629274102\n",
      "Total T: 22200 Episode Num: 111 Episode T: 200 Reward: -117.547\n",
      "Total T: 22400 Episode Num: 112 Episode T: 200 Reward: -330.737\n",
      "Total T: 22600 Episode Num: 113 Episode T: 200 Reward: -127.259\n",
      "Total T: 22800 Episode Num: 114 Episode T: 200 Reward: -124.454\n",
      "Total T: 23000 Episode Num: 115 Episode T: 200 Reward: -124.272\n",
      "recent Evaluation: -160.87273888298813\n",
      "Total T: 23200 Episode Num: 116 Episode T: 200 Reward: -234.609\n",
      "Total T: 23400 Episode Num: 117 Episode T: 200 Reward: -116.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 23600 Episode Num: 118 Episode T: 200 Reward: -295.085\n",
      "Total T: 23800 Episode Num: 119 Episode T: 200 Reward: -131.911\n",
      "Total T: 24000 Episode Num: 120 Episode T: 200 Reward: -240.112\n",
      "recent Evaluation: -174.03324684921353\n",
      "Total T: 24200 Episode Num: 121 Episode T: 200 Reward: -242.043\n",
      "Total T: 24400 Episode Num: 122 Episode T: 200 Reward: -237.833\n",
      "Total T: 24600 Episode Num: 123 Episode T: 200 Reward: -121.854\n",
      "Total T: 24800 Episode Num: 124 Episode T: 200 Reward: -125.624\n",
      "Total T: 25000 Episode Num: 125 Episode T: 200 Reward: -248.167\n",
      "recent Evaluation: -135.24254156009633\n",
      "Total T: 25200 Episode Num: 126 Episode T: 200 Reward: -125.137\n",
      "Total T: 25400 Episode Num: 127 Episode T: 200 Reward: -239.290\n",
      "Total T: 25600 Episode Num: 128 Episode T: 200 Reward: -381.210\n",
      "Total T: 25800 Episode Num: 129 Episode T: 200 Reward: -336.050\n",
      "Total T: 26000 Episode Num: 130 Episode T: 200 Reward: -116.403\n",
      "recent Evaluation: -236.605104686792\n",
      "Total T: 26200 Episode Num: 131 Episode T: 200 Reward: -0.689\n",
      "Total T: 26400 Episode Num: 132 Episode T: 200 Reward: -242.679\n",
      "Total T: 26600 Episode Num: 133 Episode T: 200 Reward: -253.383\n",
      "Total T: 26800 Episode Num: 134 Episode T: 200 Reward: -128.215\n",
      "Total T: 27000 Episode Num: 135 Episode T: 200 Reward: -233.041\n",
      "recent Evaluation: -148.01662583396063\n",
      "Total T: 27200 Episode Num: 136 Episode T: 200 Reward: -122.372\n",
      "Total T: 27400 Episode Num: 137 Episode T: 200 Reward: -246.487\n",
      "Total T: 27600 Episode Num: 138 Episode T: 200 Reward: -122.732\n",
      "Total T: 27800 Episode Num: 139 Episode T: 200 Reward: -237.877\n",
      "Total T: 28000 Episode Num: 140 Episode T: 200 Reward: -123.437\n",
      "recent Evaluation: -331.03499462413134\n",
      "Total T: 28200 Episode Num: 141 Episode T: 200 Reward: -116.446\n",
      "Total T: 28400 Episode Num: 142 Episode T: 200 Reward: -239.725\n",
      "Total T: 28600 Episode Num: 143 Episode T: 200 Reward: -122.128\n",
      "Total T: 28800 Episode Num: 144 Episode T: 200 Reward: -123.729\n",
      "Total T: 29000 Episode Num: 145 Episode T: 200 Reward: -0.644\n",
      "recent Evaluation: -307.14446938456933\n",
      "Total T: 29200 Episode Num: 146 Episode T: 200 Reward: -240.497\n",
      "Total T: 29400 Episode Num: 147 Episode T: 200 Reward: -118.878\n",
      "Total T: 29600 Episode Num: 148 Episode T: 200 Reward: -238.748\n",
      "Total T: 29800 Episode Num: 149 Episode T: 200 Reward: -353.702\n",
      "Total T: 30000 Episode Num: 150 Episode T: 200 Reward: -120.540\n",
      "recent Evaluation: -356.83614869139444\n",
      "Total T: 30200 Episode Num: 151 Episode T: 200 Reward: -121.696\n",
      "Total T: 30400 Episode Num: 152 Episode T: 200 Reward: -118.407\n",
      "Total T: 30600 Episode Num: 153 Episode T: 200 Reward: -900.169\n",
      "Total T: 30800 Episode Num: 154 Episode T: 200 Reward: -2.328\n",
      "Total T: 31000 Episode Num: 155 Episode T: 200 Reward: -114.627\n",
      "recent Evaluation: -442.38141783061917\n",
      "Total T: 31200 Episode Num: 156 Episode T: 200 Reward: -120.490\n",
      "Total T: 31400 Episode Num: 157 Episode T: 200 Reward: -245.583\n",
      "Total T: 31600 Episode Num: 158 Episode T: 200 Reward: -234.406\n",
      "Total T: 31800 Episode Num: 159 Episode T: 200 Reward: -118.740\n",
      "Total T: 32000 Episode Num: 160 Episode T: 200 Reward: -120.666\n",
      "recent Evaluation: -321.66860407437514\n",
      "Total T: 32200 Episode Num: 161 Episode T: 200 Reward: -122.521\n",
      "Total T: 32400 Episode Num: 162 Episode T: 200 Reward: -126.488\n",
      "Total T: 32600 Episode Num: 163 Episode T: 200 Reward: -123.096\n",
      "Total T: 32800 Episode Num: 164 Episode T: 200 Reward: -124.141\n",
      "Total T: 33000 Episode Num: 165 Episode T: 200 Reward: -125.800\n",
      "recent Evaluation: -288.11069862334006\n",
      "Total T: 33200 Episode Num: 166 Episode T: 200 Reward: -118.972\n",
      "Total T: 33400 Episode Num: 167 Episode T: 200 Reward: -1.627\n",
      "Total T: 33600 Episode Num: 168 Episode T: 200 Reward: -1047.516\n",
      "Total T: 33800 Episode Num: 169 Episode T: 200 Reward: -119.504\n",
      "Total T: 34000 Episode Num: 170 Episode T: 200 Reward: -332.578\n",
      "recent Evaluation: -218.51105703030566\n",
      "Total T: 34200 Episode Num: 171 Episode T: 200 Reward: -2.309\n",
      "Total T: 34400 Episode Num: 172 Episode T: 200 Reward: -124.253\n",
      "Total T: 34600 Episode Num: 173 Episode T: 200 Reward: -977.580\n",
      "Total T: 34800 Episode Num: 174 Episode T: 200 Reward: -255.004\n",
      "Total T: 35000 Episode Num: 175 Episode T: 200 Reward: -117.367\n",
      "recent Evaluation: -282.4100643116618\n",
      "Total T: 35200 Episode Num: 176 Episode T: 200 Reward: -249.227\n",
      "Total T: 35400 Episode Num: 177 Episode T: 200 Reward: -125.096\n",
      "Total T: 35600 Episode Num: 178 Episode T: 200 Reward: -352.658\n",
      "Total T: 35800 Episode Num: 179 Episode T: 200 Reward: -126.677\n",
      "Total T: 36000 Episode Num: 180 Episode T: 200 Reward: -119.853\n",
      "recent Evaluation: -135.2301693578515\n",
      "Total T: 36200 Episode Num: 181 Episode T: 200 Reward: -372.167\n",
      "Total T: 36400 Episode Num: 182 Episode T: 200 Reward: -386.780\n",
      "Total T: 36600 Episode Num: 183 Episode T: 200 Reward: -124.334\n",
      "Total T: 36800 Episode Num: 184 Episode T: 200 Reward: -2.275\n",
      "Total T: 37000 Episode Num: 185 Episode T: 200 Reward: -369.467\n",
      "recent Evaluation: -121.65953157287977\n",
      "Total T: 37200 Episode Num: 186 Episode T: 200 Reward: -123.470\n",
      "Total T: 37400 Episode Num: 187 Episode T: 200 Reward: -235.588\n",
      "Total T: 37600 Episode Num: 188 Episode T: 200 Reward: -242.265\n",
      "Total T: 37800 Episode Num: 189 Episode T: 200 Reward: -244.687\n",
      "Total T: 38000 Episode Num: 190 Episode T: 200 Reward: -126.818\n",
      "recent Evaluation: -147.40380204424147\n",
      "Total T: 38200 Episode Num: 191 Episode T: 200 Reward: -237.683\n",
      "Total T: 38400 Episode Num: 192 Episode T: 200 Reward: -125.389\n",
      "Total T: 38600 Episode Num: 193 Episode T: 200 Reward: -245.611\n",
      "Total T: 38800 Episode Num: 194 Episode T: 200 Reward: -123.515\n",
      "Total T: 39000 Episode Num: 195 Episode T: 200 Reward: -115.221\n",
      "recent Evaluation: -110.17515836512646\n",
      "Total T: 39200 Episode Num: 196 Episode T: 200 Reward: -125.531\n",
      "Total T: 39400 Episode Num: 197 Episode T: 200 Reward: -236.706\n",
      "Total T: 39600 Episode Num: 198 Episode T: 200 Reward: -125.499\n",
      "Total T: 39800 Episode Num: 199 Episode T: 200 Reward: -243.209\n",
      "Total T: 40000 Episode Num: 200 Episode T: 200 Reward: -123.204\n",
      "recent Evaluation: -206.98187343597215\n",
      "Total T: 40200 Episode Num: 201 Episode T: 200 Reward: -124.543\n",
      "Total T: 40400 Episode Num: 202 Episode T: 200 Reward: -124.440\n",
      "Total T: 40600 Episode Num: 203 Episode T: 200 Reward: -303.016\n",
      "Total T: 40800 Episode Num: 204 Episode T: 200 Reward: -125.632\n",
      "Total T: 41000 Episode Num: 205 Episode T: 200 Reward: -248.351\n",
      "recent Evaluation: -162.49801196402706\n",
      "Total T: 41200 Episode Num: 206 Episode T: 200 Reward: -118.402\n",
      "Total T: 41400 Episode Num: 207 Episode T: 200 Reward: -128.106\n",
      "Total T: 41600 Episode Num: 208 Episode T: 200 Reward: -128.881\n",
      "Total T: 41800 Episode Num: 209 Episode T: 200 Reward: -120.580\n",
      "Total T: 42000 Episode Num: 210 Episode T: 200 Reward: -2.658\n",
      "recent Evaluation: -122.47467283802155\n",
      "Total T: 42200 Episode Num: 211 Episode T: 200 Reward: -303.902\n",
      "Total T: 42400 Episode Num: 212 Episode T: 200 Reward: -118.954\n",
      "Total T: 42600 Episode Num: 213 Episode T: 200 Reward: -123.307\n",
      "Total T: 42800 Episode Num: 214 Episode T: 200 Reward: -236.993\n",
      "Total T: 43000 Episode Num: 215 Episode T: 200 Reward: -234.589\n",
      "recent Evaluation: -153.9839580842568\n",
      "Total T: 43200 Episode Num: 216 Episode T: 200 Reward: -126.098\n",
      "Total T: 43400 Episode Num: 217 Episode T: 200 Reward: -242.097\n",
      "Total T: 43600 Episode Num: 218 Episode T: 200 Reward: -117.396\n",
      "Total T: 43800 Episode Num: 219 Episode T: 200 Reward: -365.877\n",
      "Total T: 44000 Episode Num: 220 Episode T: 200 Reward: -2.231\n",
      "recent Evaluation: -143.88374823491662\n",
      "Total T: 44200 Episode Num: 221 Episode T: 200 Reward: -119.548\n",
      "Total T: 44400 Episode Num: 222 Episode T: 200 Reward: -118.593\n",
      "Total T: 44600 Episode Num: 223 Episode T: 200 Reward: -353.172\n",
      "Total T: 44800 Episode Num: 224 Episode T: 200 Reward: -125.781\n",
      "Total T: 45000 Episode Num: 225 Episode T: 200 Reward: -2.212\n",
      "recent Evaluation: -182.74171338676987\n",
      "Total T: 45200 Episode Num: 226 Episode T: 200 Reward: -227.430\n",
      "Total T: 45400 Episode Num: 227 Episode T: 200 Reward: -1.616\n",
      "Total T: 45600 Episode Num: 228 Episode T: 200 Reward: -126.455\n",
      "Total T: 45800 Episode Num: 229 Episode T: 200 Reward: -253.216\n",
      "Total T: 46000 Episode Num: 230 Episode T: 200 Reward: -125.043\n",
      "recent Evaluation: -130.13170851725005\n",
      "Total T: 46200 Episode Num: 231 Episode T: 200 Reward: -243.421\n",
      "Total T: 46400 Episode Num: 232 Episode T: 200 Reward: -123.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 46600 Episode Num: 233 Episode T: 200 Reward: -346.501\n",
      "Total T: 46800 Episode Num: 234 Episode T: 200 Reward: -123.933\n",
      "Total T: 47000 Episode Num: 235 Episode T: 200 Reward: -117.628\n",
      "recent Evaluation: -139.5160346679107\n",
      "Total T: 47200 Episode Num: 236 Episode T: 200 Reward: -232.636\n",
      "Total T: 47400 Episode Num: 237 Episode T: 200 Reward: -325.807\n",
      "Total T: 47600 Episode Num: 238 Episode T: 200 Reward: -126.882\n",
      "Total T: 47800 Episode Num: 239 Episode T: 200 Reward: -124.596\n",
      "Total T: 48000 Episode Num: 240 Episode T: 200 Reward: -122.763\n",
      "recent Evaluation: -144.42429810293171\n",
      "Total T: 48200 Episode Num: 241 Episode T: 200 Reward: -126.474\n",
      "Total T: 48400 Episode Num: 242 Episode T: 200 Reward: -239.369\n",
      "Total T: 48600 Episode Num: 243 Episode T: 200 Reward: -254.753\n",
      "Total T: 48800 Episode Num: 244 Episode T: 200 Reward: -122.904\n",
      "Total T: 49000 Episode Num: 245 Episode T: 200 Reward: -117.721\n",
      "recent Evaluation: -122.38484065102462\n",
      "Total T: 49200 Episode Num: 246 Episode T: 200 Reward: -126.452\n",
      "Total T: 49400 Episode Num: 247 Episode T: 200 Reward: -242.730\n",
      "Total T: 49600 Episode Num: 248 Episode T: 200 Reward: -248.675\n",
      "Total T: 49800 Episode Num: 249 Episode T: 200 Reward: -1.450\n",
      "Total T: 50000 Episode Num: 250 Episode T: 200 Reward: -123.928\n",
      "recent Evaluation: -130.21964099343762\n",
      "Total T: 50200 Episode Num: 251 Episode T: 200 Reward: -1.407\n",
      "Total T: 50400 Episode Num: 252 Episode T: 200 Reward: -122.315\n",
      "Total T: 50600 Episode Num: 253 Episode T: 200 Reward: -115.866\n",
      "Total T: 50800 Episode Num: 254 Episode T: 200 Reward: -120.752\n",
      "Total T: 51000 Episode Num: 255 Episode T: 200 Reward: -124.970\n",
      "recent Evaluation: -185.69948531603907\n",
      "Total T: 51200 Episode Num: 256 Episode T: 200 Reward: -121.448\n",
      "Total T: 51400 Episode Num: 257 Episode T: 200 Reward: -239.771\n",
      "Total T: 51600 Episode Num: 258 Episode T: 200 Reward: -127.306\n",
      "Total T: 51800 Episode Num: 259 Episode T: 200 Reward: -4.659\n",
      "Total T: 52000 Episode Num: 260 Episode T: 200 Reward: -121.980\n",
      "recent Evaluation: -159.92109557904\n",
      "Total T: 52200 Episode Num: 261 Episode T: 200 Reward: -244.655\n",
      "Total T: 52400 Episode Num: 262 Episode T: 200 Reward: -128.289\n",
      "Total T: 52600 Episode Num: 263 Episode T: 200 Reward: -129.676\n",
      "Total T: 52800 Episode Num: 264 Episode T: 200 Reward: -355.213\n",
      "Total T: 53000 Episode Num: 265 Episode T: 200 Reward: -251.205\n",
      "recent Evaluation: -158.39600952127265\n",
      "Total T: 53200 Episode Num: 266 Episode T: 200 Reward: -245.651\n",
      "Total T: 53400 Episode Num: 267 Episode T: 200 Reward: -6.716\n",
      "Total T: 53600 Episode Num: 268 Episode T: 200 Reward: -130.721\n",
      "Total T: 53800 Episode Num: 269 Episode T: 200 Reward: -239.744\n",
      "Total T: 54000 Episode Num: 270 Episode T: 200 Reward: -371.024\n",
      "recent Evaluation: -167.1465195011706\n",
      "Total T: 54200 Episode Num: 271 Episode T: 200 Reward: -360.615\n",
      "Total T: 54400 Episode Num: 272 Episode T: 200 Reward: -129.403\n",
      "Total T: 54600 Episode Num: 273 Episode T: 200 Reward: -478.891\n",
      "Total T: 54800 Episode Num: 274 Episode T: 200 Reward: -254.551\n",
      "Total T: 55000 Episode Num: 275 Episode T: 200 Reward: -129.277\n",
      "recent Evaluation: -149.1403504724937\n",
      "Total T: 55200 Episode Num: 276 Episode T: 200 Reward: -240.230\n",
      "Total T: 55400 Episode Num: 277 Episode T: 200 Reward: -247.635\n",
      "Total T: 55600 Episode Num: 278 Episode T: 200 Reward: -127.767\n",
      "Total T: 55800 Episode Num: 279 Episode T: 200 Reward: -486.219\n",
      "Total T: 56000 Episode Num: 280 Episode T: 200 Reward: -332.556\n",
      "recent Evaluation: -123.29298578602531\n",
      "Total T: 56200 Episode Num: 281 Episode T: 200 Reward: -249.681\n",
      "Total T: 56400 Episode Num: 282 Episode T: 200 Reward: -357.735\n",
      "Total T: 56600 Episode Num: 283 Episode T: 200 Reward: -333.147\n",
      "Total T: 56800 Episode Num: 284 Episode T: 200 Reward: -245.801\n",
      "Total T: 57000 Episode Num: 285 Episode T: 200 Reward: -160.523\n",
      "recent Evaluation: -152.86742595269016\n",
      "Total T: 57200 Episode Num: 286 Episode T: 200 Reward: -290.467\n",
      "Total T: 57400 Episode Num: 287 Episode T: 200 Reward: -597.837\n",
      "Total T: 57600 Episode Num: 288 Episode T: 200 Reward: -133.583\n",
      "Total T: 57800 Episode Num: 289 Episode T: 200 Reward: -8.809\n",
      "Total T: 58000 Episode Num: 290 Episode T: 200 Reward: -340.200\n",
      "recent Evaluation: -185.11622755197172\n",
      "Total T: 58200 Episode Num: 291 Episode T: 200 Reward: -132.968\n",
      "Total T: 58400 Episode Num: 292 Episode T: 200 Reward: -562.504\n",
      "Total T: 58600 Episode Num: 293 Episode T: 200 Reward: -246.348\n",
      "Total T: 58800 Episode Num: 294 Episode T: 200 Reward: -602.076\n",
      "Total T: 59000 Episode Num: 295 Episode T: 200 Reward: -127.479\n",
      "recent Evaluation: -140.2864460107951\n",
      "Total T: 59200 Episode Num: 296 Episode T: 200 Reward: -351.052\n",
      "Total T: 59400 Episode Num: 297 Episode T: 200 Reward: -252.928\n",
      "Total T: 59600 Episode Num: 298 Episode T: 200 Reward: -357.075\n",
      "Total T: 59800 Episode Num: 299 Episode T: 200 Reward: -245.297\n",
      "Total T: 60000 Episode Num: 300 Episode T: 200 Reward: -300.811\n",
      "recent Evaluation: -198.241822111099\n",
      "Total T: 60200 Episode Num: 301 Episode T: 200 Reward: -468.072\n",
      "Total T: 60400 Episode Num: 302 Episode T: 200 Reward: -128.984\n",
      "Total T: 60600 Episode Num: 303 Episode T: 200 Reward: -136.062\n",
      "Total T: 60800 Episode Num: 304 Episode T: 200 Reward: -254.925\n",
      "Total T: 61000 Episode Num: 305 Episode T: 200 Reward: -125.179\n",
      "recent Evaluation: -161.96321022051131\n",
      "Total T: 61200 Episode Num: 306 Episode T: 200 Reward: -253.645\n",
      "Total T: 61400 Episode Num: 307 Episode T: 200 Reward: -368.815\n",
      "Total T: 61600 Episode Num: 308 Episode T: 200 Reward: -371.847\n",
      "Total T: 61800 Episode Num: 309 Episode T: 200 Reward: -129.216\n",
      "Total T: 62000 Episode Num: 310 Episode T: 200 Reward: -244.389\n",
      "recent Evaluation: -146.48387827376\n",
      "Total T: 62200 Episode Num: 311 Episode T: 200 Reward: -248.890\n",
      "Total T: 62400 Episode Num: 312 Episode T: 200 Reward: -242.355\n",
      "Total T: 62600 Episode Num: 313 Episode T: 200 Reward: -130.451\n",
      "Total T: 62800 Episode Num: 314 Episode T: 200 Reward: -370.837\n",
      "Total T: 63000 Episode Num: 315 Episode T: 200 Reward: -340.341\n",
      "recent Evaluation: -162.57245855076275\n",
      "Total T: 63200 Episode Num: 316 Episode T: 200 Reward: -248.545\n",
      "Total T: 63400 Episode Num: 317 Episode T: 200 Reward: -246.883\n",
      "Total T: 63600 Episode Num: 318 Episode T: 200 Reward: -345.287\n",
      "Total T: 63800 Episode Num: 319 Episode T: 200 Reward: -254.103\n",
      "Total T: 64000 Episode Num: 320 Episode T: 200 Reward: -124.510\n",
      "recent Evaluation: -137.2054127236683\n",
      "Total T: 64200 Episode Num: 321 Episode T: 200 Reward: -473.127\n",
      "Total T: 64400 Episode Num: 322 Episode T: 200 Reward: -257.502\n",
      "Total T: 64600 Episode Num: 323 Episode T: 200 Reward: -362.477\n",
      "Total T: 64800 Episode Num: 324 Episode T: 200 Reward: -605.359\n",
      "Total T: 65000 Episode Num: 325 Episode T: 200 Reward: -357.880\n",
      "recent Evaluation: -115.95451690046369\n",
      "Total T: 65200 Episode Num: 326 Episode T: 200 Reward: -252.818\n",
      "Total T: 65400 Episode Num: 327 Episode T: 200 Reward: -280.439\n",
      "Total T: 65600 Episode Num: 328 Episode T: 200 Reward: -253.221\n",
      "Total T: 65800 Episode Num: 329 Episode T: 200 Reward: -255.450\n",
      "Total T: 66000 Episode Num: 330 Episode T: 200 Reward: -494.636\n",
      "recent Evaluation: -147.47073531720662\n",
      "Total T: 66200 Episode Num: 331 Episode T: 200 Reward: -375.016\n",
      "Total T: 66400 Episode Num: 332 Episode T: 200 Reward: -363.077\n",
      "Total T: 66600 Episode Num: 333 Episode T: 200 Reward: -254.698\n",
      "Total T: 66800 Episode Num: 334 Episode T: 200 Reward: -134.286\n",
      "Total T: 67000 Episode Num: 335 Episode T: 200 Reward: -133.603\n",
      "recent Evaluation: -139.05111087959008\n",
      "Total T: 67200 Episode Num: 336 Episode T: 200 Reward: -128.279\n",
      "Total T: 67400 Episode Num: 337 Episode T: 200 Reward: -487.665\n",
      "Total T: 67600 Episode Num: 338 Episode T: 200 Reward: -132.768\n",
      "Total T: 67800 Episode Num: 339 Episode T: 200 Reward: -377.707\n",
      "Total T: 68000 Episode Num: 340 Episode T: 200 Reward: -252.314\n",
      "recent Evaluation: -106.68021464628524\n",
      "Total T: 68200 Episode Num: 341 Episode T: 200 Reward: -251.344\n",
      "Total T: 68400 Episode Num: 342 Episode T: 200 Reward: -600.035\n",
      "Total T: 68600 Episode Num: 343 Episode T: 200 Reward: -250.380\n",
      "Total T: 68800 Episode Num: 344 Episode T: 200 Reward: -252.828\n",
      "Total T: 69000 Episode Num: 345 Episode T: 200 Reward: -252.631\n",
      "recent Evaluation: -136.208632537671\n",
      "Total T: 69200 Episode Num: 346 Episode T: 200 Reward: -128.020\n",
      "Total T: 69400 Episode Num: 347 Episode T: 200 Reward: -251.609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 69600 Episode Num: 348 Episode T: 200 Reward: -366.631\n",
      "Total T: 69800 Episode Num: 349 Episode T: 200 Reward: -128.092\n",
      "Total T: 70000 Episode Num: 350 Episode T: 200 Reward: -365.356\n",
      "recent Evaluation: -144.51541585663344\n",
      "Total T: 70200 Episode Num: 351 Episode T: 200 Reward: -312.716\n",
      "Total T: 70400 Episode Num: 352 Episode T: 200 Reward: -374.670\n",
      "Total T: 70600 Episode Num: 353 Episode T: 200 Reward: -255.120\n",
      "Total T: 70800 Episode Num: 354 Episode T: 200 Reward: -250.537\n",
      "Total T: 71000 Episode Num: 355 Episode T: 200 Reward: -460.551\n",
      "recent Evaluation: -165.2466702194833\n",
      "Total T: 71200 Episode Num: 356 Episode T: 200 Reward: -128.844\n",
      "Total T: 71400 Episode Num: 357 Episode T: 200 Reward: -134.411\n",
      "Total T: 71600 Episode Num: 358 Episode T: 200 Reward: -433.346\n",
      "Total T: 71800 Episode Num: 359 Episode T: 200 Reward: -366.388\n",
      "Total T: 72000 Episode Num: 360 Episode T: 200 Reward: -128.509\n",
      "recent Evaluation: -185.1249555164034\n",
      "Total T: 72200 Episode Num: 361 Episode T: 200 Reward: -248.270\n",
      "Total T: 72400 Episode Num: 362 Episode T: 200 Reward: -373.260\n",
      "Total T: 72600 Episode Num: 363 Episode T: 200 Reward: -361.967\n",
      "Total T: 72800 Episode Num: 364 Episode T: 200 Reward: -129.643\n",
      "Total T: 73000 Episode Num: 365 Episode T: 200 Reward: -253.505\n",
      "recent Evaluation: -150.68526275962913\n",
      "Total T: 73200 Episode Num: 366 Episode T: 200 Reward: -135.157\n",
      "Total T: 73400 Episode Num: 367 Episode T: 200 Reward: -132.260\n",
      "Total T: 73600 Episode Num: 368 Episode T: 200 Reward: -241.552\n",
      "Total T: 73800 Episode Num: 369 Episode T: 200 Reward: -256.877\n",
      "Total T: 74000 Episode Num: 370 Episode T: 200 Reward: -351.492\n",
      "recent Evaluation: -175.58842228153432\n",
      "Total T: 74200 Episode Num: 371 Episode T: 200 Reward: -373.257\n",
      "Total T: 74400 Episode Num: 372 Episode T: 200 Reward: -136.841\n",
      "Total T: 74600 Episode Num: 373 Episode T: 200 Reward: -493.789\n",
      "Total T: 74800 Episode Num: 374 Episode T: 200 Reward: -370.102\n",
      "Total T: 75000 Episode Num: 375 Episode T: 200 Reward: -362.192\n",
      "recent Evaluation: -124.34010363380521\n",
      "Total T: 75200 Episode Num: 376 Episode T: 200 Reward: -485.365\n",
      "Total T: 75400 Episode Num: 377 Episode T: 200 Reward: -356.194\n",
      "Total T: 75600 Episode Num: 378 Episode T: 200 Reward: -16.111\n",
      "Total T: 75800 Episode Num: 379 Episode T: 200 Reward: -250.616\n",
      "Total T: 76000 Episode Num: 380 Episode T: 200 Reward: -236.435\n",
      "recent Evaluation: -167.84202760625152\n",
      "Total T: 76200 Episode Num: 381 Episode T: 200 Reward: -376.079\n",
      "Total T: 76400 Episode Num: 382 Episode T: 200 Reward: -254.651\n",
      "Total T: 76600 Episode Num: 383 Episode T: 200 Reward: -481.386\n",
      "Total T: 76800 Episode Num: 384 Episode T: 200 Reward: -251.570\n",
      "Total T: 77000 Episode Num: 385 Episode T: 200 Reward: -374.666\n",
      "recent Evaluation: -103.95219147260862\n",
      "Total T: 77200 Episode Num: 386 Episode T: 200 Reward: -249.001\n",
      "Total T: 77400 Episode Num: 387 Episode T: 200 Reward: -536.674\n",
      "Total T: 77600 Episode Num: 388 Episode T: 200 Reward: -256.394\n",
      "Total T: 77800 Episode Num: 389 Episode T: 200 Reward: -281.917\n",
      "Total T: 78000 Episode Num: 390 Episode T: 200 Reward: -376.505\n",
      "recent Evaluation: -141.6228434140595\n",
      "Total T: 78200 Episode Num: 391 Episode T: 200 Reward: -499.432\n",
      "Total T: 78400 Episode Num: 392 Episode T: 200 Reward: -378.940\n",
      "Total T: 78600 Episode Num: 393 Episode T: 200 Reward: -359.439\n",
      "Total T: 78800 Episode Num: 394 Episode T: 200 Reward: -134.564\n",
      "Total T: 79000 Episode Num: 395 Episode T: 200 Reward: -274.445\n",
      "recent Evaluation: -204.1604497813044\n",
      "Total T: 79200 Episode Num: 396 Episode T: 200 Reward: -253.869\n",
      "Total T: 79400 Episode Num: 397 Episode T: 200 Reward: -256.527\n",
      "Total T: 79600 Episode Num: 398 Episode T: 200 Reward: -252.490\n",
      "Total T: 79800 Episode Num: 399 Episode T: 200 Reward: -248.078\n",
      "Total T: 80000 Episode Num: 400 Episode T: 200 Reward: -468.562\n",
      "recent Evaluation: -120.54375212517701\n",
      "Total T: 80200 Episode Num: 401 Episode T: 200 Reward: -356.538\n",
      "Total T: 80400 Episode Num: 402 Episode T: 200 Reward: -252.664\n",
      "Total T: 80600 Episode Num: 403 Episode T: 200 Reward: -366.338\n",
      "Total T: 80800 Episode Num: 404 Episode T: 200 Reward: -362.114\n",
      "Total T: 81000 Episode Num: 405 Episode T: 200 Reward: -249.948\n",
      "recent Evaluation: -172.03344322128925\n",
      "Total T: 81200 Episode Num: 406 Episode T: 200 Reward: -377.611\n",
      "Total T: 81400 Episode Num: 407 Episode T: 200 Reward: -489.117\n",
      "Total T: 81600 Episode Num: 408 Episode T: 200 Reward: -369.555\n",
      "Total T: 81800 Episode Num: 409 Episode T: 200 Reward: -131.644\n",
      "Total T: 82000 Episode Num: 410 Episode T: 200 Reward: -133.596\n",
      "recent Evaluation: -154.096102797015\n",
      "Total T: 82200 Episode Num: 411 Episode T: 200 Reward: -126.348\n",
      "Total T: 82400 Episode Num: 412 Episode T: 200 Reward: -417.668\n",
      "Total T: 82600 Episode Num: 413 Episode T: 200 Reward: -251.121\n",
      "Total T: 82800 Episode Num: 414 Episode T: 200 Reward: -488.043\n",
      "Total T: 83000 Episode Num: 415 Episode T: 200 Reward: -358.107\n",
      "recent Evaluation: -145.22553981736326\n",
      "Total T: 83200 Episode Num: 416 Episode T: 200 Reward: -136.571\n",
      "Total T: 83400 Episode Num: 417 Episode T: 200 Reward: -247.808\n",
      "Total T: 83600 Episode Num: 418 Episode T: 200 Reward: -483.501\n",
      "Total T: 83800 Episode Num: 419 Episode T: 200 Reward: -252.699\n",
      "Total T: 84000 Episode Num: 420 Episode T: 200 Reward: -256.925\n",
      "recent Evaluation: -188.98025278914793\n",
      "Total T: 84200 Episode Num: 421 Episode T: 200 Reward: -466.719\n",
      "Total T: 84400 Episode Num: 422 Episode T: 200 Reward: -467.878\n",
      "Total T: 84600 Episode Num: 423 Episode T: 200 Reward: -132.755\n",
      "Total T: 84800 Episode Num: 424 Episode T: 200 Reward: -372.109\n",
      "Total T: 85000 Episode Num: 425 Episode T: 200 Reward: -369.415\n",
      "recent Evaluation: -141.16166911668208\n",
      "Total T: 85200 Episode Num: 426 Episode T: 200 Reward: -491.870\n",
      "Total T: 85400 Episode Num: 427 Episode T: 200 Reward: -359.204\n",
      "Total T: 85600 Episode Num: 428 Episode T: 200 Reward: -131.319\n",
      "Total T: 85800 Episode Num: 429 Episode T: 200 Reward: -369.048\n",
      "Total T: 86000 Episode Num: 430 Episode T: 200 Reward: -476.021\n",
      "recent Evaluation: -132.29051228322095\n",
      "Total T: 86200 Episode Num: 431 Episode T: 200 Reward: -498.003\n",
      "Total T: 86400 Episode Num: 432 Episode T: 200 Reward: -281.490\n",
      "Total T: 86600 Episode Num: 433 Episode T: 200 Reward: -375.627\n",
      "Total T: 86800 Episode Num: 434 Episode T: 200 Reward: -254.848\n",
      "Total T: 87000 Episode Num: 435 Episode T: 200 Reward: -250.998\n",
      "recent Evaluation: -197.07418913167805\n",
      "Total T: 87200 Episode Num: 436 Episode T: 200 Reward: -459.284\n",
      "Total T: 87400 Episode Num: 437 Episode T: 200 Reward: -512.200\n",
      "Total T: 87600 Episode Num: 438 Episode T: 200 Reward: -499.811\n",
      "Total T: 87800 Episode Num: 439 Episode T: 200 Reward: -368.160\n",
      "Total T: 88000 Episode Num: 440 Episode T: 200 Reward: -360.514\n",
      "recent Evaluation: -184.33825326142633\n",
      "Total T: 88200 Episode Num: 441 Episode T: 200 Reward: -374.137\n",
      "Total T: 88400 Episode Num: 442 Episode T: 200 Reward: -372.315\n",
      "Total T: 88600 Episode Num: 443 Episode T: 200 Reward: -251.710\n",
      "Total T: 88800 Episode Num: 444 Episode T: 200 Reward: -249.527\n",
      "Total T: 89000 Episode Num: 445 Episode T: 200 Reward: -379.826\n",
      "recent Evaluation: -117.71213072844587\n",
      "Total T: 89200 Episode Num: 446 Episode T: 200 Reward: -362.482\n",
      "Total T: 89400 Episode Num: 447 Episode T: 200 Reward: -459.474\n",
      "Total T: 89600 Episode Num: 448 Episode T: 200 Reward: -222.499\n",
      "Total T: 89800 Episode Num: 449 Episode T: 200 Reward: -357.807\n",
      "Total T: 90000 Episode Num: 450 Episode T: 200 Reward: -250.258\n",
      "recent Evaluation: -102.73795925581983\n",
      "Total T: 90200 Episode Num: 451 Episode T: 200 Reward: -132.133\n",
      "Total T: 90400 Episode Num: 452 Episode T: 200 Reward: -135.813\n",
      "Total T: 90600 Episode Num: 453 Episode T: 200 Reward: -364.021\n",
      "Total T: 90800 Episode Num: 454 Episode T: 200 Reward: -447.679\n",
      "Total T: 91000 Episode Num: 455 Episode T: 200 Reward: -124.539\n",
      "recent Evaluation: -225.81746696843024\n",
      "Total T: 91200 Episode Num: 456 Episode T: 200 Reward: -334.162\n",
      "Total T: 91400 Episode Num: 457 Episode T: 200 Reward: -250.088\n",
      "Total T: 91600 Episode Num: 458 Episode T: 200 Reward: -10.380\n",
      "Total T: 91800 Episode Num: 459 Episode T: 200 Reward: -372.509\n",
      "Total T: 92000 Episode Num: 460 Episode T: 200 Reward: -247.409\n",
      "recent Evaluation: -139.88557327604914\n",
      "Total T: 92200 Episode Num: 461 Episode T: 200 Reward: -358.104\n",
      "Total T: 92400 Episode Num: 462 Episode T: 200 Reward: -247.268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 92600 Episode Num: 463 Episode T: 200 Reward: -7.593\n",
      "Total T: 92800 Episode Num: 464 Episode T: 200 Reward: -132.013\n",
      "Total T: 93000 Episode Num: 465 Episode T: 200 Reward: -363.443\n",
      "recent Evaluation: -191.76755396903667\n",
      "Total T: 93200 Episode Num: 466 Episode T: 200 Reward: -370.362\n",
      "Total T: 93400 Episode Num: 467 Episode T: 200 Reward: -131.557\n",
      "Total T: 93600 Episode Num: 468 Episode T: 200 Reward: -133.457\n",
      "Total T: 93800 Episode Num: 469 Episode T: 200 Reward: -129.057\n",
      "Total T: 94000 Episode Num: 470 Episode T: 200 Reward: -473.012\n",
      "recent Evaluation: -156.1858827314124\n",
      "Total T: 94200 Episode Num: 471 Episode T: 200 Reward: -249.663\n",
      "Total T: 94400 Episode Num: 472 Episode T: 200 Reward: -371.208\n",
      "Total T: 94600 Episode Num: 473 Episode T: 200 Reward: -251.140\n",
      "Total T: 94800 Episode Num: 474 Episode T: 200 Reward: -128.995\n",
      "Total T: 95000 Episode Num: 475 Episode T: 200 Reward: -249.112\n",
      "recent Evaluation: -150.53770409925\n",
      "Total T: 95200 Episode Num: 476 Episode T: 200 Reward: -343.982\n",
      "Total T: 95400 Episode Num: 477 Episode T: 200 Reward: -344.567\n",
      "Total T: 95600 Episode Num: 478 Episode T: 200 Reward: -235.553\n",
      "Total T: 95800 Episode Num: 479 Episode T: 200 Reward: -368.508\n",
      "Total T: 96000 Episode Num: 480 Episode T: 200 Reward: -469.590\n",
      "recent Evaluation: -91.154817772663\n",
      "Total T: 96200 Episode Num: 481 Episode T: 200 Reward: -154.290\n",
      "Total T: 96400 Episode Num: 482 Episode T: 200 Reward: -244.333\n",
      "Total T: 96600 Episode Num: 483 Episode T: 200 Reward: -245.549\n",
      "Total T: 96800 Episode Num: 484 Episode T: 200 Reward: -383.218\n",
      "Total T: 97000 Episode Num: 485 Episode T: 200 Reward: -131.120\n",
      "recent Evaluation: -183.30359512333104\n",
      "Total T: 97200 Episode Num: 486 Episode T: 200 Reward: -127.006\n",
      "Total T: 97400 Episode Num: 487 Episode T: 200 Reward: -240.126\n",
      "Total T: 97600 Episode Num: 488 Episode T: 200 Reward: -371.870\n",
      "Total T: 97800 Episode Num: 489 Episode T: 200 Reward: -249.098\n",
      "Total T: 98000 Episode Num: 490 Episode T: 200 Reward: -126.244\n",
      "recent Evaluation: -179.19128929111426\n",
      "Total T: 98200 Episode Num: 491 Episode T: 200 Reward: -253.800\n",
      "Total T: 98400 Episode Num: 492 Episode T: 200 Reward: -134.586\n",
      "Total T: 98600 Episode Num: 493 Episode T: 200 Reward: -360.711\n",
      "Total T: 98800 Episode Num: 494 Episode T: 200 Reward: -130.203\n",
      "Total T: 99000 Episode Num: 495 Episode T: 200 Reward: -123.234\n",
      "recent Evaluation: -163.0419214104069\n",
      "Total T: 99200 Episode Num: 496 Episode T: 200 Reward: -246.750\n",
      "Total T: 99400 Episode Num: 497 Episode T: 200 Reward: -365.847\n",
      "Total T: 99600 Episode Num: 498 Episode T: 200 Reward: -129.815\n",
      "Total T: 99800 Episode Num: 499 Episode T: 200 Reward: -252.372\n",
      "Total T: 100000 Episode Num: 500 Episode T: 200 Reward: -358.231\n",
      "recent Evaluation: -173.13194039854193\n"
     ]
    }
   ],
   "source": [
    "# The following scripts run the TD3 algorithm.\n",
    "\n",
    "alias = 'td3'\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import argparse\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import utils\n",
    "import TD3\n",
    "import DDPG\n",
    "\n",
    "def eval_policy(policy, eval_episodes=10):\n",
    "    eval_env = gym.make(ENV_NAME)\n",
    "\n",
    "    avg_reward = 0.\n",
    "    for _ in range(eval_episodes):\n",
    "        state, done = eval_env.reset(), False\n",
    "        while not done:\n",
    "            action = policy.select_action(np.array(state))\n",
    "            state, reward, done,_ = eval_env.step(action)\n",
    "            avg_reward += reward\n",
    "\n",
    "    avg_reward /= eval_episodes\n",
    "    #print(\"---------------------------------------\")\n",
    "    #print(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "    #print(\"---------------------------------------\")\n",
    "    return avg_reward\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = env.action_space.high[0]\n",
    "\n",
    "args_policy_noise = 0.2\n",
    "args_noise_clip = 0.5\n",
    "args_policy_freq = 2\n",
    "args_max_timesteps = 100000\n",
    "args_expl_noise = 0.1\n",
    "args_batch_size = 25\n",
    "args_eval_freq = 1000\n",
    "args_start_timesteps = 0\n",
    "\n",
    "kwargs = {\n",
    "    \"state_dim\": state_dim,\n",
    "    \"action_dim\": action_dim,\n",
    "    \"max_action\": max_action,\n",
    "    \"discount\": 0.99,\n",
    "    \"tau\": 0.005\n",
    "}\n",
    "\n",
    "\n",
    "args_policy = 'TD3'\n",
    "\n",
    "if args_policy == \"TD3\":\n",
    "    # Target policy smoothing is scaled wrt the action scale\n",
    "    kwargs[\"policy_noise\"] = args_policy_noise * max_action\n",
    "    kwargs[\"noise_clip\"] = args_noise_clip * max_action\n",
    "    kwargs[\"policy_freq\"] = args_policy_freq\n",
    "    policy = TD3.TD3(**kwargs)\n",
    "elif args_policy == \"OurDDPG\":\n",
    "    policy = OurDDPG.DDPG(**kwargs)\n",
    "elif args_policy == \"DDPG\":\n",
    "    policy = DDPG.DDPG(**kwargs)\n",
    "replay_buffer = utils.ReplayBuffer(state_dim, action_dim)\n",
    "\n",
    "# Evaluate untrained policy\n",
    "evaluations = [eval_policy(policy)]\n",
    "\n",
    "state, done = env.reset(), False\n",
    "episode_reward = 0\n",
    "episode_timesteps = 0\n",
    "episode_num = 0\n",
    "counter = 0\n",
    "msk_list = []        \n",
    "temp_curve = [eval_policy(policy)]\n",
    "temp_val = []\n",
    "for t in range(int(args_max_timesteps)):\n",
    "    episode_timesteps += 1\n",
    "    counter += 1\n",
    "    # Select action randomly or according to policy\n",
    "    if t < args_start_timesteps:\n",
    "        action = np.random.uniform(-max_action,max_action,action_dim)\n",
    "    else:\n",
    "        if np.random.uniform(0,1) < 0.1:\n",
    "            action = np.random.uniform(-max_action,max_action,action_dim)\n",
    "        else:\n",
    "            action = (\n",
    "                policy.select_action(np.array(state))\n",
    "                + np.random.normal(0, max_action * args_expl_noise, size=action_dim)\n",
    "            ).clip(-max_action, max_action)\n",
    "\n",
    "    # Perform action\n",
    "    next_state, reward, done,_ = env.step(action)\n",
    "    done_bool = float(done) if episode_timesteps < env._max_episode_steps else 0\n",
    "\n",
    "    replay_buffer.add(state, action, next_state, reward, done_bool)\n",
    "\n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "\n",
    "    if t >= args_start_timesteps:\n",
    "        '''TD3'''\n",
    "        last_val = 999.\n",
    "        patient = 5\n",
    "        for i in range(1):\n",
    "            policy.train(replay_buffer, args_batch_size)\n",
    "                \n",
    "\n",
    "    # Train agent after collecting sufficient data\n",
    "    if done: \n",
    "        print(f\"Total T: {t+1} Episode Num: {episode_num+1} Episode T: {episode_timesteps} Reward: {episode_reward:.3f}\")\n",
    "        msk_list = []\n",
    "        state, done = env.reset(), False\n",
    "        episode_reward = 0\n",
    "        episode_timesteps = 0\n",
    "        episode_num += 1 \n",
    "\n",
    "    # Evaluate episode\n",
    "    if (t + 1) % args_eval_freq == 0:\n",
    "        evaluations.append(eval_policy(policy))\n",
    "        print('recent Evaluation:',evaluations[-1])\n",
    "        np.save('results/evaluations_alias{}_ENV{}'.format(alias,ENV_NAME),evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KboX9hB5eEVv"
   },
   "source": [
    "# Four-Solution-Maze Environment (optional)\n",
    "\n",
    "## TODOs for you:\n",
    "\n",
    "- Q11. (bonus) In this section, another environment named Four-Solution-Maze is provided for you to evaluate your algorithms.\n",
    "\n",
    "The task is quite simple, yet never easy for even PPO/TD3.\n",
    "\n",
    "The default size of the maze is 64x64, and in each game (espisode), the agent is initialized randomly in the maze. There are 4 positions in the maze that has non-trivial reward of +10, while reaching other region will recieve only a tiny punishment of -0.1. An optimal policy should be able to find the shortest path to the most recent reward region (i.e., one of the four high-reward regions.).\n",
    "\n",
    "The action space is continuous with range [-1,1], larger actions will be clipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kX6V-0bfMSev"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "import copy\n",
    "\n",
    "class FourWayGridWorld:\n",
    "    def __init__(self, N=17,left = 10,right = 10, up=10, down = 10):\n",
    "        self.N = N\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.up = up\n",
    "        self.down = down\n",
    "        self.map = np.ones((N,N))*(-0.1)\n",
    "        self.map[int((N-1)/2),0] = self.left\n",
    "        self.map[0,int((N-1)/2)] = self.up\n",
    "        self.map[N-1,int((N-1)/2)] = self.down\n",
    "        self.map[int((N-1)/2),N-1] = self.right\n",
    "        self.loc = np.asarray([np.random.randint(N),np.random.randint(N)])\n",
    "        self.step_num = 0\n",
    "    def step(self,action):\n",
    "        action = np.clip(action,-1,1)\n",
    "        new_loc = np.clip(self.loc + action,0,self.N-1)\n",
    "        self.loc = new_loc\n",
    "        reward = self.map[int(round(self.loc[0])),int(round(self.loc[1]))]\n",
    "        self.step_num+=1\n",
    "        return self.loc,reward,self.ifdone()\n",
    "    def ifdone(self):\n",
    "        if self.step_num >= 2*self.N:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def render(self):\n",
    "        map_self = copy.deepcopy(self.map)\n",
    "        map_self[int(self.loc[0]),int(self.loc[1])] = -5\n",
    "        plt.imshow(map_self)\n",
    "    def reset(self):\n",
    "        self.map = np.ones((self.N,self.N))*(-0.1)\n",
    "        self.map[int((self.N-1)/2),0] = self.left\n",
    "        self.map[0,int((self.N-1)/2)] = self.up\n",
    "        self.map[self.N-1,int((self.N-1)/2)] = self.down\n",
    "        self.map[int((self.N-1)/2),self.N-1] = self.right\n",
    "        self.loc = np.asarray([np.random.randint(self.N),np.random.randint(self.N)])\n",
    "        self.step_num = 0\n",
    "        return self.loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "hoO_Ti-zhykw"
   },
   "outputs": [],
   "source": [
    "env = FourWayGridWorld(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rBzb2qw3h2ts",
    "outputId": "458ee588-3f5b-4f19-d45c-952b6b330a73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 15])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "SBcwx2WPh3nT",
    "outputId": "1b60ea64-3859-4feb-8bbf-db6e72ca287e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7WrHjDQmqC7K"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TD3' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-88bac7b6dbad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mto\u001b[0m \u001b[0mfit\u001b[0m \u001b[0myour\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         '''\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moutput_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutput_j\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TD3' object is not callable"
     ]
    }
   ],
   "source": [
    "# This section is used to visualize your learned policy\n",
    "from torch import Tensor\n",
    "output_i = np.zeros((33,33))\n",
    "output_j = np.zeros((33,33))\n",
    "output_i_m = np.zeros((33,33))\n",
    "output_j_m = np.zeros((33,33))\n",
    "value_ij = np.zeros((33,33))\n",
    "for i in range(33):\n",
    "    for j in range(33):\n",
    "        states = Tensor(np.asarray([i,j])).float().unsqueeze(0)\n",
    "        \n",
    "        '''\n",
    "        you need to revise the following line, \n",
    "        to fit your policy/network outputs\n",
    "        '''\n",
    "        action, value = policy(states)\n",
    "        output_i[i,j] = action[0]\n",
    "        output_j[i,j] = action[1]\n",
    "        value_ij[i,j] = value\n",
    "        \n",
    "plt.figure(figsize= (5,5))\n",
    "for i in range(33):\n",
    "    for j in range(33):\n",
    "        plt.arrow(j,-i,output_j[i,j],-output_i[i,j],head_width=0.2,shape='left')\n",
    "xlim(-1,33)\n",
    "ylim(-33,1)\n",
    "yticks([2*i-32 for i in range(17)],[2*i for i in range(17)])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5YEdvVdqDd7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment4_W/O_Sol.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
